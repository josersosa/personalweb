[
  {
    "path": "posts/2021-07-12-editor-en-linea-de-comandos-vim/",
    "title": "Editor en línea de comandos - Vim",
    "description": "Vin es un editor en línea de comandos presente en casi todos los sistemas operativos y especialmente en las distribuciones de Linux. Además pos su simplicidad es posible ejecutarlo en casi todo tipo de hardware, por lo que es muy útil conocer como funciona.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2021-07-10",
    "categories": [
      "Linux Recipes",
      "Vim"
    ],
    "contents": "\n\nContents\nInstalación\nConfiguración\nCómo ejecutar Vim\nComandos básicos\nReferencias:\n\nInstalación\napt/get install vim\nConfiguración\nel archivo de configuración se encuentra en ~/.vimrc y por lo general contiene al menos:\nsyntax on\nif has(\"autocmd\")\n   au BufReadPost * if line(\"'\\\"\") > 1 && line(\"'\\\"\") <= line(\"$\") | exe \"normal! g'\\\"\" | endif\nendif\nset background=dark\nBásicamente definen:\nResaltado de código\nRecordar la posición del curso en la última entrada\nColores compatibles con los temas oscuros de escritorio\nCómo ejecutar Vim\n$ vim\nComandos básicos\nItem\nUso\nOpciones\n1\nmodo de edición\ni, a, [INSERT]\n2\nmodo de control\n[ESC]\n3\nmodo visual (seleccionar texto)\nv\n4\nejecutar sin preguntar\n!\n5\nsalir\n:q, :q!\n6\nguardar\n:w, :w!\n7\nguardar cambios y salir\n:wq, :wq!, :x, :x!\n8\nmostrar números de linea\n:set nu\n9\nquitar números de linea\n:set nu!\n10\ncambiar set de colores\n:set background=[color] (light, dark)\n11\ncortar lineas seleccionadas\n:d\n12\ncortar una linea\n:dd\n13\ncortar varias lineas\n:d2d (para cortar 2 líneas)\n14\npegar una línea siguiente\n:p\n15\ncopiar lineas seleccionadas\n:y\n16\ncopiar una línea\n:yy\n17\ncopiar varias líneas\n:y3y (copia 3 líneas)\n18\nagregar una línea siguiente (insert)\n:o\n19\nundo (devolver cambios)\n:u\n20\nre-hacer (devolver cambio hacia adelante)\n[CTRL] r\n21\nbúsquedas\n/[texto a buscar]\n22\nsiguiente ocurrencia encontrada\nn\n23\nocurrencia anterior\nN\n24\nir al inicio del archivo\ngg\n25\nir al final del archivo\nG\nReferencias:\nVIM - Tutorial para principiantes - El MEJOR editor de texto (PeladoNerd en youtube)\n\n\n\n",
    "preview": "posts/2021-07-12-editor-en-linea-de-comandos-vim/../../images/edex-ui.png",
    "last_modified": "2021-07-12T02:44:23+00:00",
    "input_file": "editor-en-linea-de-comandos-vim.utf8.md",
    "preview_width": 800,
    "preview_height": 450
  },
  {
    "path": "posts/2021-06-30-wordpress-con-docker/",
    "title": "WordPress con Docker",
    "description": "WordPress es una de las herramientas de tipo CMS (Content Management system) más utilizados, hoy en día, para la construcción de sitios web. Veremos como podemos habilitar una instalación de esta herramienta en nuestro entorno local, con solo dos comandos (o uno solo...)",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2021-06-29",
    "categories": [
      "Linux Recipes",
      "Docker",
      "WordPress",
      "MySQL"
    ],
    "contents": "\n\nContents\nPre-requisitos\nLevantar los servicios\nComenzar a trabajar\nDocker Compose\nInstalación de Docker Compose\nUso de Docker Compose\nReferencias\n\nPre-requisitos\nCómo es lógico suponer, se requiere tener instalado Docker en nuestro sistema y haber ubicado los directorios que usaremos para almacenar la base de datos y las páginas web, aunque para este fin también podríamos usar volúmenes en lugar de directorios.\nLevantar los servicios\nComo hemos visto se requieren dos contenedores, uno para el WordPress con el servidor web y el otro para la base de datos MySQL. Para activarlos, ejecutamos en la línea de comandos las siguientes dos instrucciones, cambiando antes, los valores de los parámetros para que se acomoden los requerimientos de proyecto, tales como nombre de la base de datos, usuario, password y directorios locales para almacenar el proyecto\n# Contenedor de MySQL\ndocker run -d --name my-mysql \\\n-p 3306:3306 \\\n-e MYSQL_ROOT_PASSWORD=secret \\\n-e MYSQL_DATABASE=wordpress \\\n-e MYSQL_USER=wordpress \\\n-e MYSQL_PASSWORD=wordpress \\\n-v $HOME/mysql-data:/var/lib/mysql  \\\nmysql\n# Contenedor de WordPress\ndocker run -d --name wordpress \\\n-p 8080:80 \\\n-e WORDPRESS_DB_HOST=192.168.0.107 \\\n-e WORDPRESS_DB_USER=wordpress \\\n-e WORDPRESS_DB_NAME=wordpress \\\n-e WORDPRESS_DB_PASSWORD=wordpress  \\\n-v $HOME/worpress-data:/var/www/html \\\nwordpress\n  \nRecuerde que debe cambiar la dirección IP (192.168.0.107) por la dirección del equipo en el entorno local. Observe que usar localhost no debería funcionar, ya que se trata de una parámetro que le estamos pasando al contenedor de WordPress, y lo interpretaría como que debe buscar la base de datos dentro de el.\nComenzar a trabajar\nUna vez levantados los servicios podemos comenzar a trabajar accediendo a la dirección local en el puerto especificado:\nPantalla de instalación de wordpressDocker Compose\nOtra alternativa para levantar nuestra aplicación, que como sabemos requiere de dos componentes, es con el uso de Docker Compose. Esta herramienta viene instalada en la distribución de Docker para Windows y para Mac, pero en Linux es necesario instalarla por separado\nInstalación de Docker Compose\ncurl -L https://github.com/docker/compose/releases/download/1.24.0/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\n# para verificar la instalación\ndocker-compose -v \nUso de Docker Compose\nEsta herramienta permite la gestión de aplicaciones conformadas por múltiples componentes mediante la definición de un archivo de configuración llamado docker-compose.yaml. Note que de esta forma ya no es necesario llevar cuenta de las IPs. En nuestro caso creamos este archivo con el siguiente contenido:\nversion: \"3.9\"\n    \nservices:\n  mysql:\n    image: mysql:5.7\n    volumes:\n      - mysql_data:/var/lib/mysql\n    restart: always\n    environment:\n      MYSQL_ROOT_PASSWORD: sserpdrow\n      MYSQL_DATABASE: wordpress\n      MYSQL_USER: wordpress\n      MYSQL_PASSWORD: wordpress\n    ports:\n      -\"3306:3306\"\n  phpmyadmin:\n    depends_on:\n      - mysql\n    image: phpmyadmin/phpmyadmin\n    environment:\n      - PMA_ARBITRARY=1\n      - PMA_HOST=mysql:3306\n      - PMA_USER=wordpress\n      - PMA_PASSWORD=wordpress\n    ports:\n      -\"8000:80\" \n  wordpress:\n    depends_on:\n      - mysql\n    image: wordpress:latest\n    volumes:\n      - wordpress_data:/var/www/html\n    restart: always\n    environment:\n      WORDPRESS_DB_HOST: mysql:3306\n      WORDPRESS_DB_USER: wordpress\n      WORDPRESS_DB_PASSWORD: wordpress\n      WORDPRESS_DB_NAME: wordpress\n    ports:\n      - \"8080:80\"\nvolumes:\n  mysql_data: {}\n  wordpress_data: {}\nComo se puede observar, este archivo define la creación de dos contenedores: mysql, phpmyadmin y wordpress. Además para cada uno de ellos define los volúmenes (mysql_data y wordpress_data) que servirán para persistir los cambios, es decir guardar los proyectos que se desarrollen con estas plataformas. De esta manera los contenedores se convierten en entornos desechables ya que lo importante siempre estará almacenado en los volúmenes.\nLuego basta iniciar el servicio con la siguiente instrucción:\ndocker-compose up -d\nPara detenerlo se utiliza:\ndocker-compose down\nReferencias\nCómo ejecutar MySQL en un contenedor Docker\nInstalar wordpress usando docker\nCómo usar Docker para desarrollar en WordPress\n\n\n\n",
    "preview": "posts/2021-06-30-wordpress-con-docker/../../images/docker-wordpress.png",
    "last_modified": "2021-06-30T04:31:40+00:00",
    "input_file": "wordpress-con-docker.knit.md",
    "preview_width": 1141,
    "preview_height": 694
  },
  {
    "path": "posts/2021-06-26-configurando-una-raspberry-pi-modelo-4/",
    "title": "Configurando una Raspberry Pi modelo 4",
    "description": "Veamos cómo configurar nuestra nueva Raspberry Pi modelo 4, con una pequeña SD card de 4 GB y sin perifericos de entrada o salida, para manejarla desde la red local a través de la interfaz web de CockPit. Este es un escenario común cuando utilizamos la Raspberry para el control de dispositivos robóticos o embebida en sistemas de control y monitoreo.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2021-06-25",
    "categories": [
      "Linux Recipes",
      "Raspberry Pi",
      "Robotics"
    ],
    "contents": "\n\nContents\nDescarga del sitema operativo\nInstalando la imagen en la SD card:\nIniciando el sistema\nProblema del MAC address Randomization\nManejando nuestra Raspberry Pi con Cockpit\nInstalamos cockpit y verificamos que se esté ejecutando como servicio:\nAccediendo al servico\nMonitoreo de los recursos del sistema\nGestión de servicios\nAcceso a la terminal\n\n\nCockpit es una interfaz gráfica basada en web para la gestion de multiples servidores orientada a todo tipo de usuario, desde usuarios sin experiencia con Linux, hasta expertos administradores. Cockpit utiliza las API y los comandos del sistema para permitir su administración de la forma que prefieran, incluida la línea de comandos y las utilidades.\nDescarga del sitema operativo\nVamos utilizar el Raspberry Pi OS , hay varias versiones, en mi caso usaré la Lite, sin entorno gráfico porque la quiero manejar desde la red, aunque en todos los casos el procedieminto es el mismo:\nwget https://downloads.raspberrypi.org/raspios_lite_armhf/images/raspios_lite_armhf-2021-05-28/2021-05-07-raspios-buster-armhf-lite.zip .\nunzip 2021-05-07-raspios-buster-armhf-lite.zip\nInstalando la imagen en la SD card:\nAsumiendo que la SD card se encuentra ubicada dentro de nuestro sistema en /dev/mmcblk0, lo que podemos verificar con fdisk -l, el comando sería así:\nsudo dd if=2021-05-07-raspios-buster-armhf-lite.img  of=/dev/mmcblk0 bs=4M conv=fsync\nIniciando el sistema\nLuego de colocar la SD card en la Raspberry y encenderla,entramos con el usuario y password por defecto (que luego podemos cmbiar con passwd)\nLogin: pi\npassword: raspberry\nLuego vamos a configurar la red y actualizamos la lista de repositorios:\nsudo raspy-config\nsudo apt-get update\nProblema del MAC address Randomization\nPara evitar el problema de MAC address aleatoria y poder fijar la direccion IP de la Raspberry en nuestra red local debemos crear el siguiente archivo de configuración:\ncat >> /etc/NetworkManager/conf.d/100-disable-wifi-mac-randomization.conf <<EOT\n[connection]\nwifi.mac-address-randomization=1\n[device]\nwifi.scan-rand-mac-address=no\nEOT\nSi esto no funciona podemos configurar el cliente DHCP para que solicite siempre el mismo ip, agregando lo sigueinte en elarchivo /etc/dhcpcd.conf:\ninterface wlan0\n    static ip_address=192.168.1.2/24\n    static routers=192.168.1.254\nManejando nuestra Raspberry Pi con Cockpit\nInstalamos cockpit y verificamos que se esté ejecutando como servicio:\nsudo apt install cockpit\nsystemctl status cockpit.socket\n● cockpit.socket - Cockpit Web Service Socket\n   Loaded: loaded (/lib/systemd/system/cockpit.socket; enabled; vendor preset: enabled)\n   Active: active (listening) since Tue 2021-05-04 10:24:43 EDT; 35s ago\n     Docs: man:cockpit-ws(8)\n   Listen: 0.0.0.0:9090 (Stream)\n  Process: 6563 ExecStartPost=/usr/share/cockpit/motd/update-motd  localhost (code=exited, status=0/SUCCESS)\n  Process: 6570 ExecStartPost=/bin/ln -snf active.motd /run/cockpit/motd (code=exited, status=0/SUCCESS)\n    Tasks: 0 (limit: 2181)\n   CGroup: /system.slice/cockpit.socket\nAccediendo al servico\nAhora podemos acceder al servicio de CockPit con cualquier browser a travez del puerto 9090, conociendo la direccion IP de la Raspberry Pi, por ejemplo 192.168.0.106, el enlace sería así\nhttp://192.168.0.106:9090\nEntramos usando nuestro usario de la Raspberry:\n\nMonitoreo de los recursos del sistema\n\nGestión de servicios\n\nAcceso a la terminal\n\n\n\n\n",
    "preview": "posts/2021-06-26-configurando-una-raspberry-pi-modelo-4/../../images/robotics/raspberry-pi-model4.jpg",
    "last_modified": "2021-06-30T14:36:25+00:00",
    "input_file": "configurando-una-raspberry-pi-modelo-4.knit.md"
  },
  {
    "path": "posts/2021-05-11-despliegue-de-una-aplicacin-web-con-nginx-y-docker/",
    "title": "Desplegar una aplicación web local con NGINX y Docker",
    "description": "El NGINX es un servidor web muy ligero y eficiente, que en la Ciencia de Datos puede ser muy útil para el despliegue de aplicaciones de IA, compuestas por diferentes componentes dockeriados. Veremos lo simple que puede llegar ser despliegar cualquier aplicación web si utilizamos este servidor dentro de un contenedor docker.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2021-05-10",
    "categories": [
      "Linux Recipes",
      "Docker",
      "Nginx"
    ],
    "contents": "\n\nContents\nEnlaces importantes\nCorriendo un Web service básico\nEjecutando la web por defecto\nDesplegando nuestra propia WebApp\n\nNGINX es un servidor web muy ligero y eficiente, que es usado por desarrolladores y en ingenieros de operaciones, no solo para proveer todo tipo de aplicaciones web, sino también como proxi inverso.\nPara reproducir este tutorial necesitaras:\nTener instalado Docker en tu sistema\nTener una cuenta o registrarte en DockerHub para acceder a las imágenes oficiales de NGINX y muchas otras\nEnlaces importantes\nDocker Official Images\nNGINX official image\nCorriendo un Web service básico\nPodemos ejecutar docker por línea de comandos o por el Docker Desktop\ndocker run --rm -d -p 8080:80 --name webapp nginx\nVemos brevemente el significado de los parámetros utilizados:\n--rm: Le indica al motor de docker, que una vez que se apague el servicio, elimine el contenedor.\n-d: Indica que ser servicio debe ejecutarse como un demonio o servicio que escuha un determinado puerto (80).\n-p: Permite mapear el puerto 80 del NGINX al puerto 8080 de nuestro equipo local (localhost).\n--name: Opcional, podemos indicar un nombre para el contenedor.\nnginx: Nombre de la imagen a ejecutar (nginx oficial), si no esta descarada, procederá a hacerlo\nEjecutando la web por defecto\nBastara con acceder a la dirección http://locahost:8080/ para acceder a la página, por defecto, de NGINX:\nimage-20210426115523552Desplegando nuestra propia WebApp\nCómo demostración, crearemos un HTML simple como página principal (index.html):\n<!doctype html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"utf-8\">\n  <title>Docker Nginx image<\/title>\n<\/head>\n<body>\n  <h2>Esta página corre dentro de un contenedor con Nginx<\/h2>\n<\/body>\n<\/html>\nDesplegamos el contenedor con nuestro HTML personalizado:\ndocker run --rm -d -p 8080:80 --name webapp -v /path_to_html_dir:/usr/share/nginx/html nginx\nEl parámetro -v de docker permite compartir un archivo o directorio local con el contenedor a través de u protocolo llamado HostPath. De esta manero podemos realizar cambios en la aplicación desde nuestro ambiente de desarrollo local y ver sus efectos en el servicio dockerizado que lo expone.\nAccediendo a nuestra WebApp local, ahora vemos nuestra versión del index.html:\nimage-20210426115108122Fuente: https://www.docker.com/blog/how-to-use-the-official-nginx-docker-image/\n\n\n\n",
    "preview": "posts/2021-05-11-despliegue-de-una-aplicacin-web-con-nginx-y-docker/../../images/image-20210426115523552.png",
    "last_modified": "2021-05-28T00:57:10+00:00",
    "input_file": {},
    "preview_width": 1112,
    "preview_height": 653
  },
  {
    "path": "posts/2021-04-30-la-mquina-de-galton-del-caos-al-orden/",
    "title": "La máquina de Galton, del Caos al Orden...",
    "description": "La \"Maquina de Galton\" es el nombre de un famoso experimento, que a pesar de estar completamente gobernado por el azar, muestra claramente como se presenta siempre la misma tendencia o distribución de los resultados.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://example.com/josersosa"
      }
    ],
    "date": "2021-04-30",
    "categories": [
      "R",
      "Data Science",
      "Teaching",
      "Simulation",
      "Statistic"
    ],
    "contents": "\n\nContents\nFrancis Galton\nLa “Máquina de Galton”\nImportancia de este experimento\n¿Por qué ocurre esto?\nFormulación matemática\nSimulación de la Máquina de Galton en R\n\nAunque considero que el título de este video esta mal escogido, debido a que el caos no es desorden, sino orden. Este es un video que me gusta mostrar a los estudiantes al comienzo del tema de variables aleatorias, porque ejemplifica bastante bien la connotación empírica de las funciones de probabilidad.\nFrancis Galton\nSir Francis Galton (1822 - 1911) fue un antropólogo y geógrafo inglés. Estudió medicina en el hospital de Birmingham, en Londres y en Cambridge. Primo el gran Charles Darwin, que luego de muchos viajes se dedico a la investigación científica en el área de la geografía y la meteorología. Luego, inspirado por la publicación del Origen de las especies, se dedico en parte de su vida a teoría de la herencia y estadística demográfica.\nLa “Máquina de Galton”\nEste experimento consiste de una distribución de clavos o alfileres en forma triangular, de manera que al soltar un número de bolitas desde la cúspide de la estructura, caen chocando con estos alfileres. Cada bolita chocará con el primer clavo teniendo una probabilidad de 1/2 de ir hacía la izquierda o hacía la derecha, y así sucesivamente con los otros alfileres de los siguientes niveles. A lo largo de esta estructura, las bolitas toman caminos aleatorios hasta caer en alguno de los canales o bandejas colocadas en la base. El siguiente es un video de la máquina de Galton en acción:\n\n \n\nAl final, como se observa en el video, tendrán mayores probabilidades los canales interiores que los exteriores, formándose una distribución de probabilidades conocida como Binomial, que si el número de pelotas es suficientemente grande puede aproximarse por una distribución Normal o Gaussiana. Esta es justamente, la distribución que se encuentra dibujada sobre la máquina a modo de predicción de los resultados.\nImportancia de este experimento\nCuando nos enfrentamos a escenarios gobernados por el azar, como lo pueden ser muchas situaciones en economía, finanzas, opinión pública, redes sociales, marketing, etc. Generalmente sentimos que es como lanzar una moneda (50-50) y nuestra intuición nos dice que no podemos predecir lo que ocurrirá, por lo que no se puede tomar ninguna decisión fundamentada. Sin embargo, como se ha demostrado muchas veces, la estadística puede llegar a ser contra-intuitiva.\nSi bien no podemos predecir los resultados exactos, como lo sugiere la Maquina de Galton, muchos de estos escenarios siguen patrones. Conociendo estos patrones podemos hacer inferencias y tomar decisiones acertadas, siempre que entendamos y manejemos adecuadamente los márgenes de error de nuestras predicciones.\n¿Por qué ocurre esto?\nIntuitivamente podemos ver que la trayectoria de cada bolita es una secuencia de “decisiones” entre ¿izquierda o derecha?, cuyas posibilidades se reducen a medida que nos acercamos a las bandejas de los extremos. Tomemos por ejemplo la primera bandeja de la izquierda, para poder llegar a ella, una bolita tendría que tomar la misma decisión a lo largo de toda su trayectoria (izquierda, izquierda, izquierda,….) es decir que hay una sola forma o camino para llegar a esta bandeja. Por otro lado las bandejas del centro tienen muchos más caminos para llegar a ellas. Podemos suponer que la cantidad de bolitas que terminaran en cada bandeja, será proporcional a la cantidad de caminos posibles que hay para llegar a ellas.\nNota: Si no estas interesado en la matemática o simulación computacional, puedes leer hasta aquí.\nFormulación matemática\nSupongamos que la pirámide de alfileres conta de \\(n\\) niveles, es decir que esto corresponde las \\(n\\) decisiones que debe tomar cada bolita para llegar a alguna bandeja, por lo tanto debe haber al final \\(n+1\\) bandejas enumeradas desde el \\(0\\) al \\(n\\).\nPara representar las trayectorias de cada bolita, digamos que la decisión de ir por la izquierda es un 0 y la derecha es un 1, llamemos \\(D\\) a la variable aleatoria Bernoulli que representa cada decisión: \\[\nD=\\left\\{ \\begin{array}{lcc}\n             0 &   izquierda\n             \\\\ 1 &  derecha\n             \\end{array}, luego ~ D \\sim Bernoulli(p=1/2) \n   \\right.\n\\] Entonces cada trayectoria es independiente de las otras y se puede representar como un secuencia de \\(n\\) decisiones independientes, a su vez: \\[\nTrayectoria =\\left\\{d_1, d_2,...,d_n\\right\\}\n\\] por ejemplo: \\[\nTrayectoria =\\left\\{0, 1, 1, 0,...,1\\right\\}\n\\] Es fácil notar que la bandeja final de una bolita corresponderá a las suma de las \\(n\\) decisiones tomadas durante su trayectoria: \\[\nBandeja = \\sum_{i=1}^n{d_i}\n\\] Por ejemplo, como comentamos antes, si siempre se toma la decisión de ir por la izquierda, la bandeja final será el resultado de sumar \\(n\\) ceros: 0, es decir la primera bandeja, así, si el caso fuera tomar siempre la derecha, la suma de las decisiones daría \\(n\\) (la última de la derecha).\nEn este escenario podemos decir que la cantidad final de bolitas en cada bandeja será proporcional a la cantidad de trayectorias diferentes que llegan a ella, por lo tanto, para hallar una formulación matemática de la probabilidad de cada bandeja, pasa por contar estas trayectorias, para lo que usaremos la teoría combinatoria.\nDigamos que la bandeja final se representa por una variable aleatoria \\(X\\), para formularla, entre las bandejas de la \\(0\\) a la \\(n\\), escogemos una bandeja, digamos \\(x\\). Sabemos que para llegar a ella se tomaron \\(n\\) decisiones que incluyeron \\(x\\) unos y, por lo tanto, \\((n-x)\\) ceros, es decir, que la probabilidad de una trayectoria es el producto de la probabilidad de cada decisión: \\(p^x (1-p)^{n-x}\\). Solo faltaría saber cuantas trayectorias llegan a ella, eso lo sabemos por las posibles combinaciones de \\(x\\) unos y \\((n-x)\\) ceros, luego la probabilidad de la bandeja \\(X\\) es: \\[\nP(X)   = {n \\choose x} p^x (1-p)^{ n-x}\n\\] Que es un distribución de probabilidad conocida como Binomial, cuyos parámetros son n y p: \\[\nX \\sim Binomial(n, p)\n\\]\nDado que \\(X\\) se puede interpretar como la suma de n variables aleatorias independientes (las decisiones), cuando el parámetro n es grande, se cumple el conocido Teorema del Límite Central, lo que propone que la distribución de la variable aleatoria \\(X\\) se aproxima asintóticamente a una Normal: \\[\nX \\sim Binomial(n, p) \\approx Normal(\\mu, \\sigma^2)\n\\] donde \\(\\mu=np\\) y \\(\\sigma^2=np(1-p)\\), la esperanza matemática y la varianza de la Binomial, respectivamente.\nSimulación de la Máquina de Galton en R\nLlegamos a la parte fácil, para simular la Maquina de Galton vamos a simular las bolitas generando un número grande de trayectorias, que serán secuencias de n ceros y unos, seleccionados aleatoriamente con una probabilidad p para cada decisión:\n\n\nbolitas <- 10000 # catidad de bolitas\nn <- 30          # numero de niveles\np <- .5          # probabilidad de decision\nbandejas <- replicate(bolitas, # el numero de bolitas o trayectorias\n                      sum( sample(c(0,1), n, prob=c(0.5, 0.5), replace = TRUE) )) # suma sobre cada trayectoria\n\n\n\nLuego, para representar las bandejas donde caen las bolitas, calculamos la bandeja resultante de cada trayectoria, sumando las decisiones contenidas en cada una, todo esto lo hacemos con la función replicate. Con esto generamos un vector de las bandejas resultantes. Solo queda contar cuantas bolitas cayeron en cada bandeja y graficar la distribución, esto lo haremos con el histograma de este vector:\n\n\nhist(bandejas,               # distribucion del resultado de las bandejas\n     prob = TRUE,            # graficamos proporciones de las frecuencias\n     breaks = c(0:n+1)-0.5)  # resto 0.5 para centrar las clases en cada bandeja\nx <- seq(1,30, length.out = 100)                # generamos 100 puntos en el rango\ny <- dnorm(x, mean = n*p, sd = sqrt(n*p*(1-p))) # Funcion de dencidad de la normal \nlines(x, y, col = \"red\") # dibujamos la curva de la normal en rojo\n\n\n\n\nY obtenemos el mismo resultado que vimos en el video. Agregué a la gráfica la curva de la distribución normal para demostrarles como la aproximación a esta distribución se cumple a la perfección. Nota: Se puede ejecutar este cógigo en R varias veces para generar secuencias de trayectorias distintan y comprobar que simpre se cumple el mismo patrón.\n\n\n\n",
    "preview": "posts/2021-04-30-la-mquina-de-galton-del-caos-al-orden/../../images/simulacion-dalton.png",
    "last_modified": "2021-06-30T06:38:38+00:00",
    "input_file": "la-mquina-de-galton-del-caos-al-orden.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-04-28-datasets-para-proyectos-de-machine-learning/",
    "title": "Datasets para proyectos de Machine Learning",
    "description": "Si estas buscado un conjunto de datos \"especial\" para tu proyecto de Machine Learning, he preparado una lista, que si bien no es exhaustiva, si que sirve como propuesta de por donde comenzar a buscar.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://example.com/josersosa"
      }
    ],
    "date": "2021-04-28",
    "categories": [
      "Data Science"
    ],
    "contents": "\n\nContents\nFuentes de datos\nBucadores de datasets\nRecopilaciones o temáticos\nCompetencia o retos de ciencia de datos\nRepositorios universitarios\nPortales de datos abiertos\nProveedores de computo en la nube\nAPIs de datos\n\n\nFuentes de datos\nEsta recopilación consiste en un lista de repositorios o buscadores de datasets para todo tipo de proyectos de Machine Learning e Inteligencia Artificial. Algunas de estas fuentes de datos son en realidad buscadores, otros simples listas, Algunos son genéricos y otro son temáticos:\nBucadores de datasets\nBuscador de datasets de Google: datasetsearch.research.google.com\nBuscador de datasets de paperwithcode: paperswithcode.com/datasets\nRecopilaciones o temáticos\nDatasets in Python: towardsdatascience.com\nThe R Datasets Package: stat.ethz.ch\nThe Big Bad NLP Database : datasets.quantumstat\nOpen repository of web crawl data: Common Crawl\nMultiscale Machine Learning In Coupled Earth System Modeling M²LInES\nKDnuggets Datasets\n25 Best NLP Datasets\nCompetencia o retos de ciencia de datos\nExplore, analyze, and share quality data with Kaggle datasets: kaggle.com\nA a Large-Scale Graph ML Competiton: OGB-LSC @ KDD Cup 2021\nRepositorios universitarios\nUC Irvine Machine Learning Repository: http://archive.ics.uci.edu/ml/\nStanford Large Network Dataset Collection https://snap.stanford.edu/data/\nPortales de datos abiertos\nPortal Brasileño de datos abiertos: dados.gog.br\nPortal de datos abiertos de Uruguay: http://datos.gub.uy/\nPortal de datos abiertos de Canadá: http://open.canada.ca/data/en/dataset\nPortal de datos abiertos de Estados Unidos: https://www.data.gov/\nPortal de datos abiertos de Reino Unido: https://data.gov.uk/\nComunidad Económica Europea: https://open-data.europa.eu/es/\nBanco Mundial: http://data.worldbank.org/\nProveedores de computo en la nube\nAmazon Web Services (AWS)\nGoogle Cloud Platform (GCP)\nMicrosoft (Azure)\nAPIs de datos\nAPIs de google\nAlgunas API financieras\nAPI de Flickr\nAPIs de Twitter\n\n\n\n",
    "preview": "posts/2021-04-28-datasets-para-proyectos-de-machine-learning/../../images/datasets_peq.png",
    "last_modified": "2021-04-28T04:30:08+00:00",
    "input_file": {},
    "preview_width": 681,
    "preview_height": 409
  },
  {
    "path": "posts/2020-09-07-imgenes-de-fractales-en-gran-formato-con-r/",
    "title": "Imágenes de fractales en gran formato con R",
    "description": "Aproveché unos días de mis vacaciones para preparar algunas gráficas en R, que quería hacer desde hace tiempo para adornar mi estudio. Se trata de fractales y atractores extraños, pero quería hacerlos de forma de poder imprimirlos en formato grande, como afiches.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://example.com/josersosa"
      }
    ],
    "date": "2020-09-07",
    "categories": [
      "R",
      "Chaos and Fractals",
      "Computer Graphics",
      "Data Science"
    ],
    "contents": "\n\nContents\nGráficas en gran formato con R\nAlgoritmos de construcción\nEstructuras de datos\nProcesamiento optimización\nDimensiones y formato de la imagen\nAlising\nLayout de impresión\n\n\nLa idea es no tener que escalar las imágenes para imprimirlas en formatos grandes, sino que en vez de eso, estuvieran elaboradas pixel a pixel para estos formatos como el A1 (23.4 x 33.1 in) a 300dpi o el A2 (16.5 x 23.4 in) a 600dpi.\nHe aquí algunos resultados:\nConjunto de Mandelbrot\nAtractor de Lorenz\nAtractor de Clifford\n\n\n\nBreve reseña\nBreve reseña\nBreve reseña\nImagen de alta resolución\nImagen de alta resolución\nImagen de alta resolución\nCódigo fuente\nCódigo fuente\nCódigo fuente\nPongo a la disposición estas imágenes en alta resolución para su libre descarga, bajo licencia Creative Commons, así como los enlaces a los repositorios de código fuente para regenerarlas o modificarlas. En un próximo post estaré publicando un tutorial explicando como construir este tipo de gráficas con R, así como algunas reseñas donde expongo, desde mi punto de vista, del por qué son de tanto interés.\nGráficas en gran formato con R\nEl reto de crear imágenes de fractales o atractores extraños de gran formato implica resolver varios asuntos, entre ellos están:\nAlgoritmos de construcción.\nEstructuras de datos.\nProcesamiento y optimización.\nDimensiones y formato de la imagen.\nEl problema del Alising.\nLayout de impresión.\nAlgoritmos de construcción\nLa mayoría de los fractales o atractores extraños se construyen a partir de la definición y simulación de alguna dinámica, por ejemplo \\[\nX_{n+1}=F(X_n)\n\\] con cual, se construyen secuencias de valores para el vector X , a partir de un valor inicial o condición inicial para dicho sistema, para esto y se pueden utilizar varias estrategias:\nDiagramas de fase: consiste en la proyección de las trayectorias construidas con las variables de estado juntas en el espacio n-dimensional hacia un plano 2D.\nEscala de valores de convergencia, que consiste en recorrer una sección del espacio de posibles valores iniciales y representar en una escala de colores a los que llevan a la dinámica a converger, tomando colores según el valor de convergencia.\nTiempo de escape, consiste en en recorrer una sección del espacio de posibles condiciones iniciales y seleccionando aquellas que producen la divergencia de la dinámica, pero tomando como valor de referencia para la selección del color, la cantidad de iteraciones que requirieron para alcanzar cierto umbral, como una especie de medida de velocidad de escape.\nCualquier otro método creativo que se nos ocurra.\nEstructuras de datos\nLas estructuras de datos para construir estas gráficas son simples, el verdadero problema es contar con la memoria RAM suficiente para almacenar series de 20 millones de registros para cada una de las variables del vector de estados, o matrices en el orden de 10.000x10.000, es decir 100 millones de puntos o más\nProcesamiento optimización\nPara lograr un algoritmo capaz de construir nuestras imágenes debemos pensar en la eficiencia, en la medida de lo posible ejecutar procesos de calculo vectoriales o recurrir a sub-procesos en C/C++ con la ayuda del paquete rcpp.\nDimensiones y formato de la imagen\nCómo comentamos al comienzo, la idea principal es generar imágenes que no requieran ser escaladas o reducidas al momento de la impresión, es decir que tengan las dimensiones exactas en las cuales se verán. Recordemos que si una imagen es reducida, pierde información visual, mientras que si es agrandada, esta se pixelará. Por esta razón, primero que nada debemos decidir el tamaño impreso de nuestra gráfica.\nTabla de tamaños estándar de papel\nSize\nWidth x Height (mm)\nWidth x Height (in)\nA0\n841 x 1189 mm\n33.1 x 46.8 in\nA1\n594 x 841 mm\n23.4 x 33.1 in\nA2\n420 x 594 mm\n16.5 x 23.4 in\nA3\n297 x 420 mm\n11.7 x 16.5 in\nA4\n210 x 297 mm\n8.3 x 11.7 in\nA5\n148 x 210 mm\n5.8 x 8.3 in\nA6\n105 x 148 mm\n4.1 5.8 in\nA7\n74 x 105 mm\n2.9 x 4.1 in\nA8\n52 x 74 mm\n2.0 x 2.9 in\nA9\n37 x 52 mm\n1.5 x 2.0 in\nA10\n26 x 37 mm\n1.0 x 1.5 in\nEn R es posible graficar sobre dispositivos de despliegue distintos a la pantalla, en vez de esto podemos crear imágenes directamente en archivos con diversos formatos con funciones como png(), jpg(), tiff() o pdf(). Entre sus parámetros es posible especificar el tamaño del gráfico en diferentes unidades de medida (“cm”, “mm” o “in”), así como la resolución en “dpi” (puntos por pulgada). En relación con el formato, la recomendación es usar el PNG, dado que JPEG optimiza la imagen reduciendo su tamaño pero perdiendo calidad. Por ejemplo para generar una imagen de tamaño A2 a 600dpi y en formato PNG, el código sería de la siguiente manera:\npng(filename=\"graphic.png\", units=\"in\", width=23.4, height=16.5, res=600)\n    codigo de generación de la imagen aqui...\ndev.off()\nLe estamos indicando al dispositivo de salida que la grafica tendrá un tamaño de 23.4x16.5 pulgadas (A2) a una resolución de 600dpi. Esta misma imagen también se podría imprimir en un papel tamaño A1 pero si se reduce la resolución a 300dpi.\nAlising\nEn general, durante el proceso de generación del gráfico, cada pixel se calcula de manera exacta, sin embargo esto no es conveniente para los efectos estéticos, debido a efecto de alising, especialmente cuando lo que se despliega en la imagen son trayectorias o líneas. El Alising es el ese tipo de efecto de escalera que tienen la líneas cuando se dibujan de forma oblicua.\nPara reducir este problema se utiliza una técnica llamada anti-alising que consisten en dibujar los pixeles con cierto grado de transparencia dependiendo que tan cercanos están de la línea imaginaria central que podemos trazar en cualquier línea gráfica, haciendo que el trazo parezca suave en lugar de escalonado. Para esto se requiere acceder a las primitivas de despliegue gráfico del sistema operativo. No todos los sistemas soportan este tipo de primitivas, uno de ellos es GNOME con la librería de gráficos vectoriales llamada cairo. Por suerte, es posible incorporar su uso desde R a través del paquete “cairo”, y luego incluyendo el parámetro “type” en la función png():\ninstall.packages(\"cairo\")\nlibrary(cairo)\npng(filename=\"graphic.png\", units=\"in\", width=23.4, height=16.5, res=600, type=\"cairo-png\")\n    codigo de generación de la imagen aqui...\ndev.off()\nLayout de impresión\nEn muchos centros de impresión tienen el mismo precio, imprimir un pliego de tamaño A2 que uno de tamaño A0. En este caso es mucho más inteligente aprovechar todo el pliego A0, en el cual caben varias combinaciones (dos hojas A1, un A1 y dos A2 o cuatro A2). Para esto basta con ubicar nuestras imágenes en los tamaños y posiciones correctas.\n\nEsta tarea suele ser sencilla, el tema es que si nuestras imágenes son muy pesadas podríamos tener problemas para cargar varias de ellas en un software de dibujo cualquiera. Mi recomendación es utilizar herramientas de transformación de gráficos raster en línea de comandos, estoy hablando específicamente de imagemagick, software libre que podemos instalar en cualquier sistema operativo. Esta herramienta incluye un comando llamado convert que tiene entre su parámetros el append y rotate, que podemos usar para disponer adecuadamente nuestras imágenes en un formato A0.\nPor ejemplo si disponemos de 4 archivos de imágenes tamaño A2: clifford1.png y clifford2.png con orientación vertical, y dos imágenes lorenz1.png y mandelbrot1.png con orientación apaisada,\npodríamos usar el comando convert, para generar a partir de estos 4 archivos, uno solo en formato A0:\nconvert.exe +append clifford1.png Clifford2.png image01.png\nconvert.exe -append Mandelbrot1.png lorenz1.png image02.png\nconvert.exe -rotate 90 image02.png image03.png\nconvert.exe -append image01.png image03.png image04.png\n\n\n\n",
    "preview": "posts/2020-09-07-imgenes-de-fractales-en-gran-formato-con-r/../../images/fractales_galery.png",
    "last_modified": "2021-04-29T06:46:20+00:00",
    "input_file": {},
    "preview_width": 627,
    "preview_height": 318
  },
  {
    "path": "posts/2020-09-07-el-arte-del-movimiento-catico/",
    "title": "El arte del movimiento caótico",
    "description": "Un factor común de la mayoría de los fractales, es su poder de atraernos, de casi hipnotizarnos por su particular belleza, tal como si fueran verdaderas obras de arte. Los atractores de Clifford son un ejemplo del arte que puede representar el movimiento de los sistemas caóticos. De hecho, he comenzado preparar varios de estos gráficos en alta resolución, para compartirlos con ustedes y puedan ser impresos como posters si lo desean.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://example.com/josersosa"
      }
    ],
    "date": "2020-03-19",
    "categories": [
      "Chaos and Fractals",
      "Computer Graphics"
    ],
    "contents": "\nUn factor común de la mayoría de los fractales, es su poder de atraernos, de casi hipnotizarnos por su particular belleza, tal como si fueran verdaderas obras de arte. Los atractores de Clifford son un ejemplo del arte que puede representar el movimiento de los sistemas caóticos.\nPéndulo Caótico\nRecordando el efecto mariposa, el péndulo doble es uno de los sistemas caóticos más simples. Si se lanza, dando posiciones iniciales ligeramente diferentes cada vez, se obtienen trayectorias completamente distintas.\nAtractores de Clifford\nOtras dinámicas inspiradas en este tipo de sistemas son las que generan los atractores de Clifford: \\[\nx_{n+1} = sin (a~y_n ) + c~cos (a~x_n ) \\\\\ny_{n+1} = sin (b~x_n ) + d~cos (b~y_n )\n\\]\nCon solo variar los parámetros a,b,c, y d es posible obtener una infinidad de atractores de increíble rareza y particular belleza, casi cómo si fueran verdaderas obras de arte. Haciendo algunas simulaciones en las que dibujamos las trayectorias con un poco de transparencia, es fácil notar que para ciertos parámetros,\nAtractor de Clifford\n\nse obtienen estructuras en las que las trayectorias tienden a cubrir todo el espacio de posibilidades, sin embargo la distribución no es uniforme.\nAlgunas trayectorias son mas probables que otras. Lo que se puede observar por la intensidad de esos trazos, gracias a ellas\nse generan imágenes que aparentan tener volumen tridimensional, a pesar de estar definidas y construidas y en 2 dimensiones.\nClifford Alan Pickover es un científico que dedicó gran parte de su vida a la divulgación de la ciencia, la visualización científica , al arte computacional y a las matemáticas recreativas. En sus propias palabras, planteó que “los datos … proliferan a un ritmo increíble, si los humanos intentan leer dichos datos en forma de números y letras, tomarán la información al ritmo de un caracol. Sin embargo, si la información se presenta gráficamente, los analistas humanos pueden asimilarla y obtener información mucho más rápido”1. En muchos sentidos, sus trabajos funcionaron para impulsar el “el arte y la ciencia de hacer visibles los trabajos invisibles de la naturaleza”2.\n\n\n\n",
    "preview": "posts/2020-09-07-el-arte-del-movimiento-catico/../../images/Clifford_peq_yelow02.png",
    "last_modified": "2021-03-14T17:00:32+00:00",
    "input_file": {},
    "preview_width": 595,
    "preview_height": 419
  },
  {
    "path": "posts/2020-09-07-el-infinito-detalle-del-conjunto-de-mandelbrot/",
    "title": "El infinito detalle del conjunto de Mandelbrot",
    "description": "La convergencia de los sistemas dinámicos complejos es un problema recurrente en muchos campos, su predictibilidad  en algunos casos pudiera estar involucrada con los conceptos de la geometría fractal y la teoría del caos. Escribí una breve reseña sobre uno de los fractales más conocidos vinculados con este tema: el conjunto de Mandelbrot.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://example.com/josersosa"
      }
    ],
    "date": "2020-02-28",
    "categories": [
      "Chaos and Fractals",
      "Computer Graphics",
      "Data Science"
    ],
    "contents": "\n¿Cuánto mide la costa de Gran Bretaña? Parece una pregunta simple, pero su respuesta sorprendió a Benoît B. Mandelbrot: depende de cuán cerca se mire, “aquí hay una pregunta, un elemento básico de la geometría de la escuela primaria que, si lo piensas, es imposible” - dijo - “la longitud de la costa, en cierto sentido, es infinita”1.\nVeámoslo de la siguiente forma, pareciera sencillo medir la longitud en un mapa, pero si nos acercamos a ver con mayor detalle, descubriremos que no tomamos en cuenta muchos dobleces y cuencas, es decir que en realidad la distancia es un poco mayor de lo que creíamos. Pues bien, este efecto se repetirá siempre que veamos el mapa con mayor detalle, y es precisamente lo que ocurre con muchos objetos de la naturaleza, como las montañas, las nubes y en las matemáticas, cómo lo descubrió Mandelbrot con el conjunto que ahora lleva su nombre:\n\nEste objeto formado por todos los valores de condiciones iniciales para los cuales una determinada dinámica converge, nos muestra el infinito detalle que separa los valores que nos llevan a la convergencia, de aquellos que la hacen divergir: \\[\nz_{n+1}=z_n^2+c\n\\] Sorprende cómo una dinámica tan simple pueda generar una imagen tan fascinante, que muestra propiedades tan extrañas como la auto-similitud, vemos como las mismas formas se repiten y reaparecen a diferentes escalas.\nLa aparente contradicción entre la longitud del conjunto y su infinito detalle se resolvió con una sorprendente idea: este objeto no está en 2 dimensiones, evidentemente tampoco en 3, sino que pertenece a algún punto entre la 2da y 3ra dimensión, es decir, que pertenece a una dimensión fraccionaria o dimensión fractal, y de aquí, el por qué objetos como este adoptaron el nombre de Fractales. Piénsenlo bien, un perímetro o distancia es una medida unidimensional, calculada sobre un mapa (bidimensional), sin embargo, este objeto tiene un poco más de dos dimensiones por eso es imposible calcular su perímetro de manera exacta.\n\n¿Cuando y por qué algunas dinámicas matemáticas convergen mientras otras divergen?, o más aún ¿porque algunas dinámicas convergen bajo ciertas condiciones iniciales y divergen en otras? Como ven, la respuestas pueden llegar a ser más complejas de lo que pensábamos. Cuando estamos cerca del borde del conjunto, un punto podría converger mientras que otro infinitesimalmente cercano podría no hacerlo, en esta región se comporta como un sistema caótico.\nEstas son preguntas importantes cuando, por ejemplo, trabajamos en el entrenamiento de modelos de inteligencia artificial, en los cuales solemos usar algoritmos de entrenamiento o dinámicas como el descenso del gradiente. Esto respondería cuestiones como el por qué algunos sistemas tienen la capacidad de “aprender” mientras que otros no. O visto de otra forma, cómo diseñar sistemas de aprendizaje automático cuya dinámica de entrenamiento nos garantice la convergencia, es decir, aprender.\n\n\n\n",
    "preview": "posts/2020-09-07-el-infinito-detalle-del-conjunto-de-mandelbrot/../../images/Mandelbrot_red_peq.png",
    "last_modified": "2021-06-29T18:36:46+00:00",
    "input_file": "el-infinito-detalle-del-conjunto-de-mandelbrot.knit.md",
    "preview_width": 595,
    "preview_height": 419
  },
  {
    "path": "posts/2020-09-07-atractor-de-lorenz-y-el-efecto-mariposa/",
    "title": "Atractor de Lorenz y \"el efecto mariposa\"",
    "description": "El aparente desorden o aleatoriedad de los sistemas caóticos, es en realidad orden, tan exacto y matemático como impredecible e inexplicable. Escribí una breve reseña de una historia que vi cuando estudiaba en la universidad, sobre una de las características más interesantes de la teoría del caos: \"el efecto mariposa\".",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://example.com/josersosa"
      }
    ],
    "date": "2020-02-26",
    "categories": [
      "Chaos and Fractals",
      "Computer Graphics",
      "Data Science",
      "Simulation"
    ],
    "contents": "\nEn 1963 el matemático y meteorólogo Eduard N. Lorenz estaba experimentando con unas ecuaciones diferenciales ordinarias en un intento por simular una versión simplificada de una dinámica del clima. \\[\n\\begin{aligned}\n\\dot{x} & = \\sigma(y-x) \\\\\n\\dot{y} & = x(\\rho - z) - y \\\\\n\\dot{z} & = xy -\\beta z\n\\end{aligned}\n\\] En medio de la simulación, cuyos resultados se tenían que imprimir porque no se podían guardar en disco por esa época, se fue la luz. Una vez reestablecido el sistema, decidió continuar con la simulación pero no comenzando desde el principio, sino que tomó las condiciones iniciales en un punto intermedio de la secuencia que ya había creado. De esa forma ahorraría papel, tiempo y podría verificar que el sistema evolucionaría de la misma manera que lo había hecho antes. Sin embargo esto que parecía obvio, no ocurrió. Al cabo de un tiempo las secuencias original y la nueva comenzaron a separarse, y mucho. Se hicieron pruebas para intentar descubrir donde estaba el error, pero el hecho es que tanto el primer cálculo como el segundo seguían perfectamente las ecuaciones. El análisis gráfico mostró lo que realmente estaba ocurriendo:\n\nSin importar las condiciones iniciales que se escojan el resultado es el mismo\nLas tres variables, juntas en un gráfico de tres dimensiones, siempre tenderán a formar la figura de un atractor extraño de dos discos en 3D, que ahora conocemos como el atractor de Lorenz,\nSin embargo, estas trayectorias no son cíclicas, ya que estos caminos nunca se repiten.\nPor muy parecidas que sean dos trayectorias, estas tenderán a separarse radicalmente tarde o temprano, de hecho\nbasta una mínima diferencia “infinitesimal” entre lo dos caminos para que esto ocurra, que fue justamente lo que pasó en el experimento original, donde la variación estuvo en el orden de los decimales que no se pudieron imprimir.\nInspirado en la forma de este atractor extraño, Lorenz le dio nombre al famoso postulado de la teoría del caos: \"El efecto mariposa que dice que hasta el aleteo de una mariposa podría desencadenar eventos catastróficos en otra arte del mundo, como una poderosa tormenta.\n\nEsta imagen muestra como las trayectorias forman una patrón pero sin llegar a tocarse. Las líneas tienen el ancho de un pixel con anti-alising para maximizar el detalle en la versión impresa.\n\nEn esta imagen de detalle del atractor se observan trayectorias que parecen venir juntas y comienzan a separarse, algunas continúan en el mismo disco y otras pasan al otro.\nEs impresionante ver como esta complejidad pueda surgir de ecuaciones tan simples. Nos hace pensar que muchos fenómenos de la naturaleza aparentemente aleatorios pudieran ser caóticos, es decir, regidos por reglas matemáticas, y de ser así, sería más impactante aún, tener que aceptar que aunque conociéramos las ecuaciones que rigen a la naturaleza o el universo, no podríamos usarlas para predecir el futuro, ya que tendríamos que poder medir con infinita precisión el valor de las variables involucradas.\nEl aparente desorden o aleatoriedad de los sistemas caóticos, es en realidad orden, tan exacto y matemático como impredecible e inexplicable.\n\n\n\n",
    "preview": "posts/2020-09-07-atractor-de-lorenz-y-el-efecto-mariposa/../../images/lorenz_yelow11-10mm_peq.png",
    "last_modified": "2021-05-03T22:02:31+00:00",
    "input_file": {},
    "preview_width": 594,
    "preview_height": 420
  },
  {
    "path": "posts/2021-04-29-sincronizacin-de-directorios-con-rsync/",
    "title": "Sincronización de directorios con rsync",
    "description": "Si bien, herramientas de control de versiones y el uso de la nube ayudan a centralizar nuestra información, no todo está en la nube y la sincronización de archivos entre diferentes equipos y ambientes de trabajo puede convertirse en un problema, para eso podemos usar rsync.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2015-10-19",
    "categories": [
      "Linux Recipes",
      "Rsync"
    ],
    "contents": "\n\nContents\nComo se usa rsync\nSincronización completa\nTransferencia comprimida\nSincronización remota con SSH\nExcepciones en la sincronización\nComo se decide que archivo debe ser actualizado?\nEjemplos\nTODOs\n\nDesde que vengo trabajando remoto utilizo indistintamente diferentes equipos, el personal y el de la oficina. Esto ha provocado que la sincronización de mis archivos se haya convertido en un verdadero problema, que he resuelto con rsync.\nComo se usa rsync\nPara actualizar los contenidos de una carpeta basados en los contenidos de otra utilizamos:\n\nrsync -rtvu carpeta_origen/ carpeta_destino/ \n\nUna vista de los parámetos de rsync:\n\n-v, –verbose    : verbose output\n-q, –quiet      : suppress message output\n-a, –archive    : archive files and directory while synchronizing ( -a equal to following options -rlptgoD)\n-r, –recursive  : sync files and directories recursively\n-c, --checksum  : skip based on checksum, not mod-time & size\n-b, –backup     : take the backup during synchronization\n-u, –update     : don’t copy the files from source to destination if destination files are newer\n-l, –links      : copy symlinks as symlinks during the sync\n-n, –dry-run    : perform a trial run without synchronization\n-e, –rsh=COMMAND: mention the remote shell to use in rsync. By example use '-e ssh'\n-z, –compress   : compress file data during the transfer\n-h, –human-readable: display the output numbers in a human-readable format\n-P : Resume large file transfer after getting failed in scp\n-f : for include o exclude files o directories, example -f\"+ */\" -f\"- *\" for sync the directory structure without copying files\n--include   : to specify those files or directories which you want to include in your sync \n--exclude   : exclude files and folders with you don’t want to be transferred.\n--delete    : if a file or directory not exist at the source, but already exists at the destination, delete that existing file/directory at the target\n--max-size= : put limit on file transfer size. To specify the size in KB use K, MB use M and for GB use G (ej: --max-size='500K')\n--bwlimit=  : put restriction on data transfer speed in KB/s (ej: --bwlimit=600)\n–progress       : show the sync progress during transfer by file\n-e : To specify a protocol with rsync, by example using “ssh”\n\nSincronización completa\nEn el caso de que necesitemos remover los archivos que fueron borrados de la carpeta origen en la carpeta destino, es decir cuando queremos que las dos carpetas (origen y destino) sean idénticas, debemos utilizar el parámetro - -delete, esto usado en conjunto con el parámetro previo -u que actualiza los archivos modificados nos permite mantener dos carpetas en sincronía ahorrando ancho de banda.\n\nrsync -rtvu --delete carpeta_origen/ carpeta_destino/\n\nTransferencia comprimida\nPara ahorrar algo de ancho de banda, y usualmente también ahorrar algo de tiempo, podemos comprimir la información que está será transferida, para esto agregamos el parámetro -z a rsync:\n\nrsync -rvz carpeta_origen/ carpeta_destino/ \n\nSincronización remota con SSH\nPara actualizar los archivos de una carpeta local a una carpeta remota, utilizando un dominio, una dirección de IP o un servidor definido en el archivo de configuración de SSH:\n\nrsync -rtvz carpeta_origen/ usuario@dominio:/ruta/a/carpeta_destino/\n\nAhora para actualizar archivos de una carpeta remota a carpeta local, utilizando un dominio, una dirección de IP o un servidor definido en el archivo de configuración de SSH:\n\nrsync -rtvz usuario@dominio:/ruta/a/carpeta_origen/ carpeta_destino/\n\nExcepciones en la sincronización\nEl parámetro - -exclude seguido del directorio o el archivo que queremos excluir nos permite definir directorios/archivo que no serán sincronizados. La carpeta de origen o la carpeta de destino pueden ser un directorio local o un directorio remoto como se explico en la sección previa.\n\nrsync -rtv --exclude 'directorio' carpeta_origen/ carpeta_destino/\nrsync -rtv --exclude 'archivo.txt' carpeta_origen/ carpeta_destino/\nrsync -rtv --exclude 'direccion/a/directorio' carpeta_origen/ carpeta_destino/\nrsync -rtv --exclude 'direccion/a/archivo.txt' carpeta_origen/ carpeta_destino/ \n\nTambién podemos colocar la lista de directorios o archivos que deseamos excluir en una archivo de texto (por ejemplo excluidos.txt) y usar la opción –exclude-from de la siguiente forma:\n\nrsync -rvz --exclude-from 'excluidos.txt' carpeta_origen/ carpeta_destino/\n\nComo se decide que archivo debe ser actualizado?\nPor defecto, rsync toma la fecha de la última modificación del archivo y el tamaño de este para decidir que archivos necesitan ser transferidos y que archivos pueden ser ignorados, pero podemos utilizar en lugar de este método un hash para decidir si el archivo es diferente o no. Para hacer esto necesitamos usar el parámetro -c, que realizará un checksum en los archivos a ser transferidos. Esto ignorará cualquier archivo donde el checksum coincide.\nEjemplos\nAquí tengo algunos ejemplos de como realizo la sincronización de archivos desde una pendrive hacia el disco duro:\n\nrsync -rvuc /media/716D-15A9/Sincronizar/ /media/LOCAL/Personal/Sincronizar/\n\nIgual que el anterior pero ahora hacia el disco duro de una máquina remota en la red local, con el IP 192.168.0.100 y utilizando el usuario User usando el protocolo SSH:\n\nrsync -rvuc /media/716D-15A9/Sincronizar/ User@192.168.0.100:/media/LOCAL/Personal/Sincronizar/\n\nTODOs\nAhora queda pendiente automatizar este proceso, de forma que cuando se introduzca cierto pendrive en un equipo se ejecute un script que consulte al usuario si desea que este sea sincronizado en ese computador. Esta acción podría realizarse tanto al momento de insertar el pen como al momento de solicitar su extracción.\nFuente de este post\nhttp://www.jveweb.net/archivo/2010/11/sincronizando-carpetas-con-rsync.html\nhttps://www.linuxtechi.com/rsync-command-examples-linux/\nhttps://www.computerhope.com/unix/rsync.htm\nhttps://www.geeksforgeeks.org/rsync-command-in-linux-with-examples/\n\n\n\n",
    "preview": "posts/2021-04-29-sincronizacin-de-directorios-con-rsync/../../images/edex-ui.png",
    "last_modified": "2021-08-10T01:45:55+00:00",
    "input_file": "sincronizacin-de-directorios-con-rsync.utf8.md",
    "preview_width": 800,
    "preview_height": 450
  },
  {
    "path": "posts/2021-04-29-programando-en-r-taller-interactivo/",
    "title": "Taller interactivo: Programando en R",
    "description": "Aún hoy en día, existe mucho contenido para la formación en Ciencia de Datos y particularmente sobre R en diversos formatos y repositorios, sin embargo, la mayoría de ellos están en ingles...",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://example.com/josersosa"
      }
    ],
    "date": "2015-10-11",
    "categories": [
      "R",
      "Data Science",
      "Teaching"
    ],
    "contents": "\n\nContents\n¿Que es Swirl?\nObjetivo\nPrerrequisitos\n¿Como ejecutar el curso?\nAvance del proyecto\n\nVideo explicativo…\nTODOs\n\n¿Que es Swirl?\nEl paquete de R swirl(“Learn R, in R”) permite crear cursos interactivos que se ejecutan desde la propia consola de R, por lo cual el estudiante puede ejecutar la instrucciones directamente en R en la medida que avanza su curso. Existen varios cursor en el repositorio de swirl, pero todos están en ingles.\nObjetivo\nEl objetivo de este proyecto es disponer un curso interactivo sobre los fundamentos de la programación en R, en el idioma español para aquellos hispanohablantes interesados en aprender este lenguaje de programación. Para esto se traducirá el curso R_Programming_Alt del swirl.\nPrerrequisitos\nPara acceder a este curso debes tener instalado el R, y preferiblemente Rstudio, así como el paquete swirl. Puedes instalarlo desde la consola de R así:\n\n\ninstall.packages('swirl')\n\n\n\n¿Como ejecutar el curso?\nPara realizar este curso debemos primero instalarlo desde su repositorio en github, en la consola de R, así:\n\n\nlibrary(swirl)\ninstall_course_github('josersosa','Programando_en_R')\n\n\n\nY lo iniciamos con:\n\n\nswirl()\n\n\n\nAl comienzo nos solicita un nombre para identificarnos y almacenar los avances que hagamos en el caso que deseemos pausar el curso. Las primeras informaciones estan en ingles porque provienen del paquete swirl. Luego seleccionamos el curso Programando en R y a partir de ahí todo lo esencial estará traducido.\nPor último, cuando hayamos terminado, podemos desinstalar el curso con:\n\n\nuninstall_course(\"Programando_en_R\")\n\n\n\nAvance del proyecto\nHasta ahora, este proyecto tiene una avance del 100% en la traducción. Están traducidas todas las lecciones de un total de las 12 del curso original R_Programming_Alt. Ya se han incluido la lecciones extraspara hacer nuestro curso en español un poco más completo:\nWorkspace_and_Files.\nFunctions.\nBase_Graphics. Se incluyó la función barplot y algunos comentarios\nVideo explicativo…\nAquí le dejo un breve video de como utilizar este curso interactivo desde RStudio:\n\n\n\n\n\n\n\nTODOs\nReconfigurar los directoris con los títulos en español.\nIncluir las lecciones del curso R Programming de swirl para hacer nuestro curso en español un poco más completo:\nWorkspace_and_Files.\nFunctions.\nBase_Graphics.\nPor otra parte, intentaré incluir al final de cada lección, aparte del envío del correo, la opción de calificar mediante una conexión a alguna aula virtual o marketplace de cursos en línea.\n\n\n\n",
    "preview": "posts/2021-04-29-programando-en-r-taller-interactivo/../../images/R-Programming-Language.jpg",
    "last_modified": "2021-06-29T19:33:11+00:00",
    "input_file": "programando-en-r-taller-interactivo.knit.md"
  },
  {
    "path": "posts/2021-05-03-edicin-de-videos-en-lnea-de-comandos-con-ffmpeg/",
    "title": "Edición de videos en línea de comandos con FFmpeg",
    "description": "Hace algún tiempo utilicé [FFmpeg](http://www.ffmpeg.org/) para la automatización de la grabación de algunos tutoriales y por eso quedé con la inquietud de crear un breve turtorial con algunas de sus principales funciones.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2013-11-10",
    "categories": [
      "Linux Recipes",
      "FFmepg"
    ],
    "contents": "\n\nContents\nComponentes de FFmpeg\nParámetros de uso del ffmpeg\n\nEjemplos de uso de ffmepg.\nGrabación de la entrada de video de la WebCam\nDos formas de grabación de sonido, usando OSS o ALSA\nConversión de formatos de audio, por ejemplo de wav a ogg\nConversión de formatos de video\nConversión de video a imágenes, este ejemplo creará 25 imágenes por segundo\nConversión de imágenes a video\nDos formas de grabación de la entrada de video y audio por la WebCam y el micrófono\nConvertir video a imágenes animadas GIF\nConvertir GIF a video\nUnir audio y video\nConcatenar videos\nConcatenar varios videos haciendo recodificación\nCambiar resolución de video\nCortar un video\nTrabajar por lotes\nRedimensionar video agregando un marco negro\nRotar videos\n\nGrabación de la pantalla del escritorio Linux con sincronización del audio y el video (ScreenCast):\nAutomatización de la producción de ScreenCast:\nEl script para iniciar el screencast\nEl script para finalizar el screencast\n\nEl efecto Chroma key\nEjemplos de uso ffplay.\nDespliegue de la entrada de video de la WebCam:\nPara simplemente reproducir un video:\n\nStreaming de video con ffserver.\nCompilando ffmpeg desde las fuentes.\nFuentes.\n\nFFmpeg es un completo y muy avanzado conjunto de herramientas de software libre orientadas al procesamiento de video desde consola. Contempla aplicaciones para la grabación, reproducción, conversión, transcodificación y streaming de video. Además contiene un amplio conjunto de codecs y librerías de audio y video que lo convierten en una herramienta de desarrollo indispensable, así como tremendamente útil para la creación y manipulación de nuestros videos, la extracción o incorporación de audio, transferencia de video por red (streaming) e incluso la creación de ScreenCast para videotutoriales.\ngif de ejemplo del efecto chroma key con ffmpegComponentes de FFmpeg\nEl proyecto FFmpeg viene con varios programas pero podríamos decir que los más importantes son ffmpeg, ffserver y ffplay.\nParámetros de uso del ffmpeg\nEl ffmpeg esta orientado fundamentalmente la grabación, transcodificación y conversión de videos. Permite entre otras cosas, convertir entre una amplia gama de formatos, pasando por la extracción de imágenes y sonido de nuestros videos o la conversión de imágenes indexadas a videos. Los principales parámetros de este programa son:\n-i dispositivo de entrada tanto para vídeo como para audio.\n-f formato de entrada de vídeo o de audio.\n-r n consigue que se haga la grabación n fotogramas por segundo.\n-b se usa para estipular la tasa de bits por segundo a usar en la salida ya sea de vídeo o sonido, ejemplo: -b 128k.\n-sameq consigue que se haga la captura con la misma calidad que tenga la propia entrada. Haciendo que la tasa de bits por segundo de la salida sea la necesaria como para que no sea apreciable ninguna pérdida de calidad con respecto a la entrada. Si usas esta opción, no es necesario usar -b.\n-async n para conseguir una buena sincronización del sonido de entrada y la imagen. De este modo, si grabamos nuestra voz mientras grabamos el vídeo veremos como nuestras palabras van en sincronía con el vídeo.\n-s tamaño o resolución de la captura de pantalla, puede ser indicado de la forma 640x480 o bien su equivalente vga. El listado completo de resoluciones admisibles es el siguiente:\n  wsxga: 1600×1024\n  wuxga: 1920×1200\n  woxga: 2560×1600\n  wqsxga: 3200×2048\n  wquxga: 3840×2400\n  whsxga: 6400×4096\n  whuxga: 7680×4800\n  cga: 320×200\n  ega: 640×350\n  hd480: 852×480\n  hd720: 1280×720\n  hd1080: 1920×1080\n  16cif: 1408×1152\n  qqvga: 160×120\n  qvga: 320×240\n  vga: 640×480\n  svga: 800×600\n  xga: 1024×768\n  uxga: 1600×1200\n  qxga: 2048×1536\n  sxga: 1280×1024\n  qsxga: 2560×2048\n  hsxga: 5120×4096\n  wvga: 852×480\n  wxga: 1366×768\n  sqcif: 128×96\n  qcif: 176×144\n  cif: 352×288\n  4cif: 704×576\nEjemplos de uso de ffmepg.\nA continuación podemos ver algunos ejemplos del uso de estas herramientas:\nGrabación de la entrada de video de la WebCam\nffmpeg -f video4linux2 -s 320x240 -i /dev/video0 -sameq ./out.mpg\nDos formas de grabación de sonido, usando OSS o ALSA\nffmpeg -f oss -i /dev/dsp salida.mpg\nffmpeg -f alsa -i plughw:1,0 salida.mpg\nConversión de formatos de audio, por ejemplo de wav a ogg\nffmpeg -i my_audio.wav my_audio.ogg\nConversión de formatos de video\nffmpeg -i my_video.flv my_video.mpeg\nffmpeg -i my_video.mpeg -s 500×500 my_video.flv\nffmpeg -i input_file_name.mp4 -vcodec flv -ar 22050 output_file_name.flv\nCuando convertimos videos a formatos comprimido es posible que se reduzca la calidad de la imagen, para evitar esto podemos usar el parámetro -qscale 0 donde el cero indica que se debe mantener la calidad en la medida de lo posible:\nffmpeg -i my_video.avi -qscale 0 my_video.mp4\nConversión de video a imágenes, este ejemplo creará 25 imágenes por segundo\nffmpeg -i test.mpg -r 25 image%d.jpg\nffmpeg -i test.mpg -r 25 -ss 00:00:10 -t 00:00:05 images%05d.png\nConversión de imágenes a video\nffmpeg -f image2 -i img%d.jpg /tmp/a.mpg\nDos formas de grabación de la entrada de video y audio por la WebCam y el micrófono\nffmpeg -f video4linux2 -s 320x240 -i /dev/video0 -f audio_device -ac 2 -i /dev/dsp1 -f mp4 Filename.mp4\nffmpeg -f oss -i /dev/dsp -f video4linux2 -s 320x240 -i /dev/video0 out.mpg\nConvertir video a imágenes animadas GIF\nffmpeg -ss 7.0 -t 5.5 -i video.mp4 -f gif image.gif\nEntonces, con estos dos argumentos, FFmpeg buscará segundo 7.0 y leerá en los próximos 5.5 segundos para la creación del GIF. Otra forma de hacer esto para lograr un mejor resultado es combinar FFmpeg con Imagemagick en el siguiente pipeline:\nffmpeg -i video.mp4 -vf \"fps=10,scale=320:-1:flags=lanczos\" -c:v pam -f image2pipe - | convert -delay 10 - -loop 0 -layers optimize output.gif\nConvertir GIF a video\nffmpeg -i image.gif -f mp4 -pix_fmt yuv420p video.mp4\nEntonces, con estos dos argumentos, FFmpeg buscará segundo 7.0 y leerá en los próximos 5.5 segundos para la creación del GIF.\nUnir audio y video\nffmpeg -i audio.mp3 -i video.mpg -sameq video.mkv\nffmpeg -i audio.mp3 -i video.mpg -sameq video_result.mpg\nConcatenar videos\nffmpeg -f concat -i file video1.mpg file video2.mpg -c copy video.mpg \nffmpeg -i \"concat:video1.mpg|video2.mpg\" -c copy video.mpg\nffmpeg -i \"concat:$1|$2\" -c copy $3\nffmpeg -f concat -safe 0 -i video.txt video.mp4\nConcatenar varios videos haciendo recodificación\nffmpeg -i video1.mp4 -i video2.mp4 -i video3.mp4 \\\n  -filter_complex '[0:v:0] [0:a:0] [1:v:0] [1:a:0] [2:v:0] [2:a:0] concat=n=3:v=1:a=1 [v] [a]' \\\n  -map '[v]' -map '[a]' output2.mkv\nCambiar resolución de video\nffmpeg -i video.mp4 -vf scale=1280:766 video_1280x766.mp4 -hide_banner -qscale 0\nffmpeg -y -i video.mp4 -vf scale=1440:900,setsar=1:1 -c copy video2.mp4 -hide_banner\nCortar un video\nffmpeg -i video.mpg -ss 00:00:02.000 -to 00:00:42.068 -c copy -copyts video_corto.mpg\nTrabajar por lotes\n# Conversión de formato por lotes\nfor FILE in *.{AVI,mpg} ; do \\\\\n    NAME=`echo \"$FILE\" | cut -d'.' -f1`; \\\\\n    ffmpeg -i $FILE -qscale 0 $NAME.mkv; \\\\\n    done\nRedimensionar video agregando un marco negro\n-vf \"scale=640:-1\" \n-vf \"scale=640x360,pad=640:480:0:60:black\"\nffmpeg -i input.jpg -vf scale=w=320:h=240:force_original_aspect_ratio=decrease output_320.png\nffmpeg -y -i video.mp4 -aspect 16:9 scale=640x360,pad=640:480:0:60:black video_2.mp4\nffmpeg -i video.mp4 -vf scale=640:480,pad=1024:600:192:60:black -qscale 0 video_2.mp4\n/opt/ffmpeg/ffmpeg -i CIMG1169_.mp4  -vf scale=800:600,pad=1024:600:112:0:black  CIMG1169_2.mp4\nRotar videos\nffmpeg -i original.avi -vf \"transpose=1\" resultado.avi\nEl valor del parámetro transpose indica el tipo de transformación, siendo 1 una rotación de 90 grados en el sentido de las agujas del reloj. El valor 2 giraría 90 grados en sentido contrario.\nPara el parámetro de transposición puede pasar:\n0 = 90CounterCLockwise and Vertical Flip (default)\n1 = 90Clockwise\n2 = 90CounterClockwise\n3 = 90Clockwise and Vertical Flip\nÚselo -vf \"transpose=2,transpose=2\"para 180 grados. Otras dos transformaciones interesantes en esta misma línea que podemos aplicar mediante el argumento -vf son mirror y flip. Si queremos girar el vídeo 180 grados podemos aplicarlas ambas de modo conjunto (-vf mirror,flip).\nGrabación de la pantalla del escritorio Linux con sincronización del audio y el video (ScreenCast):\nUn ScreenCast es al vídeo lo que un SnapShot (pantallazo o captura de pantalla) a la fotografía. Hay algunos programas que realizan capturas de vídeo de lo que se muestra en nuestra pantalla, unos con mejores resultados que otros y también con mayor o menor dificultad de uso. Ejemplo de ello son Istanbul y RecordMyDesktop, dos soluciones que podrían funcionar muy bien. Sin embargo, no nos permiten grabar sonido de un micrófono mientras graba la pantalla, para por ejemplo dar un videotutorial, cosa que si podemos hacer con FFmpeg. A continuación muestro un ejemplo de como hacer esto, grabando un video de nuestra pantalla a 25 imágenes por segundo. El video se captura desde la esquina superior izquierda de la pantalla, y en este caso, hasta la coordenada 800x600:\nffmpeg -async 1 -f alsa -i plughw:1,0 -f x11grab -s 800x600 -r 25 -i :0.0 -b 128k ./out.mpg\nffmpeg -async 1 -f alsa -i plughw:1,0 -f x11grab -s 800x600 -r 25 -i :0.0 -sameq ./out.mpg\nffmpeg -async 1 -f alsa -i plughw:1,0 -f x11grab -s 800x600 -r 25 -i :0.0 -qscale 0 ./out.mpg\nffmpeg \\ \n    -async 1 \\\n    -f oss \\\n    -i /dev/dsp1 \\\n    -f x11grab \\\n    -s 1024x600 \\\n    -framerate 20 \\\n    -i :0.0 \\\n    -sameq \\\n    /root/video.mpg\nAutomatización de la producción de ScreenCast:\nPara la automatización de nuestros Screecast haremos uso de 2 herramientas (ffmpeg para realizar la captura de la pantalla y xwininfo para obtener las coordenadas y dimensiones de la ventana a grabar). Podemos realizar screencasts utilizando recursos mínimos y obteniendo óptimos resultados.\nEl script para iniciar el screencast\n\\#!/bin/bash\n\n\\# Obtener las coordenadas y el tamaño de la ventana seleccionada\n\\# Esto excluye la decoración de la ventana.\n unset x y w h\n eval $(xwininfo -frame |\n  sed -n -e \"s/^ +Absolute upper-left X: +([0-9]+).*/x=1/p\"\n      -e \"s/^ +Absolute upper-left Y: +([0-9]+).*/y=1/p\"\n      -e \"s/^ +Width: +([0-9]+).*/w=1/p\"\n      -e \"s/^ +Height: +([0-9]+).*/h=1/p\" )\n$w=$w + $w % 2 # que el ancho sea múltiplo de 2, sino ffmpeg se queja\nWIN_XY=$x\",\"$y # dar formato a las coordenadas XY\nWIN_GEO=$w\"x\"$h # dar formato al tamaño de la ventana\n\\# notify-send mostrará un mensaje indicando el inicio del screencast.\n\\# correr ffmpeg con los parámetros que se ajusten a tu configuración.\nnotify-send \"Iniciando screencast...\" && ffmpeg -f alsa -i hw:0 -f x11grab -r 25 -s $WIN_GEO -i :0.0+$WIN_XY -acodec libmp3lame -async 1 -vcodec libx264 -preset ultrafast -crf 0 -threads 0 guardar.mp4\nNo hace falta entender completamente este scripts más allá de que genera una archivo de salida llamado guardar.mp4. Para obtener resultado, sin embargo, es necesario poder hacer ciertos cambios como:.\nSi usás OSS, reemplazaremos -f alsa -i hw:0 por -f oss -i /dev/dsp\nSi usamos solo ALSA, tenés que usar los parámetros que vienen en el script (-f alsa -i hw:0). Para determinar el número que va después de hw: podemos ejecutar aplay -l y elegir el número de la tarjeta de sonido adecuada.\nSi usás Pulse Audio (Ubuntu y derivados usan esto), usá los parámetros -f alsa -ac 1 -i pulse.\nPara varias las cantidad de frames por segundo (FPS): -r 25 indica los fps a los que deseemos grabar. 25 es una buena opción.\nCon respecto al los Códec de audio, video y sincronización\n-acodec libmp3lame es el códec de audio. Lo elegí grabar en mp3. Podemos utilizar cualquier otro.\n-async 1 permite la sincronización del audio con el video.\n-vcodec libx264 -preset ultrafast -crf 0 -threads 0, le indica a ffmpeg que el códec de video a utilizar sea x264 y que el preset sea ultrafast (hay fast, slow, etc), de lo contrario no llega a grabar correctamente a la cantidad de fps deseados. El parámetro -crf 0 indica el nivel de compresión (cuanto más bajo, menor la compresión). Por último, threads 0 indica la cantidad de hilos a utilizar, al pasar 0 ffmpeg lo calcula automáticamente. Al igual que con la configuración de audio, podemos elegir otras opciones.\n\nTodas estas configuraciones fueron las que dieron mejores resultados: un archivo relativamente pequeño, una buena calidad de video, con audio sincronizado y sin lags. No obstante, te recomiendo sumergirte en la documentación de ffmpeg para descubrir otras.\nEl script para finalizar el screencast\n#!/bin/bash\nnotify-send \"Finalizando screencast...\" && killall ffmpeg\nPara que ambos scripts funcionen debemos tener instalado notify-send. La mayoría de las distribuciones deberían venir con esta herramienta instalada. En Arch y derivados: sudo pacman -S libnotify.\nEl efecto Chroma key\n/opt/ffmpeg/ffmpeg \\\n   -i image_fondo.jpg \\\n   -i video.AVI \\\n   -filter_complex \\\n      \"[1:v]chromakey=0x004682:0.15:0.0[keyed]; \\\n      [0:v][keyed]overlay[out]\" \\\n   -map \"[out]\" \\\n   -vcodec libx264 \\\n   -crf 18 \\\n   -preset slower \\\n   video_result.avi \nEjemplos de uso ffplay.\nPor otra parte ffplay fue creado como un reproductor de video. El uso de ffplay es muy simple, aquí podemos ver unos ejemplos:\nDespliegue de la entrada de video de la WebCam:\nffplay -f video4linux2 -i /dev/video0 >/dev/null &\nPara simplemente reproducir un video:\nffplay out.mpg\nStreaming de video con ffserver.\nEl ffserver es una herramienta diseñada para servir el streaming de video, por ejemplo podemos usar la webcam en streaming para poder conectarnos desde cualquier lugar con el smartphone. FFmpeg maneja una gran cantidad de formatos en los que se puede emitir, además de ser relativamente fácil de configurar. La emisión del streaming se basa en el uso de dos programas: ffserver y ffmpeg. El primero se ejecuta en modo escucha y se encarga de hacer el streaming real mientras que el segundo recoge la imagen de alguna fuente y la envía a al primero.\nPara empezar, es necesario crear un archivo de configuración: /etc/ffserver.conf, dejándolo como así:\nPort 8090\nBindAddress 0.0.0.0\nMaxHTTPConnections 2000\nMaxClients 1000\nMaxBandwidth 1000\nCustomLog -\n\n<Feed webcam.ffm>\n  File /tmp/webcam.ffm\n  FileMaxSize 35M\n<\/Feed>\n\n<Stream webcam.swf>\n  Feed webcam.ffm\n  Format swf\n  VideoBitRate 320\n  VideoFrameRate 10\n  VideoSize 640x480\n  NoAudio\n  VideoQMin 1\n  VideoQMax 3\n<\/Stream>\n\n<Stream stat.html>\n  Format status\n<\/Stream>\n\n<Redirect index.html>\n  URL http://www.ffmpeg.org/\n<\/Redirect>\nUna vez configurado, es necesario iniciar el servicio con el comando:\nffserver -f ffserver.conf\nAhora sólo quedaría enviar la imagen al servidor con el comando ffmpeg y se puede utilizar cualquier entrada para redireccionarla al servidor. Por ejemplo, en el caso de una webcam, una capturadora de TV o cualquier entrada de vídeo, el comando sería:\nffmpeg -r 15 -s 320x240 -f video4linux -i /dev/video0 http://localhost:8090/webcam.ffm\nEn algunos casos podemos encontrarnos con este error:\n[flv @ 0x97df6f0]rc buffer underflow VIDIOCMCAPTURE: Invalid argument\nPara solucionar el problema, debemos escribir antes del comando ffmpeg, lo siguiente :\nLD_PRELOAD=/usr/lib/libv4l/v4l1compat.so\nSi todo va bien, podremos ver la imagen emitida con el navegador.\nCompilando ffmpeg desde las fuentes.\nEl sistema FFmpeg viene incluido en casi todos los repositorios oficiales de las principales distribuciones de GNU/Linux, sin embargo no siempre están compilados con todas las funciones que deseamos (con el dispositivo de grabación x11_grab por ejemplo) o, en ocaciones excepcionales, querremos preparar una nueva versión para nuestro sistema operativo. De cualquier modo es importante tener una breve receta de como compilar el FFmpeg desde las fuentes. Lo primero será descargar las fuentes, para esto lo mejor será ir a la zona de descargas de su sitio oficial: www.ffmpeg.org. Para el momento de escribir este artículo, la última versión es http://www.ffmpeg.org/releases/ffmpeg-2.1.tar.gz luego lo descomprimimos en algún directorio temporal, configuramos y compilamos así:\ntar zxvf ffmpeg-2.1.tar.gz\ncd ffmpeg-2.1.tar.gz\n./configure --enable-gpl --enable-version3 --enable-nonfree --enable-postproc --enable-libfaac --enable-libmp3lame --enable-libtheora --enable-libx264 --enable-libxvid --enable-x11grab --enable-libvorbis --enable-libvpx --enable-shared --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libschroedinger --enable-libopenjpeg --enable-runtime-cpudetect\nmake\nmake install\nEs importante verificar antes de compilar que el resultado de la configuración de las fuentes, reconoció como uno más de los dispositivos de grabación incorporados el x11_grab_device dentro de los “Enabled indevs”, debería verse algo así:\nEnabled indevs:\nalsa          oss           v4l2\ndv1394         v4l           x11_grab_device\nEn el caso de sistemas Debian o derivados, antes que nada deberemos actualizar nuestro archivo /etc/apt/sources.list agregando:\ndeb-src http://www.deb-multimedia.org sid main\ndeb http://www.deb-multimedia.org wheezy main non-free\nSalvamos y actualizamos los indices de los paquetes disponibles:\napt-get update\napt-get install deb-multimedia-keyring\nDespués de esto recomiendan borrar la linea deb “http://www.deb-multimedia.org wheezy main non-free” del archivo /etc/apt/sources.list Luego podremos descargar el paquete ya preparado denominado ffmpeg-dmo y luego se procede a compilar como de costumbre:\napt-get install libxfixes-dev\napt-get source ffmpeg-dmo\ncd ffmpeg-dmo-0.11\n./configure\nmake && make install\nFuentes.\nEste post fue realizado sobre la vase de varios artículos publicados y algunas de mis experiencias previas (espero no olvidar ninguna de las fuentes): http://www.juanluperez.com/index.php/2010/09/screencast-con-ffmpeg-y-grabacion-de-microfono/ http://soledadpenades.com/2010/04/26/unknown-input-or-output-format-x11grab-ubuntu/ http://dmnet.bitacoras.com/archivos/software/streaming-de-una-webcam-con-ffmpeg.php http://www.freetux.com.ar/como-grabar-screencast-por-terminal-usando-ffmpeg/ http://sirlagz.net/2012/08/04/how-to-stream-a-webcam-from-the-raspberry-pi/ http://blog.giuseppeurso.net/raspberry-keychain-808-3-as-webcam/index.html http://www.raspberrypi-es.com/category/ffmpeg/ http://soledadpenades.com/2010/04/26/unknown-input-or-output-format-x11grab-ubuntu/ https://engineering.giphy.com/how-to-make-gifs-with-ffmpeg/ https://trac.ffmpeg.org/wiki/Concatenate https://ffmpeg.org/ffmpeg-filters.html#chromakey http://oioiiooixiii.blogspot.com/2016/02/ffmpeg-chromakey-filter-filthy-frank.html http://johnvansickle.com/ffmpeg/ https://blog.unlugarenelmundo.es/2012/12/26/chuletillas-y-xxxvi-rotar-videos-con-mencoder/\n\n\n\n",
    "preview": "posts/2021-05-03-edicin-de-videos-en-lnea-de-comandos-con-ffmpeg/../../images/video-chroma-demo.png",
    "last_modified": "2021-05-16T20:56:53+00:00",
    "input_file": {},
    "preview_width": 929,
    "preview_height": 528
  },
  {
    "path": "posts/2021-05-30-vehiculo-robot-con-lego/",
    "title": "Vehículo Robot con Lego Technic, Minsdstorm y la Raspberry Pi",
    "description": "El pequeño tamaño de la Raspberry Pi y su capacidad de procesamiento abre muchas posibilidades para la robótica, dado que ahora podemos incorporar un completo  computador en nuestros  pequeños robots, dotándolos de la capacidad de procesamiento y  comunicaciones que ofrecen los sistemas operativos modernos.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2013-09-09",
    "categories": [
      "Raspberry Pi",
      "Robotics",
      "Lego",
      "Lego Mindstorm",
      "Python"
    ],
    "contents": "\n\nContents\nControlando un carro robot con la Raspberry Pi\nEl modelo Lego technic 8081 Extreme Cruise\nAgregando motores al Extreme Crouser con el MindStorm\nAdaptando la Raspberry Pi a nuestro vehículo robot.\nLibreria para el control del NXT desde Python: nxt-python\nProgramando nuestro vehículo robot con Python\nEjecución del control de nuestro robot\n\nEste proyecto consiste en adaptar la Raspberry Pi a un vehículo Lego Technic (8081) y motorizado con Mindstorm, para luego programarlo y manejardo por una aplicación hecha en Python.\n\nControlando un carro robot con la Raspberry Pi\nEn otros posts he mostrado como construir robots y como programarlos ocontrolarlos desde dispositivos móviles. Sin embargo una de mis expectativas es poder conectarme vía SSH a los robots y controlar todas sus funciones internas remotamente. Esto implicaría que nuestro robot incluyera un computador corriendo un sistema operativo más completo que el que proporciona el NXT. Esto ahora lo puedo hacer, gracias a la Raspberry Pi. Este proyecto busca adaptar la Raspberry Pi a un vehículo Lego Technic (8081) y motorizado con Mindstorm y manejado por una aplicación hecha en Python, la cual podemos ejecutar y manejar vía SSH. Esta solución es mucho mas efectiva que la de usar una remolque para una netbook como en el experimento de “controlar un carro robot desde una Canaimita” de hace una par de años.\nEl modelo Lego technic 8081 Extreme Cruise\nAunque pudiéramos usar nuestro carro robot de propósito general para este proyecto, he disidido utilizar otro modelo de vehículo, el Extreme Cruise (8081)de Lego Technic que me llego hace poco (lo conseguí bastante barato en Madrid y un amigo me lo trajo). Este modelo de vehículo tiene varias ventajas como la amortiguación y el tamaño de las ruedas que lo convierten en una especie de “todo terreno”. Aunque no trae motores, si posee los mecanismos de dirección delantera y de tracción con diferencial. Con el mismo set se pueden armar dos modelos, aquí dejo las instrucciones (1, 2 y 3) para su ensamblado.\n\nQueda +/- así, aunque no pretendo dejarlo así por mucho rato, la idea es incorporarle la capacidad de movimiento con motores.\n  \nAgregando motores al Extreme Crouser con el MindStorm\nHe aquí donde se integran nuestro modelo 8081 con el Mindstorm. Esta tarea consistió esencialmente en incorporar dos motores, uno para la dirección y otro para la tracción. Este trabajo requirió hacer espacio, quitando el modelo de motor original y los asientos. Por ultimo amplié un poco la parte trasera levantando el techo para que entrara el bloque NXT.\nAquí algunas imágenes de como quedó:\n  \nHasta este punto ya es posible manejar nuestro vehículo a control remoto, utilizando el Bluetooth del NXT desde aplicaciones Android en nuestra Smartphone o tableta tal como lo mencioné antes, sin embargo el objetivo de este proyecto es otro.\nAdaptando la Raspberry Pi a nuestro vehículo robot.\nAhora integraremos la Raspberry Pi con nuestro vehículo. Para esto usaremos unos pocos componentes. Junto con la Raspberry Pi necesitaremos:\n\nUn dungle Wifi USB conectado a la Raspberry Pi para el acceso remoto vía SSH al control del vehículo.\nUna carcasa protectora que facilite la integración del Raspberry con el vehículo Lego\nUna Batería recargable para la alimentación de corriente para el Raspberry Pi, recordemos que le NXT usa pilas AA.\nUn cable USB para conectar las Raspberry Pi con el NXT\nAquí podemos ver algunas imágenes:\n\n\n\n\n\n\n\nLibreria para el control del NXT desde Python: nxt-python\nPara controlar el NXT desde el Raspberry Pi debemos instalar en el, la librería nxt-python. Esta librería tiene un par de dependencias que deberemos instalar previamente, estas son PyUSB y PyBluez, que nos permitirán conectarnos al NXT ya sea por USB o por Bluetooth. para el momento de escribir esto, las últimas versiones eran nxt-python-2.2.2.tar.gz, pyusb-1.0.0a3.zip y PyBluez-0.18.tar.gz que una vez descargadas en un directorio temporal, creamos el grupo “lego” y como root, las podemos instalar así:\nsu -\ncd path_al-dir_de_descarga/\ngroupadd lego\nusermod -a -G lego\nunzip pyusb-1.0.0a3.zip\ncd pyusb-1.0.0a3\npython setup.py install\ncd ..\ntar zxvf PyBluez-0.18.tar.gz\ncd PyBluez-0.18\npython setup.py install\ncd ..\ntar zxvf nxt-python-2.2.2.tar.gz\ncd nxt-python-2.2.2\npython setup.py install\nPara que el sistema identifique correctamente el dispositivonecesitamos agregar esta regla en el udev:\nSUBSYSTEM==\"usb\", ATTRS{idVendor}==\"0694\", GROUP=\"lego\", MODE=\"0660\"\nProgramando nuestro vehículo robot con Python\nEsta es la parte más interesante del proyecto. La mayoría de los lenguajes de programación de propósito especifico para el control del NXT lo modelan como una máquina de estados. Esta concepción facilita el manejo de la concurrencia propia del funcionamiento en paralelo de los efectores o del manejo de las interrupciones asociadas a los registro de los sensores. Sin embargo este no es el caso de los lenguajes de propósito general como C/C++ o Python.\nLa concurrencia en un lenguaje como Python puede ser modelada mediante el uso de hilos de ejecución (threads). Adicionalmente usaremos la librería nxt-python para el control del bloque NXT. Aquí podemos encontrar algunos ejemplos de como emplear esta librería. También dejo aquí el enlace a un buen tutorial de Python.\nEste no fue el enfoque asumido en el proyecto de carro robot controlado por Python, porque no manejaba sensores y la interface era mucho más simple y se basaba en instrucción-acción.\nNuestro ejemplo consta de 3 tipos de funciones. Tenemos el programa principal, que inicializa las variables de estado, instancia las conexiones con el NXT y los hilos de ejecución que activan los efectores. Finalmente el programa principal contiene el ciclo de recepción y despacho de las instrucciones de entrada.\nLas funciones tracción y dirección, son manejadas como hilos de ejecución paralela y se encargan de activar los efectores (motores) y controlar su velocidad. Debido a que es posible que se le vaya colocando más peso a nuestros robots, es preferible usar siempre la máxima potencia (100), de manera que el control de la velocidad de puede realizar por la activación intermitente de los motores, incrementando o reduciendo los espacios de tiempo de inactividad en función de reducir o aumentar la velocidad.\nPor ultimo están las funciones que modifican las variables de estado de manera de variar el estado del sistema y de ejercer control sobre los efectores. Estas funciones son avanzar, retroceder, izquierda y derecha. Próximamente tendremos variables para la gestión de los sensores.\nAquí podemos ver el código de la aplicación en su primera versión (carro01.py)\n#!/usr/bin/env python\n\nimport nxt.locator\nfrom nxt.motor import *\nimport time\nimport thread\nimport consola_io\n\ndef menu():\n print \"\"\"\n\n   Menu de opciones\n   \\----------------\n\n   1.-  Derecha  k\n   2.-  Izquierda  h \n   3.-  Avanzar  j\n   4.-  Retroceder  m   \n   SP.- Mostrar menu\n   ESC.- Terminar s\n \"\"\"\n\n\ndef derecha():\n  Direc[0] = -40\n  print \"Derecha\", Direc[0]\n  time.sleep(0.02)\n  Direc[0] = 0  \n\n\ndef izquierda():\n  Direc[0] = 40\n  print \"Izquierda\", Direc[0]\n  time.sleep(0.02)\n  Direc[0] = 0\n\n\ndef avanzar():\n  if Trac[0] + Trac[1] <= MAXTRAC:\n    Trac[0] = Trac[0] + Trac[1]\n  print \"Avanza \", Trac[0]  \n\ndef retroceder():\n  if Trac[0] - Trac[1] >= -MAXTRAC:\n    Trac[0] = Trac[0] - Trac[1]\n  print \"Retrocede \", Trac[0]\n\ndef detener():\n  motor_traccion = Motor(Brick, PORT_C)\n  Trac[0] = 0\n  motor_traccion.idle()\n  time.sleep(2)\n\n\ndef traccion(string,lock,*args):\n  veloc = Trac[0]\n  motor_traccion = Motor(Brick, PORT_C)\n  while 1:\n    if veloc != Trac[0]:\n      veloc = Trac[0]\n      if veloc == 0:\n        motor_traccion.idle()\n        print \"Detener\"\n      print string,\" Velocidad de traccion: \",veloc\n    if (veloc > 0):\n      motor_traccion.idle()\n      time.sleep((MAXTRAC - abs(veloc))/800.0)\n      motor_traccion.run(-MAXTRAC)  \n    if (veloc < 0):\n      motor_traccion.idle()\n      time.sleep((MAXTRAC - abs(veloc))/800.0)\n      motor_traccion.run(MAXTRAC)\n\n\ndef direccion(string,lock,*args):\n  direcc = Direc[0]\n  motor_direccion = Motor(Brick, PORT_B)\n  while 1:\n    if direcc != Direc[0]:\n      direcc = Direc[0]\n      if direcc == 0:\n        motor_direccion.idle()\n        print \" Detener \",string\n    if (direcc > 0):\n      motor_direccion.idle()\n      time.sleep((MAXDIREC - abs(direcc))/500.0)\n      motor_direccion.run(-MAXDIREC)  \n    if (direcc < 0):\n      motor_direccion.idle()\n      time.sleep((MAXDIREC - abs(direcc))/500.0)\n      motor_direccion.run(MAXDIREC)\n\n\nif __name__==\"__main__\":\n  Brick = nxt.locator.find_one_brick()\n  MAXTRAC = 120\n  MAXDIREC = 100\n  Direc = [0, 20]\n  Trac = [0, 20]\n  lock=thread.allocate_lock()\n  thread.start_new_thread(traccion,(\"Traccion\",lock))\n  thread.start_new_thread(direccion,(\"Direccion\",lock))\n  #-- Sacar menu()\n  menu()\n  #-- bucle principal\n  while 1:\n    #-- Leer tecla\n    c = consola_io.getkey()\n    #-- Procesar tecla\n    if  c=='k': \n      derecha()\n    elif c=='h': \n      izquierda()\n    elif c=='j': \n      avanzar()\n    elif c=='m': \n      retroceder()\n    elif c=='n': \n      retroceder()\n    elif c==' ': \n      detener()\n      menu()\n    elif c=='s': \n      detener()\n      break  #-- Salir del bucle\n  #-- Terminar \n  print \"-- FIN --\"\nEjecución del control de nuestro robot\nSe ejecuta por consola, con lo que podemos acceder a nuestro robot vía SSH y controlar nuestro carro robot a distancia: Siempre que esté al alcance de nuestra red WiFi. Para esto empleé un router inalámbrico TPLink alimentado por la conexión USB de mi laptop. Con los que pude crear una pequeña red local inalámbrica itinerante. Luego configuré mi Raspberry Pi a esta red, de manera que cuando vuelva a arrancar (pero esta vez sin monitor y adherido al carro robot), pueda enlazare con esta red de forma automática. Aquí un pequeño video de su funcionamiento:\n\n \n\n\n\n\n",
    "preview": "posts/2021-05-30-vehiculo-robot-con-lego/../../images/robotics/Raspberry_Pi_P1030182.JPG",
    "last_modified": "2021-07-17T17:07:55+00:00",
    "input_file": "vehiculo-robot-con-lego.utf8.md"
  },
  {
    "path": "posts/2021-06-08-armando-un-media-center-con-la-raspberry-pi-y-xbmc/",
    "title": "Armando un Media Center con la Raspberry Pi y XBMC",
    "description": "Por su pequeño tamaño y su buena potencia, la Raspeberry Pi es útil para todo tipo de soluciones each computing. Veremos como podemos utilizar nuestra Rasperry Pi para construir nuetra propia Media Center para convertir cualquier televisor en un Smart TV, con muchas funcionalidades similares a la Rocu, el Chrome Cast o el Apple TV.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2013-09-03",
    "categories": [
      "Linux Recipes",
      "Raspberry Pi",
      "Media Center",
      "XBMC"
    ],
    "contents": "\n\nContents\nComponenetes del Media Center\nDistros específicas para habilitar un Media Center con XBMC\nAgregando nuevos componentes o addons al XBMC.\nUsando el Media Center.\nControl remoto del XBMC.\nMis próximos proyectos con el Media Center - Raspberry Pi\n\nEsta vez emplearemos nuestra Raspberry Pi para construir un Media Center. Podemos integrar en una misma interfaz, el despliegue de videos y multimedia de varias fuentes como la televisión y el Internet. Existe un proyecto en Software Libre, que tiene esto como objetivo, llamadoXBMC y puede ser extendido mediante la programación de plugins en Python.\nComponenetes del Media Center\nPara armar nuestra Media center necesitaremos los siguientes componentes o periféricos:\nLa Raspberry Pi, por supuesto.\nUna memoria SD de 4Gb o más. Aunque algunas imágenes requieren 1Gb, 2Gb o hasta 4G como mínimo y preferiblemente de Clase 10.\nUn transformador DC de 5v con salida mini-USB.\nUn cable HDMI o RCA para el televisor.\nOpcionalmente un teclado USB o inalámbrico (con receptor USB).\nOpcionalmente un mouse USB o inalámbrico (con receptor USB).\nOpcionalmente un cable RJ45 conectado al Switch o Hub para acceso a la red de datos o a Internet.\nOpcionalemete un Dungle Wifi USB, para acceso a la red de datos o a Internet.\nHub USB 4 puertos nos permitirá incorpora una mayor número de periféricos.\nOpcionalmente un Pendrive con videos y películas para ver en el Media Center.\n\nDistros específicas para habilitar un Media Center con XBMC\nExiste una buena variedad de distribuciones especialmente orientada a convertir nuestra Raspberry en un Media Center con el XBMC ya pre-configurado, aunque ya podemos instalar XBMC en nuestro Raspbian, aquí hay algunas de ellas:\n*OpenELE*: No provee un imagen pre-configurada con un sistema de instalación, sin embargo, podemos encontrar las ultimas imágenes aquí. Es una de las más estables y optimizadas según los foros. Además cuenta con una sección de configuración bastante completa\nRaspbmc: La imagen ocupa unos 1.3. Cuenta con un instalador hecho en Python, pero para Window. Al parece se mantiene bastante actualizada por lo que es la preferida de algunos.\nXBian: Ofrece una image de unos 700Mb, la de menor tamaño de todos los que he evaluado, su instalación es elemental. Levanta la aplicación XBMC como un servicio en el arranque y carece de interface gráfica propia, ya que no se requiere si funcionar como un Media Center. Esta es la razón de lo reducido que es la distro. Es bastante rápida y ligera pero con es sencillo adaptar nuevo hardware.\nEn mi caso, para el momento de realizar el experimento, solo contaba con una memoria SD de 1Gb. Por esta razón decidí comenzar probando XBian. El proceso de instalación de la imagen es similar al descrito en el post los primeros pasos con la raspberry Pi.\ndd if=XBian1.0Alpha5.img of=/dev/disk1 bs=1m \nAgregando nuevos componentes o addons al XBMC.\nUna vez seleccionado e instalado el sistema sobre nuestro Raspberry Pi y esperando que haya reconocido la conexión a Internet, podemos instalar algunos componentes o Addons como los siguientes:\nTv a la carta: Configura el acceso a canales de televisión de todo el mundo, disponibles en streaming vía Internet.\nVideos a la carta: Maneja el acceso a canales de videos como Youtube, Vimeo, etc.\nPelis a la carta: Configura fuentes de películas completas como Cuevana entre otros.\nUsando el Media Center.\nAl terminar este proceso, que duró en mi caso, solo unos minutos, podemos comenzar a utilizar el Media Center. Es bastante sencillo, aquí podemos encontrar una FAQ o un manual y un tutorial, en el caso que deseemos profundizar en sus opciones. La wiki de XBMC es otra fuente de información muy completa\n\n\n\n\n\n\nControl remoto del XBMC.\nTenemos varias formas de controlar remotamente nuestro Media Center.\nTeclado inalámbrico. Tenemos una guía de referencia para el uso de teclado en XBMC.\nControl infrarrojo conectado al GPIO IR receiver, aquí podemos ver como. Otra forma con un adaptador USB así.\nControl web: El XBMC contiene un simple servicio web para el control remoto por la red.\nCelulares o tabletas a través de varias aplicaciones de Android como esta.\nMis próximos proyectos con el Media Center - Raspberry Pi\nSmart-TV Pi: La idea es construir un pequeño “Set Up Box” o decodificador para la televisión digital abierta (TDA) pero con capacidad de integrar en un mismo dispositivo, al estilo de un completo Media Center con XBMC, la posibilidad de no solo ver Televisión, en nuestro televisor, sino también reproducir películas desde un pendrive y ver videos desde canales de internet como Youtube, Vimeo, Cuevana, etc, incluso ver portales de redes sociales como Twitter y Facebook. Convirtiendo así, nuestro televisor convencional en un Smart-Tv.\nControl por reconocimiento de Rostros y formas: Por la entrada USB de nuestra Raspberry Pi, podemos conectar una webCam y con la programación de un sistema de reconocimiento de patrones basado en OpenCV, que luego podemos aplicarlo en el control remoto de nuestra Media Center.\n\n\n\n",
    "preview": "posts/2021-06-08-armando-un-media-center-con-la-raspberry-pi-y-xbmc/../../images/robotics/Raspberry_Pi_P1020063.JPG",
    "last_modified": "2021-06-08T05:00:53+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-23-primeros-pasos-con-la-raspberry-pi-modelo-b/",
    "title": "Primeros pasos con la Raspberry Pi, modelo B",
    "description": "El Raspberry Pi es uno de los proyectos más importantes, surgidos en los últimos años,  que están orientados a promover el aprendizaje de la informática en los  niños a muy bajo costo. Consiste en una placa base, que con el precio de 35$, contiene todos los elementos de un completo computador pero con  las dimensiones de una tarjeta de crédito.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2013-09-01",
    "categories": [
      "Linux Recipes",
      "Raspberry Pi",
      "Robotics"
    ],
    "contents": "\n\nContents\nUn poco de historia.\nCaracterísticas de la Raspberry Pi (Modelo B)\nExperimentos con la Raspberry Pi.\nLos primeros pasos\nComponentes básicos.\nInstalación del sistema operativo.\nInicio por primera vez con el Raspbian.\nReproducción de video\nAmbiente gráfico.\nInstalacion de nuevos software.\nEscritorio remoto.\n\nComponentes adicionales.\nSeleccionando un sistema operativo\nMis próximos proyectos con la Raspberry Pi\nComo programar con la Raspberry Pi\nArtículos y proyectos interesantes que he encontrado por ahí:\n\nLa Raspberry Pi tiene una capacidad de procesamiento equivalente a la de una netbook sencilla y un consumo de energía mínimo. Esto no representa un grave problema de capacidad, dado que es que capaz de presentar video en HD y manejar aplicaciones 3D con OpenGL 2.0, esto la convierte en una potencial herramienta para agregar capacidad, inteligencia y autonomía a nuestros robots.\nUn poco de historia.\n Este proyecto es bastante reciente. A pesar de que los primeros diseños de Raspberry Pi fueron en el 2006, fue en el 2011 que se creo una fundación para su producción y su administrador, Eben Upton, se puso en contacto con un grupo de profesores, académicos y entusiastas de la informática para crear un ordenador con la intención de animar a los niños a aprender informática. En agosto de 2011, se fabricaron cincuenta placas alpha. Las primeras ventas comenzaron el 29 de febrero de 2012. (fuente Wikipedia). La tarjeta con la que estaré haciendo mis experimentos es una modelo B, fabricada en diciembre del 2011.\nCaracterísticas de la Raspberry Pi (Modelo B)\nDespués de un par de meses de espera, llego mi esperada Raspberry Pi. La primera impresión es que se trata de una dispositivos muy simple y pequeño. Pero después de analizar sus componentes y características llego a la conclusión de que se trata de un completo computador, sobre el cual puedo probar mis distribuciones favoritas de GNU/Linux. Estas son sus especificaciones:\nPrecio: $35 (aprox)\nSoC: Broadcom BCM2835 (CPU + GPU + DSP + SDRAM + puerto USB)\nCPU: ARM1176JZF-S a 700 MHz (familia ARM11)\nGPU: Broadcom VideoCore IV,59 , OpenGL ES 2.0, MPEG-2 y VC-1 (con licencia),57 1080p30 H.264/MPEG-4 AVC\nMemoria (SDRAM): 512 MB (compartidos con la GPU)4 desde el 15 de octubre de 2012\nPuertos USB 2.0: 2 (vía hub USB integrado)\nEntradas de vídeo: Conector [[MIPI] CSI que permite instalar un módulo de cámara desarrollado por la RPF\nSalidas de vídeo: Conector RCA (PAL y NTSC), HDMI (rev1.3 y 1.4), Interfaz DSI para panel LCD\nSalidas de audio: Conector de 3.5 mm, HDMI\nAlmacenamiento integrado: SD / MMC / ranura para SDIO\nConectividad de red: 10/100 Ethernet (RJ-45) via hub USB\nPeriféricos de bajo nivel: 8 x GPIO, SPI, I²C, UART\nReloj en tiempo real: Ninguno\nConsumo energético: 700 mA, (3.5 W)\nFuente de alimentación: 5 V vía Micro USB o GPIO header\nDimensiones: 85.60mm × 53.98mm64 (3.370 × 2.125 inch)\nSistemas operativos soportados:\nGNU/Linux:\nDebian (Raspbian)\nFedora (Pidora)\nArch Linux (Arch Linux ARM)\nSlackware\nRISC OS2\n\n  \nExperimentos con la Raspberry Pi.\nComo todo proyecto para fomentar el desarrollo, la Raspberry Pi tiene un gran número de posibles usos, el límite es la imaginación. Aquí expongo algunos usos comunes con los que he comenzado a experimentar:\nSistema de propósito general: el primer uso que le podemos dar a nuestra Raspberry Pi, es la de una computador común. Podemos usar todos los periféricos comunes. Como monitor podemos emplear un televisor convencional, dado que tenemos salidas RCA de video analógico y HDMI de video digital. Hice la prueba de una convertidor de HDMI a DVI y la conecté a un monitor sin ningún problema.\n\nMedia Center con XBMC: Otro posible uso que me parece más interesante, es el de emplear la RaspBerry Pi para construir un Media Center. Podemos integrar en una misma interfaz, el despligue de videos y multimedia de varias fuentes como la televisión y el Internet. Existe un proyecto en Software Libre, que tiene esto como objetivo, llamado XBMC y puede ser extendido mediante la programación de pluggins en Python. He dedicado otro post para mostrar como hacer esto. Fuente en Wikipedia.\n\nControl de Robots y Domótica: Su pequeño tamaño y su gran capacidad posibilita su utilización en robótica ya que podemos incorporar un completo computador en nuestros pequeños robot, dotándolos de la capacidad de procesamiento y comunicaciones que ofrecen los sistemas operativos modernos. También la automatización de algunas acciones como el encendido y apagado de luces, registro de sensores de movimiento, temperatura, etc. Mi primer experimento, que comentaré en otro post, fué adaptar la Raspberry Pi a un vehículo Lego Technic (8081) y motorizado con Mindstorm y manejado por una aplicación hecha en Python.\n\nLos primeros pasos\nLos primeros pasos están bien descritos en el documento QuckStart que podemos encontrar en el sito de la Raspberry Pi, este documento describe como instalar la imagen de Raspbian, un sistema operativo basado en Debian wheezy sobre una memoria SD. En principio no nos hará falta realizar el proceso de instalación del sistema operativo, ya que podemos encontrar un buen número de imágenes de sistemas adaptados a nuestro nuevo juguete. En el propio sitio de descargas de Raspberry Pi podemos encontrar varias de ellas.\n\nComponentes básicos.\nLa Raspberry Pi, por supuesto.\nUna memoria SD de 4Gb o más. Aunque algunas imágenes requieren 1G o hasta 2G como mínimo y preferiblemente de Clase 10.\nUn transformador DC de 5v con salida mini-USB.\nUn cable HDMI o RCA para el televisor.\nUn teclado USB o inalambrico (con receptor USB).\nUn mouse USB o inalambrico (con receptor USB).\nOpcionalmente un cable RJ45 conectado al Switch o Hub para acceso a la red de datos o a Internet.\nInstalación del sistema operativo.\nA continuación describiré con un poco más de detalle los pasos, en Linux, para solventar algunos obstáculos a los que nos podríamos enfrentar instalando un sistema operativo sobre una memoria SD, ya que loas instrucciones que se encuentra por ahí son para Windows:\nVamos al sitio de descargas y bajamos la imagen comprimida del sistema operativo Raspbian, a la fecha, la ultima es la del 26/07/2013:\nwget http://downloads.raspberrypi.org/images/raspbian/2013-07-26-wheezy-raspbian/2013-07-26-wheezy-raspbian.zip\nunzip 2013-07-26-wheezy-raspbian.zip\nLuego copiaremos la images escogida sobre la memoria SD que nos servirá de disco para la Raspberry Pi, aquí un breve tutorial. Es importante respaldar lo que tengamos ahí dado que el contenido previo se perderá, para esto usaremos el comando dd, con los parámetros if (dirección d ela imagen a utilizar), of (dispositivo de destino) y bs (tamaño de los bloques de memoria a manejar en la copia) . Si suponemos que la unidad SD fue detectada como /dev/disk1, la instrucción quedaría así:\n\ndd if=2013-07-26-wheezy-raspbian.img of=/dev/disk1 \nDespués de unos minutos, esta instrucción copia la imagen sobre el dispositivo de almacenamiento (Memoria SD). Es este punto es importante tener varias cosas en cuenta. Se puede mejorar la velocidad de copiado raster (dd) aumentado el tamaño de los bloques (aprovechando la capacidad DMA de nuestro equipo), en algunos caso puede funcionar bs=4m o más. Otro punto importante es que, obviamente, la memoria física debe ser igual o mayor que la imagen (.iso ó .img). Lo común es que no sea igual sino mayor, con lo que deberíamos extender el formato de la partición para que nuestro sistema aproveche toda la capacidad de la memoria SD, esto lo haremos más adelante con expand_rootfs. Si no contamos una memora de gran capacidad, podemos escoger alguna distro que sea minimalista. Por ejemplo contamos con una imagen de Arch linux que cabe perfectamente en una memoria SD de 1Gb de capacidad, aquí un tutorial para adaptar ese sistema a nuestra Raspberry Pi. Otro punto muy importante es que debemos escribir la imagen del sistema (.iso ó .img) sobre todo el dispositivo de almacenamiento, no sobre una partición particular. Si la memoria ya esta formateada, es podible que nuestro sistema reconozca una o varias de las particiones como por ejemplo /dev/Disk1s1 o /dev/Disk2s1, es estos caso las letras sx corresponde a particiones, es por eso que deberemos utilizar /dev/disk1 o /dev/disk2 respectivamente. He leído en varios foros que puede que algunas memorias SD no son reconocidas o compatibles con la Raspberry, esto no me ha ocurrido con mi modelo B, a pesar de haber probado unas 4 o 5 memorias de diferentes marcas, clases y tamaños.\nInicio por primera vez con el Raspbian.\nUna vez que contamos son el sistema operativo, en este caso Rasbian, sobre la memoria SD, debemos introducirla en la ranura que se encuentra en la parte de abajo de la Raspberry. Ahora solo queda conectar la salida de video, el teclado (y mouse) y encenderla. Como habrán notado, la Raspeberry no cuenta con un interruptor, por o que encenderá en cuanto conectemos la alimentación de corriente. En este punto, es posible que la Raspberry no encienda, recuerden que la Raspberry no cuenta con baterías y la alimentación debe ser de 5v DC. Algunos cargadores de celulares no proveen una corriente continua estable por lo que no nos funcionaran, yo tuve que hacer varios intentos hasta que conseguí uno bueno. Los siguientes pasos están descritos a continuación:\n\nEn el primer arranque se activara el Raspi-conf que nos permitirá hacer las configuraciones del equipo. Esta es una de las ventajas de las Rasbian, que cuenta con un sistema de ventanas que nos facilitará la configuración inicial. Esto solo se requiere hacer una vez y nos permitirá hacer cosas como:\n\nExtender el formato sobre todo el espacio de la memoria SD (expand_rootfs).\nCambiar el password del usuario“pi” está creado por defecto.\nCambiar la zona horaria y la fecha y hora del sistema.\nConfigurar el teclado y el idioma (locale).\nConfigurar el overclock (pasar la frecuancia del procesador de 700MHz a 1000Mhz).\nActivar el servicio SSH en el arranque.\nActivar el ambiente gráfico en el arranque.\nAl final aceptaremos la opcion de reinicio.\n\nLa Raspberry Pi iniciará solicitándonos el Login y el Password a lo que responderemos con “pi” y “raspberry” respectivamente (sin comillas). Luego aparecerá el prompt: pi@raspberry ~ $ y ya estamos listos para usarla…\nReproducción de video\nAhora podemos comenzar a utilizar nuestro sistema, por ejemplo si tenemos una película en un pendrive, podemos verla en el televisor con el comando omxplayer, por ejemplo, sustituyendo el path por el adecuado a su caso:\nomxplayer /media/sda1/video.mp4\nEl omxplayer asume por defecto que la salida utilizada es la análogica, en caso de estar usando la salida HDMI deberemos incorporar el parámetro -hdmi así:\nomxplayer -hdmi /media/sda1/video.mp4\nAmbiente gráfico.\nDesde luego que más interesante para observar las capacidades de la Raspberry es trabajar con ventanas, por ejemplo para iniciar el ambiente gráfico (si es que tenemos conectado un televisor o monitor) podemos introducir la instrucción que lo iniciará: startx\n\nInstalacion de nuevos software.\nHasta ahora podemos usar nuestra Raspebrry Pi como un computador tradicional. Pero dependiendo del espacio disponible que tengamos en nuestra memoria SD, podemos instalar nuevas aplicaciones, por cualquiera de los métodos tradicionales. Yo recogimientoconfigurar a mano el repositorio que usaremos ya que la selección automática de repositorios (master) me manda a Brasil, que no es la mejor opción en mi caso. Aquí podemos encontrar una lista de repositorios oficiales de Raspbian según zonas geográficas, yo escogí EEUU. Luego toca el repositorio escogido en el archivo, quedando algo así. Luego solo queda actualizar el índice de paquetes disponibles con apt-get uptate, y si queremos actualizar nuestro sistema usaremos apt-get upgrade.\n\nsudo apt-get update\nsudo apt-get upgrade\nAhora podemos instalar aplicaciones con el comando apt-get install o instalar un manejador gráfico de paquetes de software, como synaptic:\nsudo apt-get install synaptic\nLuego será mucho más fácil la instalación de nuevos programas, yo recomiendo para comenzar :\nFirefox: un mejor y más actualizado navegador.\nVCL: un muy buen reproductor de video.\nffmpeg: sistema de programas de consola útiles para la manipulación de video y audio.\nImageMagick: sistema de programas de consola para la manipulación de imágenes.\nXBMC: El mejor software de Media Center para Linux.\nEscritorio remoto.\nPodemos controlar nuestra Raspberry desde nuestro equipo de escritorio de manera gráfica, a través del escritorio remoto que provee el protocolo VNC. Para ello debemos descargar el servidor en nuestra Raspberry e iniciar el servicio así:\n\nsudo apt-get install tightvncserver\nvncserver :1 -geometry 1024x768 -depth 16 -pixelformat rgb565\nUna buena opción es incluir esta instrucción en un archivo script, que luego podemos ejecutar automaticamente al arrancar, de manera de no requerir la salida con el televisor.\nLuego podemos ver y manejar el escritorio remotamente desde una variedad de dispositivos y aplicaciones clientes de VNC, por ejemplo en KDE tenemos el Krdc, en Gnome tenemos el Vinagre, en Windows el RealVNC, Putty y en Android el AndroidVNC. Un punto importante para el acceso remoto a nuestra Raspberry es que debemos conocer el IP que ha tomado en nuestra red. Esto lo podemos saber con el comando ifconfig pero podría ser un problema si no tenemos conectada a ella periféricos de entrada y salida (teclado y monitor). Para resolver eso recurrí a la pantalla de administración de mi switch casero en donde encontré la Raspberry en el área de clientes de red (DHCP).\nOtra manera de ejecutar aplicaciones remotamente, con interfaces gráficas, es a través del protocolo SSH, como lo he descrito en otro post, podemos escribir desde nuestro PC el comando remoto de la siguiente manera, sustituyendo por la dirección de tu Raspberry Pi:\nssh -X -l pi 192.168.1.13\nComponentes adicionales.\nDependiendo del proyecto en el que queramos trabajar, será necesario incorporar nuevos componentes como por ejemplo:\nHub USB 4 puertos (sin alimentación adicional) nos permitirá incorpora una mayor número de perifericos. Recordemos que unestra raspeberry cuenta solo con 2 puertos USB, de esta forma podemos extender hasta 5 la capacidad de puertos.\nDungle Wifi USB, si deseamos incorporar la Raspberry en nuestros robots, sera neceario poder matener la conexión a lared de forma inalambrica.\nConvertidor HDMI-DVI será necesario si deseamos utilizar un monitor convencional con entrada digital.\nMódulo de Cámara integrada. Hace poco se publicó la producción de un nuevo módulo de camara para el Raspberry Pi.\nDongle Bluetooth USB, útil si deseamos controlar nuestro Raspberry desde dispositivos celulares y necesario si queremos acceder a perifericos como la Wiimote.\n  \nSeleccionando un sistema operativo\nLa selección del sistema oerativo, o mejor dicho, distribución de Linux que usaremo para nuestro Raspberry Pi dependerá, como siempre del gusto de cada quien. Existen versiones de las principales ditribuciones más algnas de proposito especifico. Hasta ahora solo he porbado unas cuantas distros que listare a continuacion:\nDistro de proposito general:\nRaspbian: Sistema operativo basado en Debian wheezy. esta imágen viene bastante competa y ocupa unos 1.8Gb, por lo que debe ser instalada en una memoria de al menos, 2Gb.\nArch Linux: Es un sistema que requiere un poco mas de trabajo par su configuración, sin embargo tiene bastantes adeptos. A pesar de que la imagen ocupa 1.8Gb, el sistema ya instalado es mucho más pequeño.\nMis próximos proyectos con la Raspberry Pi\nCarro robot controlado con una Raspberry Pi: como ya lo he mencionado la incorporación de un computador de este tipo, permite aprovechar la movilidad y autonomía que permite su pequeño tamaño, peso y consumo eléctrico. Este proyecto busca construir un pequeño vehículo robot con la suficiente autonomía y capacidad de procesamiento que me permita experimentar con temas de Inteligencia Artificial en el control de movimiento y ejecución de tareas.\nControl de equilibrio: Un segway con lego+wiimote+raspberry: Este pequeño computador viene a complementar la tarea de construir un robot de dos ruedas, capaz de mantener el equilibrio y responsear instrucciones por voz.\nSmart-TV Pi: La idea es construir un pequeño “Set Up Box” o decodificador para la televisión digital abierta (TDA) pero con capacidad de integrar en un mismo dispositivo, al estilo de un completo Media Center con XBMC, la posibilidad de no solo ver Televisión, en nuestro televisor, sino también reproducir películas desde un pendrive y ver videos desde canales de internet como Youtube, Vimeo, Cuevana, etc, convirtiendo así, nuestro televisor convencional en un Smart-Tv.\nControl por reconocimiento de Rostros y formas: Por la entrada USB de nuestra Raspberry Pi, podemos conectar una webCam y con la programación de un sistema de reconocimiento de patrones basado en OpenCV podemos aplicarlo en el control de vehículos robóticos.\nRe-calibración automática de antenas de telecomunicaciones: Este proyecto consiste en la posibilidad de construir un dispositivo para integrarlo a las antenas de comunicaciones, para su re-calibración automática. uno de los problemas de las comunicaciones satelitales, es que los satélites sueles moverse y salir del espacio de visibilidad de alguna antenas. Esto requiere de un ajuste de la posición de las mismas. La propuesta es usar la Raspberry para que, a través de la programación de redes neuronales, y el conocimiento previo de la posición del satélite, se puedan calcular las trayectorias más probables que permitan re-calibrar la posición de las antenas con el uso de servomotores.\nComo programar con la Raspberry Pi\nLas herramientas de programación de la Raspberry Pi son las mismas que contamos en nuestro sistema GNU/Linux, por lo que la elección depende, realmente, del gusto de cada quien, en mi caso: Python y C/C++. Ahora bien, para el desarrollo de aplicaciones para el control de robots hechos con el Lego MindStorm será necesario instalar NXT-Python y LibNXT. Otra recomendación, si queremos hacer tareas de reconocimiento basado en el procesamiento de video, es instalar OpenCV y FFmpeg. Por ultimo y por ahora, recomiendo la librería LibWiimote de conexión con la Wiimote que nos permitirá acceder a sus sensores como cámara infrarroja y acelerometro, igualmente útiles en la robótica,\nArtículos y proyectos interesantes que he encontrado por ahí:\nAdafruit Holiday Gift Guide 2012 – Raspberry Pi Kits & Accessories\nCon ustedes, el Macintosh más pequeño del mundo\nRaspberry PI: Programando el puerto GPIO con Qt Creator\nA,B,C…π\nTutorial Raspberry Pi (Primeros pasos)\nPrimeros pasos Raspberry Pi\nHow to set up Raspberry Pi\nInstalling Raspberry Pi on SD card on mac or linux\nLos diez mejores proyectos\nDiez proyectos que me gustaría hacer con la Raspberry Pi\nRaspberry Pi ya tiene tienda de aplicaciones: Pi Store\nAccesorios para Raspberry Pi\nRaspberry Pi USB Power Issues - Ultimate Solution\nUniversity builds cheap supercomputer with Raspberry Pi and Legos\nXBMC y tu Raspberry Pi: OpenELEC\n\n\n\n",
    "preview": "posts/2021-05-23-primeros-pasos-con-la-raspberry-pi-modelo-b/../../images/Raspberry-Pi-1.jpg",
    "last_modified": "2021-06-13T01:53:40+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-13-alternativas-de-programacion-del-nxt-con-software-libre/",
    "title": "Alternativas de programación del NXT con Software Libre",
    "description": "Como ya sabemos, una de las principales razones para tener un NXT es su capacidad de procesamiento, y más aún, la posibilidad que tenemos de  programarlo. Es este post haré un repaso por las diferentes alternativas que tenemos en el mundo del software libre, para programar nuestros  robots.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2013-08-25",
    "categories": [
      "Lego Mindstorm",
      "Robotics"
    ],
    "contents": "\n\nContents\nCaracterísticas de NXT\nProgramación del NXT\nOpciones libres para la programación del NXT\nOtros lenguajes privativos para el NXT\n\n\nConclusiones\nAlgunos enlaces y fuentes relacionadas\n\nCaracterísticas de NXT\nEn otro post comenté sobre las características y capacidades del bloque NXT, ahora las repasaremos desde el punto de vista de sus potencialidades para programarlo. NuestroLego Mindstorm viene con un ambiente de programación privativo y un lenguaje gráfico, basado en bloques, llamado NXT-G (aquí algunos ejemplos de programas NXT-G). El NXT-G es bastante amigable y una herramienta ingeniosa para introducir a los niños en los conceptos de programación, sin embargo, como dije antes, es privativo. Aquí podrán descargar una guía rápida de programación NXT-G, o esta otra.\n\nPara poder sacar el máximo de la capacidad de nuestros robots, aquellos que somos aficionados a la programación, seguramente preferirán lenguajes de programación con más capacidad que la que puede ofrecer un diagrama gráfico. Antes que nada repasemos las características del bloque NXT:\n\n32-bit Atmel AT91SAM7S256 main microcontroller (256 KB de memoria flash, 64 KB RAM)\nMicrocontrolador de 8-bit Atmel ATmega48 @ 4 MHz (4 KB de memoria flash , 512 Bytes RAM)\nPatalla LCD de 100x64 pixel\nCuatro puertos de entrada de 6-pin (ports 1-4)\nTres puertos de salida de 6-pin (ports A-C)\nPuerto USB\nBluetooth Class II V2.0\nLoudspeaker - 8 kHz, 8-bit resolution, 2–16 kHz sample rate\nPanel de 4 botones\nAnaranjado: On/Enter\nFlechas gris claro: moving left and right in the NXT menu\nBotón gris oscuro: Clear/Go back\n\nAlimentación de corriente por 6 baterías AA o una bateria recargable DC NXT\nPeriféricos sensores:\nSensor de Color (9694), para detectar 6 diferentes colores: azul, verde, rojo, amarillo, blanco, negro. Viene incluido con la nueva versión.\nSensor de Luz (9844), para detectar niveles de luz. (incluido en la primera versión, pero reemplazada por el sensor de color en la 2.0.\nSensor de Tacto (9843), consiste en un simple botón que detecta si algo lo toca.\nSensor de Ultrasonido (9846), para medir distancias usando hondas inaudibles de sonido.\nSensor de Sonido (9845), para básicamente “escuchar”: capaz de medir volumen pero no graba los sonidos.\nSensor de Compas (MS1034), para la detección de la dirección. ha sido construido con un calibrador que reduce la interferencia producida por otros objetos magnéticos (No viene incluido en el kit básico).\nSensor Acelerómetro (MS1040), para detectar en que dirección se mueve. también puede medir la fuerza G, es decir, la de gravedad (No viene incluido en el Kit básico).\nSensor RF-ID, para comunicaciones entre múltiples robots (No viene incluido en el kit básico).\nSensor de Rotación (incluido dentro de los servo-motores), para medir la velocidad y angulo de giro. El cálculo se realiza en base a los dientes de los engranares internos.\n\nPeriféricos actuadores:\nServo Motor (9842).\nEl Sensor de Color puede emitir una luz que utiliza como lampara para censar su reflejo.\n\nFuente: http://en.wikipedia.org/wiki/Lego_Mindstorms_NXT_2.0\nEstas especificaciones plantean la posibilidad de resolver la autonomía en un gran número de tareas para nuestros robots desde el propio NXT, sin embargo, para cierto tipo de trabajos no, especialmente para aquellos en los que se requiere mayor capacidad de procesamiento, por ejemplo el procesamiento de imágenes de video o para ciertos tipos de cálculos en temas como Inteligencia Artificial. En estos casos seguirá siendo necesario recurrir a la capacidad de computadores de escritorio o servidores.\nProgramación del NXT\nCuando abordamos el tema de programar nuestro NXT tenemos que tomar varias cosas en cuenta antes de seleccionar el lenguaje y las herramientas de desarrollo, como las capacidades del NXT y la compatibilidad de este con el lenguaje que deseamos utilizar. Para ciertos lenguajes es necesario la actualización o el cambio del sistema operativo interno de la NXT (firmware). Por ejemplo, para usar Java es necesario sustituir el firmware original por el LejOS.\nEn el caso de que no queramos modificar el sistema interno, es importante destacar que las funciones del mismo son accesibles, tanto desde las aplicaciones internas como desde los puertos de entrada/salida, como el USB y el Bluetooth. Esta característica permite que, o bien los lenguajes de programación empleados, deben generar en sus compilaciones, programas compatibles con el NXT y por tanto puedan ser cargados y ejecutados en el mismo (*.rxe). O por otra parte, nuestros programas hagan uso de librerías adecuadas para comunicarse con el NXT y por tanto, puedan ejecutarse desde fuera del mismo. En el primer caso, obtendremos soluciones con mucho mayor autonomía pero limitadas a las capacidades de procesamiento de la NXT. En el segundo caso podremos aprovechar el uso computadores de mayor capacidad de procesamiento pero las limitaciones de movilidad y autonomía que estas conexiones (Bluetooth o USB) impliquen.\nOpciones libres para la programación del NXT\nGracias al espíritu científico con el que fue conceptualizado y construido el Lego Mindstorm, sus creadores dispusieron suficiente información técnica como para la proliferación de herramientas libres para el desarrollo sobre esta plataforma, así como nuevos sensores y elementos electrónicos compatibles con ella. A continuación haré un breve repaso de las herramientas y lenguajes de desarrollo para la NXT:\nEnchanting es un ambiente gráfico de programación, basado en Scratch y BYOB/Snap!, contiene conectores para la programación del NXT dentro del ambiente del popular Scratch IDE.\nleJOS NXJ es un lenguaje de alto nivel de fuentes abiertas y basado en Java. Requiere de un firmware modificado desarrollado por el equipo de leJOS.\nBricxCC (Bricx Command Center) de John Hansen, es un IDE para programar varias versiones de bloque programables de LEGO, como el RCX y el NXT. Actualmente incluye lenguajes como el NQC (Para el bloque RXC), el NBC (Beta) y NXC (para el NXT). Lamentablemente solo está disponible para Windows. Hasta ahora he podido hacerlo funcionar en GMU/Linux con Wine pero sin comunicación directa con el NXT.\nNQC Not Quite C esta dirigido a programar el bloque RCX y uno de los pocos que reemplaza el framework, utiliza como lenguaje de programación una versión propia de C. Debe emular las instrucciones, haciendo que el proceso sea más lento que por la metodología de reemplazar el firmware. Funciona tanto en modo interpretado, para que sea ejecutado desde fuera, como en modo compilado para que sea cargado en el bloque. Not Quite C esta disponible para Mac OS y Windows y Linux.\nNBC (Next Byte Codes) es un languaje básico de código abierta con una sintaxis de ensamblador que puede ser utilizado para programar el bloque NXT a bajo nivel. El ambiente BricxCC también tiene la capacidad de des-compilar los archivos ejecutables estándar .rxe hacia codigo NBC.\nNXC (Not eXactly C) es un lenguaje de alto nivel similar a C, construido sobre el compilador NBC, por lo que también puede ser utilizado para programar el bloque NXT. NXC is basicamente NQC para el NXT. es uno de los más ampliamente usados por otros lenguajes de programación para el NXT. Es posible, hasta crear videojuegos para el NXT.\npbLua es un port de el lenguaje de programación Lua, consiste en un lenguaje interpretado de propósito general, para que el Lego Mindstorms. lo pueda ejecutar requiere de un firmware propio.\nPyNXC en un proyecto que convierte código Python en código binario NXC “Not Exactly C”, que luego puede ser cargado en nuestros Robots del Lego Mindstorm.\nBrickTool por John Hansen es un utilidad basada en Bluetooth para las comunicaciones entre el PC y el bloque NXT.\nICommand por Brian Bagnall: es un API de Java API para controlar remotamente el bloque Lego NXT.\nNXT# por Bram Fokke es una librería para controlar el Lego Mindstorms NXT para .NET.\nNXT Perl API por Michael Collins es una capa de control del NXT escrita en Perl**.\n**\n*Ruby-nxt* es una librería para controlar el NXT remotamente usando Ruby.\n*LibNxt*por David Anderson es una librería de comunicación entre el PC y el bloque NXT escrita en C.\n*Nxt-Python*es una librería Python para el control de Robots Lego Mindstorms NXT, permite la comunicación con el NXT tanto por via USB como por Bluetooth. Soporta comandos directos y una gran variedad de sensores adicionales de terceros.\nT2N (Talk to NXT) es una herramienta por línea de comandos para transferir programas ejecutables y archivos de datos entre el PC y el bloque NXT\nOtros lenguajes privativos para el NXT\nRobotics Studio by Microsoft.\nRobolab.\nRoboMind.\nRobotC.\nMATLAB y Simulink.\n\nConclusiones\nHay una amplia variedad de alternativas para programar los robots de Lego. Pienso que, a menos que sean amantes de Java (que no es mi caso), no hace falta sustituir el firmaware original para programar nuestros robots y sacarles el máximo provecho.\nA mi juicio las grandes alternativas para la programación del Lego Minstorm NXT son Python y C/C++, ya sea para crear ejecutables nativos (*.rxe) para el bloque NXT con PyNXC o NQC, o para compilar aplicaciones que se ejecuten el PC y se comuniquen con el NXT (por USB o Bluetooth) con nxt-python o con LibNxt, en Python y C/C++ respectivamente.\nEn varios post anteriores muestro como controlar un carro robot con python, y desde una “canaimita” este es uno de los videos:\n\n \n\nAlgunos enlaces y fuentes relacionadas\nhttp://blog.electricbricks.com/es/2009/09/lenguajes-programacion-nxt/\nhttp://www.teamhassenplug.org/NXT/NXTSoftware.html\nhttp://mindstorms.lego.com/en-us/default.aspx\nhttp://ro-botica.com/mindstorms_sys.asp\nhttp://www.philohome.com/nxt.htm\nhttp://es.wikipedia.org/wiki/Lego_Mindstorms\nhttp://en.wikipedia.org/wiki/Lego_Mindstorms_NXT\nhttp://en.wikipedia.org/wiki/Lego_Mindstorms_NXT_2.0\n\n\n\n",
    "preview": "posts/2021-06-13-alternativas-de-programacion-del-nxt-con-software-libre/../../images/robotics/nxt.jpg",
    "last_modified": "2021-06-29T19:54:11+00:00",
    "input_file": "alternativas-de-programacion-del-nxt-con-software-libre.knit.md"
  },
  {
    "path": "posts/2021-06-13-wiimote-como-sensor-de-posici0n-y-movimiento-para-nuestros-robots/",
    "title": "Wiimote como sensor de posición y movimiento para nuestros robots",
    "description": "Partiendo del hecho de que el Wiimote, comando de mano de la  consola de juegos Wii, es capaz de seguir hasta 4 fuentes de luz  infrarroja y ubicar sus coordenadas, así como con el posicionamiento y orientación gracias que posee un acelerometro  bastante preciso, podriamos considerarlo como un potencial instrumento  sensor para nuestros robots.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2013-06-14",
    "categories": [
      "Wiimote",
      "Robotics"
    ],
    "contents": "\n\nContents\nAccediendo a las funciones del Wiimote desde Linux\nCompilación de la librería Libwiimote\nEjemplo de uso de la librería Libwiimote\nInterpretación de la salida de la salida del programa acelerometer\nFuentes:\n\nEn otros post, he comentado sobre posibles usos para este dispositivo (pizarra interactiva). Ahora, partiendo del hecho de que el Wiimote (comando de mano de la consola de juegos Wii) es capaz de seguir hasta 4 fuentes de luz infrarroja y ubicar sus coordenadas con resolución de 1024x768, así como con el posicionamiento y orientación gracias que posee un acelerometro bastante preciso, podriamos considerarlo como un potencial instrumento sensor para nuestros robots.\nAccediendo a las funciones del Wiimote desde Linux\nLibwiimote es una librería desarrollada en C que permite el acceso al control del Wiimote desde Linux. El objetivo de este proyecto es el de contar con una completa y sencilla interface para acceder a todas las funciones de este control. El código fuente de la libreria puede descargarse desde aquí.\nCompilación de la librería Libwiimote\nPara la compilación de Libwiimote, descargue a la ultima versión, la 0.4. También es necesario contar con la librería bluez y bluez-compact. Debido a un cambio en las ultimas versiones del API de acceso al Bluetooth en linux, es necesario cambiar la el nombre la función hci_remote_name por su nuevo nombre hci_read_remote_name en las siguientes archivos:\nsrc/wiimote_link.c\nconfigure.in\nLuego, para compilar la librería realizaremos las siguientes instrucciones:\ntar zxvf libwiimote-0.4.tgz\ncd libwiimote-0.4/\nautoconf\n./configure\nmake\nsudo make install\nsudo ln -s /usr/local/lib/libcwiimote.so.0.4.0 /usr/local/lib/libcwiimote.so\nsudo ldconfig\nEjemplo de uso de la librería Libwiimote\nEn la página de este proyecto encontramos un par de ejemplo útiles para comprender el uso de esta librería. A continuación le dejo el código de un pequeño ejemplo, que llame “acelerometer.c”, y que lee la orientación del wiimote y la presenta por consola. Funciona de manera indefinida hasta que se presiona el botón de home dentro del control. En esta wiki podemos encontrar algo de ayuda\n#include \n #include \"wiimote_api.h\"\n int main() \n {\n  wiimote_t wi;\n  wiimote_connect(&wi, \"xx:xx:xx:xx:xx:xx\");\n  wi.mode.acc = 1;    // enable accelerometer\n  printf(\"Iniciando lectura del acelerometro...\\n\");\n  while (wiimote_is_open(&wi)) {\n   wiimote_update(&wi);   // synchronize with wiimote\n   if (wi.keys.home) {  // check if home key is pressed\n    wiimote_disconnect(&wi);\n    printf(\"\\nFinalizo lectura...\\n\");\n   }\n   printf(\"x=%d \\ty=%d \\tz=%d \\n\", wi.axis.x, wi.axis.y, wi.axis.z);\n  }\n  return 0;\n }\nAntes de compilar debemos cambiar “xx:xx:xx:xx:xx:xx” por el identificador del control. Este identificador lo obtenemos del comando de escaneo de lo dispositivos, tal como lo comenté en el post sobre como acceder a dispositivos bluetooth desde consola.\nLa compilación de este código podemos ejecutar así:\ngcc -I/path_to/libwiimote-0.4/src/ -L/path_to/libwiimote-0.4/lib/  -lcwiimote -lbluetooth -lm -Os -Wall -pipe -D_ENABLE_TILT  -D_ENABLE_FORCE -g -O2 -o acelerometer acelerometer.c\nInterpretación de la salida de la salida del programa acelerometer\n…En desarrollo…\nFuentes:\nhttp://blog.jorgeivanmeza.com/2009/07/instalacion-de-wiipresent-en-linux-ubuntu-9-04-un-largo-camino/\nhttp://libwiimote.sourceforge.net/\nhttp://www.seguridadmobile.com/bluetooth/especificacion-bluetooth/bluez/\n\n\n\n",
    "preview": "posts/2021-06-13-wiimote-como-sensor-de-posici0n-y-movimiento-para-nuestros-robots/../../images/robotics/wiimote_normal2_tn.png",
    "last_modified": "2021-06-13T03:09:30+00:00",
    "input_file": {},
    "preview_width": 198,
    "preview_height": 119
  },
  {
    "path": "posts/2021-07-25-renombrar-particiones-en-linux/",
    "title": "Renombrar particiones en Linux",
    "description": "Desde hace algún tiempo, la mayoría de las distribuciones de GNU/Linux identifican las particiones de nuestro computador por un código UUID de 128 bits, compuesto por 32 caracteres hexa-decimales. El problema es que estos códigos son imposibles, o al menos, muy difíciles de aprender. El proceso de identificar la partición adecuada en donde buscar o guardar un determinado archivo se convierte en un verdadero problema.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2013-01-14",
    "categories": [
      "Linux Recipes",
      "Vim"
    ],
    "contents": "\n\nContents\nFormatos EXTx\nFormato JFS\nFormato RaserFS\nFormato XFS\nFormato NTFS\nFormato FAT o FAT32\nPartición de intercambio (swap)\nAutomontaje de las particiones\nIdentificación de las particiones\nOtras utilidades\nFuentes\n\nUna forma de resolver esta situación es colocar un Label a estas particiones. Aunque esto no es requerido para el gestor de discos en Linux, generalmente los navegadores de archivos si usan estas etiquetas para identificar la particiones en su interfaz gráfica.\nFormatos EXTx\nLa manea de cambiar o asignar un nuevo label o etiqueta a una partición formateada como EXT2, EXT3 o EXT4 es la siguiente:\ntune2fs -L etiqueta /dev/sdxx\no también…\ne2label /dev/sdxx etiqueta\nEn donde /dev/sdxx corrsponde al path de la partición que deseamos etiquetar y ETIQUETA corresponde al texto del la etiqueta que deseamos asignarle.\nFormato JFS\nPara elcaso de las particiones formateadascon JFS:\njfs_tune -l etiqueta /dev/sdxx\nFormato RaserFS\nPara particiones formateadas con RaserFS:\nreiserfstune -l etiqueta /dev/sdxx\nFormato XFS\nEn el caso de XFS podemos renombrar las particiones así:\nxfs_admin -l etiqueta /dev/sdxx\nFormato NTFS\nEn cuanto a las particiones NTFS el comando es el siguiente:\nntfslabel /dev/sdxx etiqueta\nFormato FAT o FAT32\nEn cuanto a las particiones de windows FAT, el comando es el siguiente:\nexfatlabel /dev/sdxx etiqueta\nO también:\nfatlabel /dev/sdxx etiqueta\nEstos procedimientos me permitieron etiquetar todas las particiones de mi sistema y así evitar el listados de identificadores numéricos inentendibles en mi navegador de archivos.\nimgPartición de intercambio (swap)\nPara crear o prepara una particion para el swaping con una etiqueta particular:\nmkswap -L etiqueta /dev/sdxx\nAutomontaje de las particiones\nComo deben saber, para automatizar el montaje de nuestras particiones en Linux, es necesario configurar el archivo /etc/fstab Cuando este es creado en el proceso de instalación suele identificar los dispositivos a montar por su UUID, pero si queremos utilizar las etiquetas que acabamos de configurar, podemos hacerlo con el siguiente formato:\nLABEL=/LOCAL /usr/local ext3 defaults 1 2\nDonde, por ejemplo, LOCAL corresponde a la etiqueta de la partición que deseamos montar en el punto de montaje /usr/local.\nIdentificación de las particiones\nPara poder hacer todo lo anterior es necesario poder identificar todas las particiones, cuales están montadas y que formato tienen para esto podemos usar algunos comando como:\npara listar todas las particiones podemos ejecutar el comando fdisk con la opcion -l. Si deseamos saber cuales particiones están montada y donde podemos usar el comando mount o el comando df con la opcion -h, este ultimo da información adicional como cuanto espacio tienen y cuanto queda disponible. Otra manea de listar las particiones es con el comando tree sobre el directorio /dev/disks que da un resultado como el siguiente:\n# tree /dev/disk/\n/dev/disk/\n|-- by-id\n|  |-- ata-LITE-ON_DVDRW_SOHW-1653S -> ../../sr0\n|  |-- ata-SAMSUNG_HD753LJ_S13UJ1CS200431 -> ../../sdb\n|  |-- ata-SAMSUNG_HD753LJ_S13UJ1CS200431-part1 -> ../../sdb1\n|  |-- ata-SAMSUNG_HD753LJ_S13UJ1CS200431-part2 -> ../../sdb2\n|  |-- ata-SAMSUNG_HD753LJ_S13UJ1CS200431-part5 -> ../../sdb5\n|  |-- ata-SAMSUNG_HD753LJ_S13UJ1CS200431-part6 -> ../../sdb6\n|  |-- ata-SAMSUNG_SP1213C_S02AJ10Y426107 -> ../../sdc\n|  |-- ata-SAMSUNG_SP1213C_S02AJ10Y426107-part1 -> ../../sdc1\n|  |-- ata-SAMSUNG_SP1213C_S02AJ10Y426107-part2 -> ../../sdc2\n|  |-- ata-SAMSUNG_SP1213C_S02AJ10Y426107-part3 -> ../../sdc3\n|  |-- ata-SAMSUNG_SP1213C_S02AJ10Y426107-part4 -> ../../sdc4\n|  |-- ata-WDC_WD1200JS-00MHB0_WD-WCANM3479857 -> ../../sda\n|  |-- ata-WDC_WD1200JS-00MHB0_WD-WCANM3479857-part1 -> ../../sda1\n|  |-- ata-WDC_WD1200JS-00MHB0_WD-WCANM3479857-part2 -> ../../sda2\n|  |-- ata-WDC_WD1200JS-00MHB0_WD-WCANM3479857-part3 -> ../../sda3\n|  |-- ata-WDC_WD1200JS-00MHB0_WD-WCANM3479857-part5 -> ../../sda5\n|  |-- ata-WDC_WD1200JS-00MHB0_WD-WCANM3479857-part6 -> ../../sda6\n|  |-- ata-WDC_WD1200JS-00MHB0_WD-WCANM3479857-part7 -> ../../sda7\n|  |-- ata-WDC_WD1200JS-00MHB0_WD-WCANM3479857-part8 -> ../../sda8\n|  |-- ata-WDC_WD1200JS-00MHB0_WD-WCANM3479857-part9 -> ../../sda9\n|  |-- usb-TSSTcorp_CDDVDW_SE-S084C_SATASLIM0000203fe6e-0:0 -> ../../sr1\n|  |-- wwn-0x50024e90010e43d2 -> ../../sdb\n|  |-- wwn-0x50024e90010e43d2-part1 -> ../../sdb1\n|  |-- wwn-0x50024e90010e43d2-part2 -> ../../sdb2\n|  |-- wwn-0x50024e90010e43d2-part5 -> ../../sdb5\n|  |-- wwn-0x50024e90010e43d2-part6 -> ../../sdb6\n|  |-- wwn-0x50f0000000000000 -> ../../sdc\n|  |-- wwn-0x50f0000000000000-part1 -> ../../sdc1\n|  |-- wwn-0x50f0000000000000-part2 -> ../../sdc2\n|  |-- wwn-0x50f0000000000000-part3 -> ../../sdc3\n|  `-- wwn-0x50f0000000000000-part4 -> ../../sdc4\n|-- by-label\n|  |-- BACKUP -> ../../sdb1\n|  |-- DATOS -> ../../sda2\n|  |-- LIBRE_C3 -> ../../sdc3\n|  |-- LOCAL -> ../../sdb5\n|  |-- MEDIA -> ../../sdc4\n|  |-- OPT -> ../../sda6\n|  |-- OPT2 -> ../../sdb6\n|  |-- fedora8 -> ../../sda5\n|  |-- kukenan42 -> ../../sda8\n|  |-- kukenan43 -> ../../sdc1\n|  |-- slack13 -> ../../sda7\n|  `-- slack14 -> ../../sdc2\n|-- by-path\n|  |-- pci-0000:00:1d.7-usb-0:6:1.0-scsi-0:0:0:0 -> ../../sr1\n|  |-- pci-0000:00:1f.2-scsi-0:0:0:0 -> ../../sda\n|  |-- pci-0000:00:1f.2-scsi-0:0:0:0-part1 -> ../../sda1\n|  |-- pci-0000:00:1f.2-scsi-0:0:0:0-part2 -> ../../sda2\n|  |-- pci-0000:00:1f.2-scsi-0:0:0:0-part3 -> ../../sda3\n|  |-- pci-0000:00:1f.2-scsi-0:0:0:0-part5 -> ../../sda5\n|  |-- pci-0000:00:1f.2-scsi-0:0:0:0-part6 -> ../../sda6\n|  |-- pci-0000:00:1f.2-scsi-0:0:0:0-part7 -> ../../sda7\n|  |-- pci-0000:00:1f.2-scsi-0:0:0:0-part8 -> ../../sda8\n|  |-- pci-0000:00:1f.2-scsi-0:0:0:0-part9 -> ../../sda9\n|  |-- pci-0000:00:1f.2-scsi-1:0:0:0 -> ../../sdb\n|  |-- pci-0000:00:1f.2-scsi-1:0:0:0-part1 -> ../../sdb1\n|  |-- pci-0000:00:1f.2-scsi-1:0:0:0-part2 -> ../../sdb2\n|  |-- pci-0000:00:1f.2-scsi-1:0:0:0-part5 -> ../../sdb5\n|  |-- pci-0000:00:1f.2-scsi-1:0:0:0-part6 -> ../../sdb6\n|  |-- pci-0000:00:1f.5-scsi-0:0:0:0 -> ../../sdc\n|  |-- pci-0000:00:1f.5-scsi-0:0:0:0-part1 -> ../../sdc1\n|  |-- pci-0000:00:1f.5-scsi-0:0:0:0-part2 -> ../../sdc2\n|  |-- pci-0000:00:1f.5-scsi-0:0:0:0-part3 -> ../../sdc3\n|  |-- pci-0000:00:1f.5-scsi-0:0:0:0-part4 -> ../../sdc4\n|  `-- pci-0000:03:00.0-scsi-0:0:0:0 -> ../../sr0\n`-- by-uuid\n  |-- 05c2741b-ba40-4e2d-ab76-81a81fab7cda -> ../../sdc4\n  |-- 15bc33aa-18f3-420c-8994-0a135ada26e3 -> ../../sdb6\n  |-- 18DE-A71C -> ../../sda2\n  |-- 3be461c8-f6cd-4c4a-a77f-8970a9f1892c -> ../../sdc3\n  |-- 5C247DF4247DD18E -> ../../sda1\n  |-- 5d39ae0a-cad6-4a0a-9ad1-eb583c6cc2a8 -> ../../sda8\n  |-- 63190f5d-6a45-45f2-a028-7d481928e40b -> ../../sda5\n  |-- 6c652e3e-3e2d-4bd6-94d5-20b3531424d5 -> ../../sda9\n  |-- 725c8ad4-832a-45a8-a441-ed5d218dabe6 -> ../../sdc1\n  |-- bb3d0633-25c6-46e6-9d9e-7b48805848d2 -> ../../sdc2\n  |-- bd4a028d-47d7-4e33-8d22-e2b2725e57c7 -> ../../sda6\n  |-- c03a0ecb-7dec-4c78-8c0a-61add968a93b -> ../../sda7\n  |-- c190c3a0-fd07-4339-bc8a-0822c5eeb2a9 -> ../../sdb5\n  `-- c6c3b5be-7c69-4a32-8fe7-8b56279cdc0e -> ../../sdb1\nComo pueden ver este directorio contiene varios sub-directorios donde se listan todas las particiones por identificador del disco, etiquetas, dirección física del dispositivo y UUID.\nOtras utilidades\nAlgunas utilidades / comandos de Linux que son útiles para las operaciones relacionadas con el sistema de archivos incluyen:\nfdisk : para crear, modificar, eliminar particiones, incluida la creación e impresión de tablas de particiones, etc.\nparted : realiza las mismas operaciones que fdisk e incluso muchas más.\ndf : muestra todos los sistemas de archivos montados en el sistema de archivos de Linux y sus puntos de montaje.\nmount : para montar sistemas de archivos, directorios, cambiar el punto de montaje de un directorio / dispositivo y todo tipo de operaciones de este tipo.\nmkfs : creación y formato de un sistema de archivos. Por lo general, el comando se usa en concatenación con el tipo de formato deseado. Me gusta: mkfs.ext4 para formatear el sistema de archivos con el tipo ext4.\numount : para desmontar el sistema de archivos de una partición.\nGParted / QParted - GUI Parted para sistemas Gnome y KDE.\nDisks : utilidad de software preinstalada en sistemas Linux para administrar particiones a través de GUI.\nFuentes\nhttps://www.tecmint.com/change-modify-linux-disk-partition-label-names/\nhttps://www.monkey-mind.net/software/fatlabel/fatlabel.htm\n\n\n\n",
    "preview": "posts/2021-07-25-renombrar-particiones-en-linux/../../images/edex-ui.png",
    "last_modified": "2021-07-30T14:41:10+00:00",
    "input_file": "renombrar-particiones-en-linux.utf8.md",
    "preview_width": 800,
    "preview_height": 450
  },
  {
    "path": "posts/2021-05-08-como-verificar-puertos-y-procesos-en-linux/",
    "title": "Cómo verificar puertos y procesos en Linux",
    "description": "Muchas veces necesitamos saber que puertos esta escuchando nuestro servidor para usar el cliente y conectar o bien para configurar nuestro firewall y así permitir las conexiones a dicho servicio o simplemente por información. Veremos como podemos consultar en nuestro sistema GNU/linux cuales puertos están siendo utilizados y que servicios o aplicaciones los están usando.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://example.com/josersosa"
      }
    ],
    "date": "2012-09-20",
    "categories": [
      "Linux Recipes"
    ],
    "contents": "\n\nContents\nEl registro de servicios estándar: Archivo “services”\nListado de aplicaciones o servicios activos: “lsof”\nEstado y uso de la red en el equipo local: “netstat”\nEscaneo de puertos de equipos en la red: “nmap”\nIdentificando la aplicación que usa determinado puerto: “fuser”\nIdentificando los ID de procesos: “pidof”\nEjemplos de uso de estos comandos\nQue servicio usa el puerto 138 en el protocolo udp:\nQue puertos usa el servicio avahi-dae:\nQue versión uso en ssh:\nQue servicios tengo escuchando en mi Linux:\n\nAutomatizando estas tareas\nQue servicios uso, ejemplo: lss\nQue servicio usa un puerto dado, por ejemplo: lsw 22\nQue versión tiene mi servicio, por ejemplo: lsv ssh\n\n\nA continuación revisaremos las principales herramientas para identificar los puertos activos y las aplicaciones que los están utilizando. Para poder ejecutar estos comando es necesario tener privilegios de administrador (usuario root) o utilizar el comando sudo, anteponiéndolo a estos comandos.\nEl registro de servicios estándar: Archivo “services”\nPara saber que puertos esta escuchando nuestro servidor podemos consultar el archivo /etc/services en el cual se registran diferentes servicios, el puerto que usa y un pequeño comentario. Este archivo de configuración mantiene el registro de todos los puertos estándar. Por ejemplo, si queremos saber que puerto usa por defecto el servicio ssh haría:\ngrep -i ssh /etc/services\nLa salida del comando anterior sería:\nssh       22/tcp  #Secure Shell Login\nssh       22/udp  #Secure Shell Login\nsshell     614/tcp  #SSLshell\nsshell     614/udp\nx11-ssh     6010/tcp  #Unofficial name, for convenience\nx11-ssh     6010/udp\nListado de aplicaciones o servicios activos: “lsof”\nEl problema que muchas veces el servicio no viene registrado en el archivo services o viene pero no muestra todos los puertos que en realidad escucha. En estos caso podemos utilizar otros programas como lsof o “list open files”. Entre los datos que arroja como salida este programa esta el puerto utilizado, por lo que otras maneras de averiguar el puerto/s que usa nuestra aplicación es:\nlsof -n -i -P | grep '*:'\nPor ejemplo, si quiero saber que puestos escucha el samba haría:\nsudo lsof -n -i -P | grep '*:' | grep -e nmbd -e smbd\nEstado y uso de la red en el equipo local: “netstat”\nOtra manera de lograr nuestro objetivo es utilizando el comando netstat o “network statistics”, de la siguiente manera:\nnetstat -ltunp\nO si queremos el puerto de una aplicación especifica:\nnetstat -ltunp | grep -e smbd -e nmbd\nEscaneo de puertos de equipos en la red: “nmap”\nOtra manera de ver los puertos es usar un escaner que nos de la información del servicio como puede ser nmap. Nmap es un excelente escaner de puertos que nos da mucha información de los servicios/puertos que usa el PC.\nPara escanear con nmap, basta con:\nnmap $HOSTNAME\nLa salida del anterior comando sería por ejemplo:\nPORT STATE SERVICE\n22/tcp open ssh\n80/tcp open http\n139/tcp open netbios-ssn\n445/tcp open microsoft-ds\n901/tcp open samba-swat\n3333/tcp open dec-notes\n4000/tcp open remoteanything\n6667/tcp open irc\n6881/tcp open bittorent-tracker\nComo vemos en la salida, se nos presenta el puerto/protocolo estado servicio, por defecto nmap realiza un escaneo del tipo sT (TCP connect scan) a los puertos por defecto. Si queremos ver mas información de los servicios, versión así como escanear ambos protocolos (tcp y udp) y todos los puertos haríamos:\nnmap -sV -A -O -sT -sU -p - $HOSTNAME\nComo vemos, su salida sera mas extensa. El inconveniente es que nmap sabe el servicio que usa un puerto por el archivo services y muchas veces no viene dicho servicio saliendo algo así como unknown, por ello deberemos de hacer uso de los comandos lsof, netstat y nmap para averiguar información de los puertos, servicios y demás información.\nIdentificando la aplicación que usa determinado puerto: “fuser”\nSi queremos saber a la inversa, o sea, si se el puerto/protocolo y quiero saber que servicio lo esta usando podría usar fuser a parte de los anteriores:\nfuser -n <protocolo> -v <puerto>\nO de forma abreviada:\nfuser puerto/protocolo\nPor ejemplo, si quiero saber que servicio esta usando el puerto 3333/tcp haría:\nfuser -n tcp -v 3333\nEl anterior comando me diría lo siguiente:\nUSER PID ACCESS COMMAND\n3333/tcp: c 6987 F.... eggdrop\nIdentificando los ID de procesos: “pidof”\nEste comando no permite saber cual es el numero de PID del demonio una aplicación, en particular los servicios. Ejemplo para el servicio ssh:\npidof sshd\nEjemplos de uso de estos comandos\nComo resumen pongo algunos ejemplos:\nQue servicio usa el puerto 138 en el protocolo udp:\nfuser -n udp -v 138\nQue puertos usa el servicio avahi-dae:\nsudo lsof -ni -P | grep avahi-dae\nQue versión uso en ssh:\nnmap -sV -p ssh $HOSTNAME\nQue servicios tengo escuchando en mi Linux:\nlsof -ni | grep '*:' | awk '{ print $1 }' | sort -u\nAutomatizando estas tareas\nPara que sea mas fácil, podríamos crear las siguientes funciones y meterlas en el archivo .bashrc:\nvi ~/.bashrc\nQue servicios uso, ejemplo: lss\nfunction lss {\nsudo lsof -ni | grep \"*:\" | awk '{ print $1 }' | sort -u\n}\nQue puertos usa el servicio dado, por ejemplo: lsp amule\nfunction lsp {\nsudo lsof -ni -P | grep \"*:\" | grep $1 | awk '{ print $1,$7,$8 }' | sed -e \"s/*://g\" | sort\n}\nQue servicio usa un puerto dado, por ejemplo: lsw 22\nfunction lsw {\nsudo fuser -n tcp -v $1 || sudo fuser -n udp -v $1\n}\nCual es el numero de proceso de mi servicio, ejemplo: lspi eggdrop\nfunction lspi {\necho -e \"$1 `sudo pidof $1`\"\n}\nQue versión tiene mi servicio, por ejemplo: lsv ssh\nfunction lsv {\nV=`which nmap`\nif [ -z $V ]; then\necho -e \"No dispone del programa nmap\"\nelse\necho \"$1 -> \\\"`sudo nmap -sV -sT -sU -p $1 linux | grep $1 | awk '{print $3,$4,$5,$6,$7,$8,$9,$10}'`\\\"\"\nfi\n}\nUna vez añadida las funciones al .bashrc lo releemos para que se actualicé así:\nsource ~/.bashrc\nA partir de ahora ya podríamos usarlo\nFuente: http://chakal.homelinux.com/blog/?p=101\n\n\n\n",
    "preview": "posts/2021-05-08-como-verificar-puertos-y-procesos-en-linux/../../images/edex-ui.png",
    "last_modified": "2021-05-08T14:46:13+00:00",
    "input_file": {},
    "preview_width": 800,
    "preview_height": 450
  },
  {
    "path": "posts/2021-06-13-controlando-nuestros-robots-con-software-libre-en-android/",
    "title": "Controlando nuestros robots con Software Libre en Android",
    "description": "Una de las ventajas de que nuestro NXT posea integrado un dispositivo bluetooth para comunicación inalámbrica es que puede ser controlado desde dispositivos móviles como tabletas ocelulares. Con ellos podemos controlar el movimiento y observar los estímulos registrados por sus diferentes sensores, incluso podemos hacer uso del acelerómetro de nuestro dispositivo móvil para dirigir el robot con nuestro movimiento, al estilo consola de juegos.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2012-08-22",
    "categories": [
      "Lego Mindstorm",
      "Robotics"
    ],
    "contents": "\n\nContents\nLego TriBot como robot de pruebas\nAplicaciones Android para controlar nuestro robot\nNXT Remote Control\nNXT Controller Plus\nMINDdroid\n\nAplicaciones android\nReferencias de nuevos proyectos:\n\nLego TriBot como robot de pruebas\nEn vista del interés que mi hija de 3 años ha presentado en jugar con su Lego Duplo y su habilidad en el manejo de la tableta, decidí, construir un pequeño robot con el que pudiera interactuar, ya sea para controlarlo desde la tableta y para agarrar objetos y moverlos.\nHay un modelo bastante simple llamado Tribot y cuyas instrucciones podemos descargar de internet. Este robot debe su nombre a que posee solo 3 ruedas, dos delanteras controladas por servos independientes y una trasera de libre movilidad.\nAlgunas imágenes de como quedó:\n\n\n\n\n\n\nAquí unos breves videos de su funcionamiento:\n\n \n\n\n \n\nAplicaciones Android para controlar nuestro robot\nEn la tienda de Google play de aplicaciones Andorid podemos encontrar una gran cantidad de programas desarrollados para el control de robot desde dispositivos móviles. En este conjunto de programas se incluyen algunos que son software libre y con unas funcionalidades bastante completas. La principal ventaja de estas aplicaciones es que no necesitamos programar nuestro robot, dado que la mayoría de ellas, hacen uso de funciones propias del NXT para su control, con lo cual, podemos empezar a probar tan pronto como esté contruido. Es este apartado intentaré hacer una revisión sobre algunos de estas aplicaciones.\n\nNXT Remote Control\nNXT Remote Control es un aplicación de software libre (GPL, aquí la página del proyecto en Google Code) que esta orientada básicamente al control del movimiento del robot de forma remota, a través de varias interfaces de control. Estas funciones de control incluyen el avanzar, retroceder, girar a la izquierda y a la derecha. En una de las interfaces (3 motores) se permite adicionalmente, controlar la tenaza delantera. Las interfaces incluidas contemplan:\nInterfase de control a botones.\nInterfase de orientación por control de angular y radial\nInterfase de control independientes de 2 y 3 motores\nAquí podemos versus pantallas:\nA botones:\nAngular:\nA 3 motores:\n\n\n\nNXT Controller Plus\nNXT Controller Plus es otra aplicación de software Libre (GPL, aquí la página del proyecto en Google Code), que permite el control del movimiento del robot por orientación angular y radial. Adicionalmente registra visualmente las entradas de los sensores conectados a NXT. Tiene una pantalla de configuración bastante simple y completa. Bastante útil para probar el comportamiento del robot y sus sensores.\nAquí les muestro un par de pantallas tomadas de la pagina Google Play:\n \nMINDdroid\nMINDdroid es una aplicacion de software libre (GPL,aquí la página del proyecto en Github) y fue desarrollada y presentada por los mismos representantes del Lego Mindstom. Aparte del control directo de los motores tanto por el método angular/radial como por el posicionamiento de la tableta, a través del uso de su acelerómetro. Otro elemento interesante de esta aplicación es que permite ejecutar programas cargadas en el NXT remotamente y hacer upload de nuevas programas, con lo que se tiene un control bastante completo del robot sin la necesidad de manejarlo de forma directa desde el panel del la NXT.\nAplicaciones android\nAquí les dejo una lista de algunas aplicaciones android para el control de movimiento de robots\nEstas son aplicaciones que me han parecido ingeniosas en el Google Play, pero que aunque son gratis, no son software libre, por lo que no podemos estudiar el como fueron construidas, y por tanto, carecen de interés científico:\nRemote NXT\nNXT GSensor Remote: Este programa realiza el control del robot mediante el movimiento de la tableta o el celular mediante el empleo de su acelerómetro.\nNXT Simple Remote: Otra aplicación para el control de movimiento.\nNXT Numeric Remote: Otra aplicación para el control de movimiento con un teclado numérico.\nNXT Drive\nControle Bluetooth Lego NXT\nMindstorms Control Car\nNXT CONTROL REMOTO REVIEW\nRobot Lego ATC NXT: Control de robots por voz.\nNXT Speech Control:Control de robots por voz.\nHiTechnic Segway Remote\nLEGO NXT Face Follower\nNXT Messenger\nStream-O-Bot\nBlue Tooth R2D2\nReferencias de nuevos proyectos:\nAquí dejo algunos enlaces a blogs sobre proyectos de robótica\nhttp://www.nxt-code.com/\nhttp://blog.electricbricks.com/\n\n\n\n",
    "preview": "posts/2021-06-13-controlando-nuestros-robots-con-software-libre-en-android/../../images/robotics/android_p1030459.jpg",
    "last_modified": "2021-06-29T20:35:22+00:00",
    "input_file": "controlando-nuestros-robots-con-software-libre-en-android.knit.md"
  },
  {
    "path": "posts/2021-05-16-tunneling-tcp-con-ssh/",
    "title": "Tunneling TCP con SSH, asegurando conexiones a traves de redes inseguras",
    "description": "Vamos a ver como conseguir conexiones TCP/IP seguras aunque tengamos  que pasar por una red insegura. En un gran numero de situaciones se nos  presenta esta necesitad, como por ejemplo acceder a un equipo sin IP  pública que se encuentra detrás de una subred o cuando queremos  \"entubar\" o asegurar una conexión a través de Internet o redes  inhalámbricas para pasar algún protocolo o servicio cualquiera de manera segura, como conectarnos a un servidor de correo, o que simplemente  queremos navegar, es decir que no necesariamente se requiere un shell  remoto.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2012-08-18",
    "categories": [
      "Linux Recipes",
      "SSH"
    ],
    "contents": "\n\nContents\nTunneling con SSH\nAccediendo a un servicio Jupyter en la máquina segura\n\nConexión desde el lado inseguro de la red\nConexión desde el lado seguro de la red\n\nPara lograr esto debemos asumir que contamos con el acceso, mediante SSH, a una máquina de confianza, es decir un equipo en una parte “segura” de la red. Puede ser la máquina a la que nos queremos conectar para leer el correo, o el proxy que usamos para navegar, o la máquina que hace de gateway entre la red inalámbrica y la red “alámbrica”. El objetivo es, entonces establecer un puente o túnel, mediante SSH entre nuestra máquina y la máquina “segura”, de manera de protegernos de los peligros de la parte insegura de la red. Más adelante veremos como aprovechar esta conexión SSH, para transmitir protocolos o servicios como si fueran locales.\nTunneling con SSH\nPara establecer este tunel debemos usa la siguiente sintaxis para el comando ssh:\nssh -L puerto_local:maquina_destino:puerto_destino maquina_segura\nCon esto, se establece un shell en la “máquina_segura” creando un túnel entre esta y nuestra “máquina_local”. Sin embargo, lo interesante es que este comando también activa el puerto TCP “puerto_local” en nuestra máquina que hace referencia (como un enlace simbólico) al “puerto_destino” TCP de la “maquina_destino”.\n\n\nhide\n\nlibrary(DiagrammeR)\nDiagrammeR::mermaid(\"graph LR\n  subgraph Máquina Local.\n    A[Cliente] --> B(Puerto local)\n    end\n  subgraph Máquina Segura.\n    D[Serv SSH] \n    end\n  B -.-> D\n  subgraph Máquina Destino.\n    E(Puerto destino_) --> F[Servidor] \n    end\n  D -.-> E\n  \")\n\n\n\n{\"x\":{\"diagram\":\"graph LR\\n\\tsubgraph Máquina Local.\\n    A[Cliente] --> B(Puerto local)\\n    end\\n\\tsubgraph Máquina Segura.\\n    D[Serv SSH] \\n    end\\n\\tB -.-> D\\n\\tsubgraph Máquina Destino.\\n    E(Puerto destino_) --> F[Servidor] \\n    end\\n\\tD -.-> E\\n\\t\"},\"evals\":[],\"jsHooks\":[]}\nLa idea es que mientras esté activa esta conexión SSH o túnel, si nos conectamos a localhost:puerto_local, esa conexión TCP será redirigida a través del túnel SSH y con la seguridad correspondiente, a la máquina_segura, y desde ahí se establecerá una conexión a maquina_destino:puerto_destino.\nAccediendo a un servicio Jupyter en la máquina segura\nEs importante tener en cuenta que si en lugar de maquina_destino, ponemos localhost, estaríamos asumiendo que la “máquina_destino” en la “máquina_segura”. Un de uso prático de esto es el siguiente:\nSupongamos que levantamos uns servicio Jupyter, que usa el puerto 8888, en una máquina virtual en la nube, la cual solo tiene el puerto 22 abierto. Podriamos abier el puero 8888 o el 80 y poner a escuchar nuestro servicio ahí, pero eso dejaría nuestra conexión a Juyter insegura y abierta a posibles ataques. Otra opción es crear un tunel SSH a nuestra máquina para proteger la conexion, de manera que ahora para de acceder al servicio usariamos un puerto local:\n\n\nhide\n\nDiagrammeR::mermaid(\"graph LR\n  subgraph Máquina Local\n  A[Cliente] --> B(Puerto local)\n  end\n  subgraph Máquina Segura.\n    E(Puerto destino) --> F[Servidor]\n  end\n  B -.->|tunel ssh| E\n  \")\n\n\n\n{\"x\":{\"diagram\":\"graph LR\\n  subgraph Máquina Local\\n  A[Cliente] --> B(Puerto local)\\n  end\\n  subgraph Máquina Segura.\\n    E(Puerto destino) --> F[Servidor]\\n  end\\n  B -.->|tunel ssh| E\\n  \"},\"evals\":[],\"jsHooks\":[]}\nObserve que así podemos ejecutar el Jupyter en el servidor remoto y lo accedemos como si se tratara de un servicio local:\nssh usuario@servidor-remoto \"jupyter notebook > ~/jupyter.log &\"\n# esperamos unos segundos para que levante el servicio\nssh -L 8880:servidor-remoto:8888 servidor-remoto\n# ahora podemos acceder al servicio localmente en http://localhost:8880\nRecuerden que para conocer el token que se ha producido automaticamente debemos consultar el log generado por el jupyter:\nssh usuario@servidor-remoto \"cat ~/jupyter.log\"\nConexión desde el lado inseguro de la red\nEjemplos de túneles cuando estamos del lado inseguro de la red (parámetro -L)\nssh -L 8080:localhost:3128 miproxy.segu.ro\nSuponiendo que tengamos acceso SSH a miproxy.segu.ro, y que esta máquina esté ejecutando un proxy (por ejemplo el squid) en el puerto 3128, con este comando conseguimos (además del shell de siempre) que todas las conexiones al puerto 8080 local se vayan por el túnel SSH al puerto 3128 de miproxy.segu.ro. Así que configuramos el navegador para que use como proxy localhost:8080, y en realidad estaremos usando miproxy.segu.ro:3128, solo que la comunicación irá protegida por SSH.\nssh -L 110:mipop3:110 miservidor.segu.ro\nSupongamos que tenemos acceso SSH a miservidor.segu.ro, y una cuenta POP3 en la máquina mipop3, que está en la misma red local que miservidor.segu.ro. O bién no tenemos acceso a mipop3 desde fuera, o bién nos da miedo que nuestro password viaje en pelotas por medio mundo hasta llegar a él. Usando este comando SSH conseguimos que las conexiones al puerto local 110 sean redirigidas a mipop3:110, via miservidor.segu.ro, y la conexión entre la máquina local y miservidor.segu.ro va protegida por SSH.\nConexión desde el lado seguro de la red\nEjemplos de túneles cuando estamos del lado seguro de la red (parámetro -R)\nLa versión con -R es muy parecida, pero el primer puerto que se especifica es remoto y el host:puerto que vienen después se resuelven en local. Por supuesto la re-dirección se hace en sentido contrario.\nEs decir, si hacemos\nssh -R 6110:localhost:110 miservidor.segu.ro\nconseguimos que las conexiones a miservidor.segu.ro:6110 sean redirigidas de forma transparente a través del túnel SSH al puerto 110 local. Así que si en la máquina local tenemos un servidor POP3 funcionando, las máquinas de la parte remota pueden usarlo accediendo al puerto 6110 de miservidor.segu.ro.\nFuente:http://bulma.net/body.phtml?nIdNoticia=1147\n\n\n\n",
    "preview": "posts/2021-05-16-tunneling-tcp-con-ssh/../../images/edex-ui.png",
    "last_modified": "2021-07-30T14:40:57+00:00",
    "input_file": "tunneling-tcp-con-ssh.utf8.md",
    "preview_width": 800,
    "preview_height": 450
  },
  {
    "path": "posts/2021-05-12-como-ejecutar-comandos-remotos-con-ssh/",
    "title": "Cómo ejecutar comandos remotos con SSH",
    "description": "Generalmente estamos acostumbrados a utilizar el comando SSH para  ejecutar aplicaciones a través de una shell interactiva, pero también  podemos hacer que el cliente de SSH ejecute un comando remoto y nos  envíe su salida a la maquina local. En este post muestro este y otros trucos con SSH.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2012-05-12",
    "categories": [
      "Linux Recipes",
      "SSH"
    ],
    "contents": "\n\nContents\nAlgunos trucos para el uso del SSH.\nEjecutando un programa remoto mostrando la salida en la máquina local.\nDescomprimiendo locamente un archivo alojado en una máquina remota.\nCopiando un directorio remoto en la maquina local.\nEjecutar aplicaciones remotas para procesar archivo locales.\n\nAplicaciones remotas con interface gráfica\nEjecutar aplicaciones gráficas remotas con despliegue local.\n\nTransferencia de grandes volúmenes de datos\nComo transferir un directorio a otra máquina comprimiendolo al vuelo.\n\n\nPara lograr esto, basta con poner el comando con todos sus parámetros a continuación del nombre del equipo remoto, por ejemplo para ver el contenido de la carpeta personal del usuario jose en el equipo remoto.ejemplo.com podríamos poner lo siguiente:\n$ ssh  jose@remoto.ejemplo.com comando_remoto\nAlgunos trucos para el uso del SSH.\nEjecutando un programa remoto mostrando la salida en la máquina local.\n$ ssh jose@remoto.ejemplo.com ls\njose@remoto.ejemplo.com's password: \ndoc\ntest.txt\nmisc\nsrc**\nDescomprimiendo locamente un archivo alojado en una máquina remota.\nOpenSSH tiene herramientas para poder transmitir archivos por SSH, pero a pesar de ello, vamos a explotar el echo de que al ejecutar un comando de forma remota el cliente de SSH nos envía su salida, con esto y la creación de una tubería (pipe), podemos extraer el archivo directamente sin tener que bajárnoslo para luego borrarlo:\n$ ssh manolo@remoto.ejemplo.com cat a.tar.gz | tar xvzf -\njose@remoto.ejemplo.com's password:\na\na/a.txt\na/b.txt\na/c.txt**\nCopiando un directorio remoto en la maquina local.\nPara realizar alguna operación mas elaborada como realizar una copia en local de un directorio remoto, como en el ejemplo:\nssh usuario1@servidor.dominio.es \"tar cf - /home/usuario1\" | tar xvf -**\nEjecutar aplicaciones remotas para procesar archivo locales.\nVeámoslo con otro ejemplo, imaginemos que queremos invocar el comando wc en un equipo remoto para contar el número de líneas, palabras y bytes que tiene el archivo test.txt que tenemos almacenado en nuestro disco duro:\n$ cat test.txt | ssh  usuario@remoto.ejemplo.com wc\nusuario@remoto.ejemplo.com's password:\n    5   24   124**\nAplicaciones remotas con interface gráfica\nEjecutar aplicaciones gráficas remotas con despliegue local.\nPara poder ejecutar aplicaciones gráficas remotamente debemos cambiar las siguiente opciones dentro del archivo /etc/ssh/sshd_config:\nAllowAgentForwarding yes\nX11Forwarding yes\nX11DisplayOffset 10\nX11UseLocalhost yes\nUn ejemplo de como abrir una aplicación gráfica:\nssh -X -p 7900 root@localhost xterm\nSuponiendo que el servicio SSH se este escuchando por el puerto 7900. En caso de que deseemos ejecutar aplicaciones remotas es conveniente configurar nuestro servicio SSH en puertos no convencionales. En algunos casos, puede ser necesario algo más de trabajo, ya que al tratar de ejecutar una aplicación remota puede que de el siguiente error:\nssh -X user@IP_servidor_remoto\npassword: ....\nxterm\nxterm:2127): Gtk-WARNING **: cannot open display: localhost:10.0\nEn estos casos tendremos que informar a nuestro equipo local que debemos aceptar el desplieque gráfico desde el servidor remoto, usando xhost así:\nxhost +IP_servidor_remoto\nY luego puede que tengamos que identificar la salida gráfica remota en el servidor remoto, usando la variable de entorno DISPLAY así:\nexport DISPLAY=IP_maquina_local:0.0\nTransferencia de grandes volúmenes de datos\nComo transferir un directorio a otra máquina comprimiendolo al vuelo.\nLa forma más eficiente y segura que conozco es:\n$ tar -c path_a_respaldar/ | gzip | ssh  usuario@ejemplo.com \"tar -zxvf -  --directory /path_equipo_remoto > /path_a_logs/proyects.log\"\nCon esta única instrucción podemos tranferir gran volúmen datos en archivos de un filesystem local a otro remoto, comprimiendolos en el origen y descomprimeinto en el destino para reducir el tiempo de transferencia. Además para los efectos de sistema operativo se está transmitiendo un solo archivo (formato tar.gz) por lo que no tiene que perder tiempo creando un indice, esto puede llevar mucho tiempo cuando se trata de muchos archivos\nFuente: http://sial.org/howto/openssh/publickey-auth/\n\n\n\n",
    "preview": "posts/2021-05-12-como-ejecutar-comandos-remotos-con-ssh/../../images/edex-ui.png",
    "last_modified": "2021-05-16T21:10:05+00:00",
    "input_file": {},
    "preview_width": 800,
    "preview_height": 450
  },
  {
    "path": "posts/2021-06-13-carro-robot-controlado-desde-una-netbook-escolar/",
    "title": "Carro robot controlado desde una netbook escolar",
    "description": "Este proyecto busca controlar nuestro carro robot desde una netbook. El objetivo es experimentar con la movilidad que representa el tener  nuestro robot conectado a una pequeña y liviana computadora pero con  mayores prestaciones que el NXT, tales como la capacidad de  procesamiento, la cámara web y la tarjeta de red WiFi.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2012-04-09",
    "categories": [
      "Lego Mindstorm",
      "Robotics"
    ],
    "contents": "\n\nContents\nEl computador “Canaima”\nIncorporando el Canaimita en el carro robot\nControlando a distancia nuestro robot.\n\nEl computador “Canaima”\n“Canaima Educativo” es un proyecto del Gobierno Bolivariano que tiene por objetivo apoyar la formación integral de las niñas y los niños, mediante la dotación de una computadora portátil escolar con contenidos educativos a los maestros y estudiantes del subsistema de educación primaria conformado por las escuelas públicas nacionales, estadales, municipales, autónomas y las privadas subsidiadas por el Estado\".(Fuente: http://www.canaimaeducativo.gob.ve).\n\n​\nIncorporando el Canaimita en el carro robot\nPara incorporar y conectar el computador, voy a adaptar un pequeño remolque que soporte el peso del mismo. Como lo he mencionado en otro post, aun no he logrado conectar, vía Bluetooth, las aplicaciones hechas con nxt-python al computador por lo que debo recurrir a la conexión USB. Por otro lado, aunque presidiera de la conexión USB y utilizara la Bluetooth, esta ultima tiene mucho menos alcance que una WiFi. Teniendo el computador adjunto al robot, podemos controlarlo en todo un edificio o galpón industrial, vía red inalambrica (WiFi).\n\nControlando a distancia nuestro robot.\nEL control remoto del robot fue implementado mediante el uso de una pantalla remota desde un computador portatil conectado a la Canaimita remolcada por el robot, vía WiFi. La conexión inalambrica se estableció mediante una configuración adhoc para poder prescindir del access point.Para establecer esta conexión utilice la siguiente configuración:\n\\#iwlist wlan0 scan\nifconfig wlan0 down\nsleep 2\niwconfig wlan0 mode Ad-Hoc\niwconfig wlan0 essid 'robotland'\niwconfig wlan0 channel 10\niwconfig wlan0 rate auto\niwconfig wlan0 ap any\nifconfig wlan0 up\nifconfig wlan0 192.168.1.2\nroute add default wlan0\n/sbin/dhcpcd -t 60 wlan0 &\nComo se puede ver, establece una red llamada “robotland” en el canal 10. Podemos ver que canales estan disponibles en nuestro entorno con el comando “iwlist wlan0 scan”. El dispositivo utilizado es wlan0, pero puede variar de computador en computado. Por ultimo, la dirección IP asignada al equipo Canaimita fue 192.168.1.1 y al equipo remoto 192.168.1.2. A continuacion podemos ver una muestra del movimiento de nuestro robot controlado por una netbook Canaimita:\n\n \n\nLa aplicación de control empleada es la descrita en el post sobre el carro robot, y podemos usarla a través de una sesión ssh. Por otro lado aprovechamos la cámara web integrada en la Canaimita para mostrar en vídeo la vista desde el carro a lo largo de sus movimientos:\n\n \n\n\n\n\n",
    "preview": "posts/2021-06-13-carro-robot-controlado-desde-una-netbook-escolar/../../images/robotics/carrorobot_tn_cimg7021.jpg",
    "last_modified": "2021-06-29T19:59:18+00:00",
    "input_file": "carro-robot-controlado-desde-una-netbook-escolar.knit.md"
  },
  {
    "path": "posts/2021-06-13-carro-robot-de-proposito-general/",
    "title": "Carro robot de proposito general",
    "description": "Con este proyecto busco construir y programar un pequeño carro robot  de propósito general que sirva de base para futuros experimentos. La  intención es que tenga la suficiente capacidad de movilidad y tracción  como para funcionar de manera autónoma en una variedad de terrenos, así  como la capacidad de incorporar nuevos sensores que le permitan  incorporar la detección de obstáculos, visión artificial, etc.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2012-04-08",
    "categories": [
      "Lego Mindstorm",
      "Robotics"
    ],
    "contents": "\n\nContents\nSistemas de dirección y tracción.\nProgramación de carro robot con software libre.\n\nSistemas de dirección y tracción.\nUn subsistema importante en la construcción de robot son los sistemas de dirección. En principio nos deben permitir controlar el giro del robot con un solo motor. Para nuestro pequeño modelo utilice un sistema modificado basado en el “Compact pendular steered suspension” que utiliza engranajes de palanca y sin amortiguación (dado que aun no tengo amortiguadores). Aquí podemos ver una demostración en video del funcionamiento de este sistema:\n\n\n \n\nCon respecto al sistema de tracción, podría haber utilizado dos motores, como lo hace muchos modelos parecidos a este, pero he preferido restringir el uso de los motores para poder disponer de ellos en otros experimentos, de hecho, uno de los posibles usos de este modelo sera llevar consigo un brazo robot. Una de las cosas a tomar en cuenta cuando utilizamos un solo motor en el sistema de tracción de nuestro vehículos, es que cuando el mismo gira, las ruedas traseras derecha e izquierda llevan velocidades diferentes. Eso podría ocasionar el rompimiento del eje o de alguno de los engranajes. Para evitar esto utilizamos un diferencial.\n\nA continuación podemos ver los sistemas de dirección y de tracción funcionando en un breve vídeo de pruebas:\n\n \n\nProgramación de carro robot con software libre.\nAlgunos de los inconvenientes del sistema NXT son su capacidad de procesamiento y que no trabaja con números punto flotante, al menos al utilizar el firmware original. Esto es especialmente malo si queremos experimentar con redes neuronales o procesamiento digital de imágenes en visión artificial para el control de nuestro robot. Una manera se superar estos problemas es controlar el robot desde un computador y es así precisamente como funciona el nxt-python. Los programas hechos con esta librería corren en el computador y no en el NXT, por tanto aprovechan todas las capacidades de nuestro PC, pero además pueden leer el valor de los sensores así como activar los motores. Aquí podemos revisar algunas referencias sobre el nxt-python:\n\nhttp://code.google.com/p/nxt-python/\nhttp://home.comcast.net/~dplau/nxt_python/\nhttp://pypi.python.org/pypi/nxt-python/2.2.1\nhttp://www.fing.edu.uy/inco/cursos/fpr/wiki/index.php/API_nxt-python\nPara nuestro primer programa con nxt-python hice un sistema de control, por teclado, desde el computador. Dado que las operaciones estándar de entrada por teclado en el python requieren presionar la tecla Enter, me apoyo en la librería console_io para poder accionar las funciones del robot instantáneamente al presionar ciertas teclas. La operaciones implementadas son Cruce a la derecha (“k”) y a la izquierda (“h”), avanzar (“j”) y retroceder (“m”). Para detener se puede utilizar la tecla ESC o “s” y el “espacio” para mostrar el menú de nuevo:\n#!/usr/bin/env python\nimport nxt.locator\nfrom nxt.motor import *\nimport consola_io\n\ndef menu():\n print \"\"\" \n   Menu de opciones\n   \\----------------\n   \n   1.-  Derecha  k\n   2.-  Izquierda  h\n   3.-  Avanzar  j\n   4.-  Retroceder  m   \n   SP.- Mostrar menu\n   ESC.- Terminar s\n \"\"\"\n \ndef derecha(b):\n  motor_direccion = Motor(b, PORT_B)\n  if Direc[0] - Direc[1] >= -180:\n    Direc[0] = Direc[0] - Direc[1]\n    motor_direccion.turn(-80, Direc[1])\n  print \"Derecha\", Direc[0]\n  \ndef izquierda(b):\n  motor_direccion = Motor(b, PORT_B)\n  if Direc[0] + Direc[1] <= 180:\n    Direc[0] = Direc[0] + Direc[1]\n    motor_direccion.turn(80, Direc[1])\n  print \"Izquierda\", Direc[0]\n\ndef avanzar(b):\n  motor_traccion = Motor(b, PORT_C)\n  if Trac[0] + Trac[1] <= 100:\n    Trac[0] = Trac[0] + Trac[1]\n    if Trac[0] != 0:\n      motor_traccion.run(Trac[0])\n    else:\n      motor_traccion.idle()\n  print \"Avanzar\", Trac[0]\n  \ndef retroceder(b):\n  motor_traccion = Motor(b, PORT_C)\n  if Trac[0] - Trac[1] >= 0:\n    Trac[0] = Trac[0] - Trac[1]\n    if Trac[0] != 0:\n      motor_traccion.run(Trac[0])\n    else:\n      motor_traccion.idle()\n      \n  print \"Retroceder\", Trac[0]\n\ndef detener(b):\n  motor_traccion = Motor(b, PORT_C)\n  Trac[0] = 0\n  motor_traccion.idle()\n  print \"Detener\", Trac \n\n#---------------------\n#- Comienzo programa\n#---------------------\n#  thread.start_new_thread(thread_direction,(\"Thread No:1\",2))\n#  thread.start_new_thread(thread_traction,(\"Thread No:1\",2))\nDirec = [0, 60]\nTrac = [0, 50]\nb = nxt.locator.find_one_brick()\n#-- Sacar menu\nmenu()\n#-- bucle principal\nwhile 1:\n  #-- Leer tecla\n  c = consola_io.getkey()\n  #-- Procesar tecla\n  if  c=='k': \n    derecha(b)\n  elif c=='h': \n    izquierda(b)\n  elif c=='j': \n    avanzar(b)\n  elif c=='m': \n    retroceder(b)\n  elif c=='n': \n    retroceder(b)\n  elif c==' ': \n    detener(b)\n    menu()\n  elif c=='s': \n    detener(b)\n    break  #-- Salir del bucle\n#-- Terminar \nprint \"-- FIN --\"\nEn teoría la librería nxt-python permite que le computador se conecte con el NXT vía USB o Bluetooth, pero esta segunda opción no me ha funcionado hasta ahora. Aquí les dejo un ejemplo del funcionamiento del programa de control por teclado:\n\n \n\n\n\n\n",
    "preview": "posts/2021-06-13-carro-robot-de-proposito-general/../../images/robotics/carrorobot_cimg7003.jpg",
    "last_modified": "2021-06-29T20:19:50+00:00",
    "input_file": "carro-robot-de-proposito-general.knit.md"
  },
  {
    "path": "posts/2021-06-13-brazo-robot-articulado/",
    "title": "Brazo Robot Articulado",
    "description": "Este proyecto consiste en construir y programar un Brazo Robot  articulado. Este tipo de brazos robots son unos de los más utilizados,  en la industria, por su versatilidad. Son capaces de hacer muchos tipos  de movimientos por su similitud con el brazo humano.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2012-04-07",
    "categories": [
      "Lego Mindstorm",
      "Robotics"
    ],
    "contents": "\n\nContents\nBrazo articulado.\nFuncionamiento del brazo articulado.\nConstrucción del brazo robot.\nConclusiones.\n\nBrazo articulado.\nEl brazo robot de tipo articulado, es uno de los más complejos debido a la cantidad de movimientos que pueden realizar y, por tanto, el número de tareas que pueden desempeñar. Su configuración es similar a la del brazo humano y esta constituido por dos secciones rectas que corresponderían al brazo y el antebrazo humano y que a su vez están montados sobre un pedestal giratorio. Estos componentes están conectados entre sí por dos articulaciones giratorias que corresponderían al hombro y al codo respectivamente. Una muñeca esta unida al extremo del antebrazo, con lo que se suman a la estructura varias articulaciones más con la intención de permitir o facilitar el posicionamiento y la orientación de la herramienta.\nFuncionamiento del brazo articulado.\nTodos los robots del tipo industrial están diseñados para realizar trabajo productivo. Este trabajo se realiza mediante el desplazamiento de las diferentes partes que constituyen el cuerpo del robot, a saber: su cuerpo, brazo, muñeca y efector final, a estos elementos los llamaremos segmentos . Los punto de articulación entre cada una de los segmentos, es decir, la base, el hombro, codo y muñeca, se corresponde con los puntos de rotación que le dan al robot sus grados de libertad. El robot articulado posee 4 grados de libertad y cada uno de los cuales requiere de un motor independiente. Esto sin contar con el motor que accione el abrir y cerrar de la mano.\nConstrucción del brazo robot.\nLuego de varios intentos para lograr un poco de estabilidad, cosa difícil de lograr debido al peso de los motores, llegue a un modelo estable. Debido a que el bloque NXT solo cuenta con 3 salidas para el control de efectores, como motores, la pruebas solo se pudieron hacer por partes. Por una parte, experimentos con las articulaciones de brazo: hombro, codo y mucheca. Y por otra el movimiento de la base y el de la mano. A continuación, algunas imágenes:\n\nConclusiones.\nAunque se logro un modelo en tamaño y movimientos similar a lo deseado, el peso de los motores hace difícil el control del los movimientos. Esto se podría resolver optimizando la posición de los motores transfiriendo el trabajo a la base y utilizando ejes y cardanes. Otra posibilidad es utilizar contrapeso en los diferentes ejes aunque esto traiga como consecuencia la reducción de la movilidad.\nOtro problema fue la cantidad de motores necesario para obtener todos lo grados de libertad deseados. Como mencione anteriormente el bloque NXT solo contiene 3 salidas y para este proyecto se requieren, al menos cinco. Una posible solución es construir o adquirir un multiplexor para los motores del NXT (como este por ejemplo)\n\n\n\n",
    "preview": "posts/2021-06-13-brazo-robot-articulado/../../images/robotics/brazorobot_s5030518.jpg",
    "last_modified": "2021-06-13T02:22:04+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-13-robot-seguidor-de-linea/",
    "title": "Robot seguidor de línea (linetracking)",
    "description": "El objetivo de este proyecto es el de construir y programar un robot que oriente su movimiento en función de una línea negra dibujada en el piso. Consiste en un problema típico de control, en el cual nos basamos  en las lecturas de un sensor infrarrojo para activar los motores de dirección y de tracción de un pequeño carro robot contruido en Lego y controlado por un bloque RCX 2.0.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2012-04-06",
    "categories": [
      "Lego Mindstorm",
      "Robotics"
    ],
    "contents": "\n\nContents\nConstrucción del robot\nProgramación del comportamiento del robot\nUna breve demostración\nConclusiones\n\nConstrucción del robot\nLa construcción de carro robot requiere de dos motores y un sensor de luz infrarroja. En vista de que uno de los motores ese dañó hace algún tiempo,he tenido que adaptar un motor de 5v para este experimento. Uno de los motores se utilizará para controlar el sistema de dirección y el otro para el de tracción. El sensor se coloca adjunto al sistema de dirección para al detectar el umbral adecuado de luz que identifique la linea negra, la posición actual indicará la dirección en la cual deba moverse el carro. Para tener retroalimentación del ángulo de giro, adaptaremos un nuevo sensor de giro construido por mi mismo.\n\n\nProgramación del comportamiento del robot\nPara la lógica del comportamiento del robot, he decidido usas el lenguaje NQC, similar a C, multiplataforma, y funciona sobre firmware original del bloque RXC.Aquì dejo algunos enlaces sobre este lenguaje:\nhttp://bricxcc.sourceforge.net/nqc/\nhttp://es.wikipedia.org/wiki/NQC\nhttp://www.donosgune.net/2000/gazteler/prg_leng/NQCgaz.htm\nSe requirió algo de experimentación para identificar los valores adecuados para el umbral que separa la detección de la linea negra de lo que no lo es, también para la identificación de los umbrales de seguridad para el giro de las ruedas en el sistema de dirección. A continuación dejo el código del sistema de control del carro robo:\n\\#define UMBRAL_DER 605 \n\\#define UMBRAL_IZQ 765 \n\\#define CENTRO 690 \n\\#define UMBRAL_LUZ 40 \n\\#define IZQ 1 \n\\#define DER 2 \nint velocidad, __velocidad, direccion; \n \ntask marcha() \n{ \n while (true) \n { \n  __velocidad = velocidad; \n  if (__velocidad > 0) {Fwd(OUT_A);} \n  if (__velocidad < 0) {Rev(OUT_A); __velocidad = -__velocidad;} \n  On(OUT_A); \n  Wait(__velocidad); \n  Off(OUT_A); \n } \n} \n \ntask cruce_der() \n{ \n direccion = DER; \n Fwd(OUT_B); \n while (SENSOR_1 > UMBRAL_DER) \n { \n  On(OUT_B); \n  Wait(1); \n  Off(OUT_B); \n } \n} \n \ntask cruce_izq() \n{ \n direccion = IZQ; \n Rev(OUT_B); \n while (SENSOR_1 < UMBRAL_IZQ) \n { \n  On(OUT_B); \n  Wait(1); \n  Off(OUT_B); \n } \n} \n \n task buscar() \n{ \n int dir = direccion; \n while (true){ \n  if ( dir == DER ){ \n   start cruce_der; \n   Wait(200); \n   start cruce_izq; \n   Wait(200); \n  } else { \n   start cruce_izq; \n   Wait(200); \n   start cruce_der; \n   Wait(200); \n  } \n  if ( dir == DER ){ \n   start cruce_izq; \n   Wait(200); \n   velocidad = -50; \n   start marcha; \n   Wait(30); \n   stop marcha; \n   velocidad = 10; \n   Off(OUT_A); \n  } else { \n   start cruce_der; \n   Wait(200); \n   velocidad = -50; \n   start marcha; \n   Wait(30); \n   stop marcha; \n   velocidad = 10; \n   Off(OUT_A); \n  } \n \n/*  velocidad = -50; \n  start marcha; \n  Wait(50); \n  stop marcha; \n  velocidad = 50;*/ \n } \n} \n \ntask main() \n{ \n velocidad = 10; \n direccion = DER; \n SetSensor(SENSOR_2,SENSOR_LIGHT); \n SetSensorMode(SENSOR_1, SENSOR_MODE_RAW); \n SetDirection(OUT_A, OUT_FWD); \n SetPower(OUT_A, 7); \n SetDirection(OUT_B, OUT_FWD); \n SetPower(OUT_B, 5); \n start marcha; \n// Wait(500); \n// Off(OUT_A); \n// stop marcha; \n while (true) \n { \n  if (SENSOR_2 > UMBRAL_LUZ) \n  { \n   stop marcha; \n   Off(OUT_A); \n   start buscar; \n   until (SENSOR_2 <= UMBRAL_LUZ) Wait(20); \n   stop buscar; \n   stop cruce_izq; \n   stop cruce_der; \n   Off(OUT_B); \n   velocidad = 10; \n   start marcha; \n  } \n  velocidad = 10; \n } \n \n/* start marcha; \n Wait(300); \n stop marcha; \n Off(OUT_A); \n start cruce_der; \n Wait(300); \n start cruce_izq; \n Wait(300); \n start cruce_der; \n Wait(300); \n start cruce_izq; \n Wait(300); \n start cruce_der; \n Wait(300); \n start cruce_izq; \n Wait(100); \n*/ \n  \n} \nUna breve demostración\nAquí dejo un pequeño video. Pido disculpas por la calidad pero fue tomado con el célular:\n\n \n\nConclusiones\nLa lógica de control funciona bastante bien en general excepto para los caso de giros muy pronunciados. Para resolver este problema se podría modificar el modelo del carro de manera de permitir un mayor rango de giro de la ruedas delanteras.\n\n\n\n",
    "preview": "posts/2021-06-13-robot-seguidor-de-linea/../../images/robotics/linetracking_rcx_tn_s5030572.jpg",
    "last_modified": "2021-06-29T20:21:49+00:00",
    "input_file": "robot-seguidor-de-linea.knit.md"
  },
  {
    "path": "posts/2021-06-13-adaptando-un-nuevo-motor-al-rcx/",
    "title": "Adaptando un nuevo motor al RCX",
    "description": "En el desarrollo de experimentos con en Lego MindStorm, el primer problema que se me presentó fue la necesidad de incorporar más motores. Aquí  presento un solución sencilla a este problema: Incorporar un nuevo  motor.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2012-04-05",
    "categories": [
      "Lego Mindstorm",
      "Robotics"
    ],
    "contents": "\n\nContents\nUn Motor eléctrico de 5v\nCompensación de la fuerza y velocidad del motor\n\nMotor adaptado al RCXUn Motor eléctrico de 5v\nCualquier motor eléctrico de 5v como el que esta presente en muchos juguetes, es una opción perfecta para ser incorporado en los modelos de robots. Basta con conectar las entradas eléctricas de motor a un par de tornillos pequeños, de manera que sirvan para encajar con los cables conectores de lego.\n\nCompensación de la fuerza y velocidad del motor\nEl problema que se presenta con esta adaptación es que el motor funciona con un numero de revoluciones muy alto, al menos para los modelos que queremos construir con ellos. La manera de resolverlo es adjuntar un sistema de engranajes que disminuya la velocidad de giro mientras aumenta su fuerza.Este mecanismo se muestra en la foto:\n\n\n\n\n",
    "preview": "posts/2021-06-13-adaptando-un-nuevo-motor-al-rcx/../../images/robotics/motor_rcx_tn_motor_rcx_s5030551.jpg",
    "last_modified": "2021-06-13T02:07:58+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-13-creacion-de-un-sensor-de-angulo-de-giro/",
    "title": "Creación de un sensor de ángulo de giro",
    "description": "Después de experimentar bastante con las posibilidades del Lego  MindStorm, comienzan a surgir la necesidad de contar no otros sensores y efectores, con los cuales construir nuevos proyectos. Una de estas  carencias es la posibilidad de contar con un medidor del ángulo de giro.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2012-03-25",
    "categories": [
      "Lego Mindstorm",
      "Robotics"
    ],
    "contents": "\n\nContents\nInsumos para la construcción del sensor de ángulo.\nConexión con el bloque RCX o NXT.\n\nInsumos para la construcción del sensor de ángulo.\nLos sensores que maneja el RCX y el NXT son analógicos y básicamente se manejan por señales que se miden el voltios dentro del rango 0 volt a 5 volt. Para la construcción de nuestro sensor de ángulos nos basaremos en la adaptación de una resistencia variable del tipo de manivela. Otro insumo serán dos pequeños tornillos que no servirán como contactos para el cable de conexión con el RCX.\n\nConexión con el bloque RCX o NXT.\nPara conectar nuestro nuevo sensor al bloque RCX basta con conectar cualquier cable de conexión a una de las entradas de sensores de bloque RCX. Para el caso del bloque NXT recomiendo utilizar el cable conversor 8528 y utilizar el sensor de giro como si fuese un sensor de luz.\n\n\n\n\n",
    "preview": "posts/2021-06-13-creacion-de-un-sensor-de-angulo-de-giro/../../images/robotics/robot_tn_s5030552.jpg",
    "last_modified": "2021-06-13T02:02:52+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-18-algoritmo-de-error-o-back-propagation/",
    "title": "Algoritmo de Retropropagación del Error o Back-propagation",
    "description": "Una guía sobre el algoritmo de Retropropagación del Error o Back propagation, utilizado para el entrenamiento de Redes neuronales multicapa. Este es uno de los más importantes algoritmos de entrenamiento supervisado de redes neuronales y a es utilizado para un gran número de aplicaciones.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2011-08-31",
    "categories": [
      "Data Science",
      "Teaching",
      "Machine Learning",
      "Neural Networks"
    ],
    "contents": "\n\nContents\nINTRODUCCIÓN\nTOPOLOGÍA DE LA RED\nEL ALGORITMO “BACKPROPAGATION”\nAPLICACIONES DE EJEMPLO.\n\nINTRODUCCIÓN\nAdemás de la capacidad de memorizar otro tipo de computo que ocurre en el sistema nervioso central consiste en aprender reacciones a estímulos. La clase de redes neuronales artificiales que ejecuta este tipo de computo suele diferir radicalmente de los dispositivos de memoria, en particular presentan conexiones sinápticas asimétricas (en algunos casos unidireccionales) lo que impide la aplicación de formalismos de estudio del tipo físico (termodinámica de sistemas en equilibrio) para su estudio. Esta clase de dispositivos suelen denominarse Redes neuronales cibernéticas.\nLas redes neuronales a capas pertenecen a la clase de redes cibernéticas y son las mejor estudiadas, aunque no con un enfoque tan general como el de las redes de Hopfield.\nEn estas redes la información “fluye” unidireccionalmente desde una capa de entrada constituida por “elementos sensores” hasta otra capa de unidades de procesamiento (UPs), generalmente neuronas motoras, en las cuales se manifiesta la respuesta o salida. En su recorrido la información es procesada parcialmente por diferentes capas intermedias de UPs.\nEn términos matemáticos puede pensarse que la relación entrada-salida define una correspondencia (relación) y la red neuronal a capas provee una representación de esta correspondencia. Por tal razón suelen también denominarse redes de correspondencias o relaciónales.\nEn este trabajo nos concentraremos en dos redes neuronales a capas: el perceptron generalizado y la red de funciones de base radial (RBF) estas arquitecturas son suficientemente poderosas para cualquier tarea del tipo considerado, es por esta razón que también son considerados como un aproximador universal de funciones de gran utilidad en problemas no linealmente separables y no lineales en general.\nTOPOLOGÍA DE LA RED\nAdemás consideraremos solo redes de una capa escondida (intermedia) como se ilustra a continuación:\nimage-20210721093440374La notación es que los subíndices \\(i\\) se refieren a las salidas, \\(j\\) a capa oculta y \\(k\\) a la entrada.\nCada capa de estas redes puede tener un numero arbitrario de UPs, estas solo se interconectan con las UPs de la capa siguiente (no existe interconexión en una misma capa o con UPs en capas arbitrarias)\nla salida de cada UP. es conectada a la entrada de cada UP. en la capa siguiente. Así mismo cada componente del patrón de entrada es comunicado a cada UP. de la primera capa.\nEn general la capa de entrada no se cuenta como tal ya que no procesa la información. La única tarea que realiza es la de distribuir el patrón de entrada a todas las unidades de la capa intermedia. Las entradas siempre permanecen ancladas a un valor particular. Estos pueden ser valores binarios, bipolares o reales preferiblemente normalizados.\nComo antes, m denota a dimensionalidad del patrón de entrada, \\(n\\) la del patrón de salida y \\(p\\) el número de patrones de entrenamiento.\nEl computo que realizan las UPs escondidas en el perceptron generalizado es:\n\\[\nV_{j}=f\\left(h_{j}^{\\mu}\\right)=f\\left(\\sum_{k} w_{j k} x_{k}^{\\mu}\\right)\n\\] mientras que las UPs de salida: \\[\nO_{i}=f\\left(\\sum_{j} W_{i j} V_{j}\\right)\n\\] en todos los casos la función de transferencia es o la sigmoide simple (rango entre 0 y 1) o la bipolar (rango entre –1 y 1):\n\\[\nf(x)=\\frac{1}{1+\\exp (-\\alpha x)} \\text { o } f(x)=\\tanh (x)\n\\] Estas funciones tienes las características comunes de ser continuas y derivables para todo x, así mismo mantienen un valor de inactividad (0 ó -1) para los valores de x menores al llamado umbral de activación, alrededor del cual la función crece hasta saturarse en el valor máximo de activación (1). Para obtener la forma bipolar basta con calcula la expresión 2f(x)-1,con f(x) las funciones ya descritas.\nimage-20210718114747539El computo que realizan las UPs escondidas en la red de funciones de base radial es:\n\\[\nV_{j}=f\\left(-\\sum_{k} \\frac{\\left(x_{k}^{\\mu}-w_{k}\\right)^{2}}{2 \\sigma^{2}}\\right)\n\\] mientras que las UPs de salida:\n\\[\nO_{i}=\\sum_{j} W_{i j} V_{j}\n\\] la función de transferencia de las UPs en la capa escondida es típicamente una exponencial conformando una gaussiana (función de base radial):\n\\[\nf(x)=\\exp (x)\n\\]\nEn todas las expresiones anteriores no se considera explícitamente el umbral que puede incluirse complementando al patrón de entrada con una componente adicional de valor 1 y agregando en la capa intermedia una unidad adicional con actividad constante de uno. Esta modificación no altera el algoritmo pero si incluye en cada capa un nuevo peso que será calculado junto con el resto de los pesos sinápticos y que funge como termino independiente en el argumento de la función de transferencia provocando su desplazamiento horizontal.\nEL ALGORITMO “BACKPROPAGATION”\nEl algoritmo de aprendizaje en este tipo de redes es supervisado y provee de un método para ajustar los pesos sinápticos de tal forma de que la red sintetize la correspondencia entre los pares de patrones (xi,yi) en el conjunto de entrenamiento.\nEl algoritmo de entrenamiento mas popular es el llamado “retropropagacion del error” (error backpropagation) el cual ha sido reinventado una serie de veces por diferentes autores, Brison y Ho en 1969, Werbos en 1974, Parker en 1985, y Rumelhart, Hinton y Williamsen 1986.\nLa base de este algoritmo es simplemente el método de descenso de gradiente que se emplea para optimizar una función de calidad de la ejecución de la red. La usada mas comúnmente es:\n\\[\nE(\\vec{w})=\\frac{1}{2} \\sum_{\\mu i}\\left(y_{i}^{\\mu}-O_{i}^{\\mu}\\right)^{2}\n\\] Esta función es evidentemente derivable y por su construcción corresponde a un paraboloide n-dimensional cóncavo hacia arriba, lo cual garantiza geométricamente que tiene mínimo. Un ejemplo de esta estructura geométrica para el caso bidimensional es la siguiente:\nimage-20210718114948715Utilizando las expresiones de los cómputos que realizan las UPs en las redes consideradas podemos escribir las siguientes relaciones para las salidas producidas.\nPerceptron:\n\\[\nO_{i}=f\\left(\\sum_{j} W_{i j} f\\left(\\sum_{k} w_{j k} x_{k}^{u}\\right)\\right)\n\\] RBF:\n\\[\nO_{i}=\\sum_{j} W_{i j} f\\left(-\\sum_{k} \\frac{\\left(x_{k}^{\\prime \\prime}-w_{j k}\\right)^{2}}{2 \\sigma_{k}^{2}}\\right)\n\\] En esencia esto es todo lo que hay detrás de la retropropagacion. No obstante la forma que resulta para las expresiones de modificación de los pesos son de gran importancia practica. Sea el perceptron,\nconsideremos primero la interconexión entre capa escondida y de salida:\n\\[\n\\begin{gathered}\n\\Delta W_{i j}=-\\eta \\frac{\\partial E}{\\partial W_{i j}}=\\eta \\sum_{\\mu}\\left(y_{i}^{\\mu}-O_{i}^{\\mu}\\right) f^{\\prime}\\left(\\sum_{j} W_{i j} V_{j}\\right) V_{j}^{\\mu} \\\\\n=\\eta \\sum_{\\mu} \\delta_{i}^{\\mu} V_{j}^{\\mu}\n\\end{gathered}\n\\] Este resultado es idéntico al del perceptron simple de una sola capa con la salida *v**j* de la capa escondida jugando el papel de patrón de entrada.\nAl considerar a continuación la conectividad capa de entrada - capa escondida se ha de derivar con respecto a \\(W_{jk}\\) variable implícita en el error.\nEmpleando la regla de la cadena:\n\\[\n\\begin{aligned}\n&\\Delta w_{j k}=-\\eta \\frac{\\partial E}{\\partial w_{j k}}=\\eta \\sum_{\\mu} \\frac{\\partial E}{\\partial V_{j}^{\\mu}} \\frac{\\partial V_{j}^{\\mu}}{\\partial w_{j k}} \\\\\n&=\\eta \\sum_{\\mu}\\left(y_{i}^{\\mu \\prime}-O_{i}^{\\mu}\\right) f^{\\prime}\\left(\\sum W_{j} V_{i}\\right) W_{j} f^{\\prime}\\left(\\sum_{k} w_{\\mu} x_{i}^{\\mu}\\right) x_{k}^{\\mu} \\\\\n&=\\eta \\sum_{\\mu i} \\delta_{i}^{\\mu} W_{i j} f^{\\prime}\\left(\\sum_{k} w_{j k} x_{k}^{\\mu}\\right) x_{k}^{\\mu} \\\\\n&=\\eta \\sum_{\\mu} \\delta_{j}^{\\mu} x_{k}^{\\mu}\n\\end{aligned}\n\\] Donde se ha definido:\nCon lo que ambas expresiones para la actualización de los pesos sinápticos tienen la misma forma pero con distintas definiciones de los \\(\\delta_s\\).\nPor esta razón en la literatura también se encuentra el nombre de regla delta generalizada para este algoritmo de aprendizaje.\nConsideremos ahora el mismo calculo pero para la red de RBF. Para la interconexión entre capa escondida y de salida:\n\\[\n\\begin{gathered}\n\\Delta W_{i j}=-\\eta \\frac{\\partial E}{\\partial W_{i j}}=\\eta \\sum_{\\mu}\\left(y_{i}^{\\mu}-O_{i}^{u}\\right)\\left(\\sum_{j} W_{i j} V_{j}\\right) V_{j}^{\\mu} \\\\\n=\\eta \\sum_{\\mu} \\delta_{i}^{\\mu} V_{j}^{\\mu}\n\\end{gathered}\n\\] Donde se ha definido:\n\\[\n\\delta_{i}^{\\mu}=\\left(\\sum_{j} W_{i j} V_{j}\\right)\\left(y_{i}^{\\mu}-O_{i}^{u}\\right)\n\\] Consideremos ahora el caso de los valores medios en las RBFs gaussianas:\nFinalmente el caso de las varianzas \\(\\sigma\\) en las RBFs gaussianas:\n\\[\n\\Delta \\sigma_{k}=-\\eta \\frac{\\partial E}{\\partial \\sigma_{k}}=\\eta \\sum_{\\mu} \\frac{\\partial E}{\\partial V_{j}^{\\mu}} \\frac{\\partial V_{j}^{\\mu}}{\\partial \\sigma_{k}}\n\\] En general es útil emplear constantes de aprendizajes diferentes para cada parámetro. Estas han de determinarse experimentalmente.\n\\[\n\\begin{aligned}\n\\Delta w_{j k}=& \\eta_{w} \\sum_{\\mu i}\\left(y_{i}^{\\mu}-O_{i}^{\\mu}\\right)\n\\left(\\frac{\\left(x_{k}^{\\mu}-w_{j k}\\right)}{\\sigma_{k}^{2}} W_{i j} \\exp \\left(-\\sum_{h} \\frac{\\left(x_{h}^{\\mu}-w_{j h}\\right)^{2}}{2 \\sigma_{h}^{2}}\\right)\\right.\\\\\n\\Delta \\sigma_{k}=& \\eta_{\\sigma} \\sum_{\\mu i}\\left(y_{i}^{\\mu}-O_{i}^{\\mu}\\right)\n\\left(\\sum_{h} \\frac{\\left(x_{k}^{\\mu}-w_{h k}\\right)^{2}}{\\sigma_{k}^{3}} W_{i j} \\exp \\left(-\\sum_{h} \\frac{\\left(x_{h}^{\\mu}-w_{j h}\\right)^{2}}{2 \\sigma_{h}^{2}}\\right)\\right.\n\\end{aligned}\n\\] En general con un número arbitrario de capas escondidas el algoritmo de backpropagation siempre actualiza los pesos sinápticos con una regla de la forma:\n\\[\n\\Delta W_{p q}=\\eta \\sum_{\\mu} \\delta_{\\text {salida }}^{\\mu} \\cdot V_{\\text {entrada }}\n\\] Donde entrada y salida refieren a las terminaciones \\(p\\) y \\(q\\) correspondientes. Y \\(V\\) refiere a la salida-activación de la capa escondida o entrada real. El significado de \\(\\delta\\) depende de la capa que esta siendo tratada.\nLa ecuación anterior descree la regla de actualización de los pesos sinápticos como una suma sobre todos los patrones de entrenamiento \\(\\mu\\). Sin embargo una metodología frecuentemente usada es el entrenamiento incremental en el que se le presenta a la red un patrón a la vez, esto evidentemente disminuye el costo computacional de la función o regla de actualización de pesos en cada paso. Si a la vez los patrones son presentado en un orden aleatorio esto produciría un camino igualmente aleatorio sobre el espacio de los pesos permitiendo así una mayor exploración sobre la superficie de costo o error. La eficiencia relativa de ambas opciones dependerá del problema, sin embargo la experiencia indica que la metodología incremental mejora el entrenamiento en la mayoría de los casos, especialmente en la situaciones donde el conjunto de entrenamiento es muy regular o redundante.\nComo comentario final es útil anotar que al emplear la red de RBF con el algoritmo de aprendizaje de retropropagación del error ha de cuidarse la selección de los valores iniciales de los parámetros. En particular los valores medios han de estar en el rango de valores de la data (hasta es bueno seleccionar algunos patrones de entrada como valores iniciales para estos parámetros) por su parte para los valores iniciales de las varianzas es conveniente seleccionar valores del orden de la varianza de la data o en su defecto valores entre 0.5 y 1 .\nExisten otros esquemas más eficientes para entrenar estas redes de RBF. En general se trata de combinaciones de entrenamiento supervisado para las UPs de la capa de salida con metodologías no-supervisadas para el entrenamiento de los parámetros de las UPs de la capa escondida.\nLa eficiencia de las redes de RBF radica precisamente en estos esquemas mixtos de entrenamiento que reducen considerablemente su complejidad temporal. Permitiendo una mayor experimentación en la entonación de la red.\nAPLICACIONES DE EJEMPLO.\nLABERINTO: Entrenaminto de una red neuronal para salir de un laberinto específico.\nimage-20210718115517555FRONTON: entrenamiento de una RNA para controlar el movimiento de la raqueta en el juego del frontón en 2D y 3D.\nimage-20210718115533101PENDULO INVERTIDO: entrenamiento de una RNA para controlar el sistema del pendulo invertido\nimage-20210718115552020\n\n\n",
    "preview": "posts/2021-07-18-algoritmo-de-error-o-back-propagation/../../images/simulacion-dalton.png",
    "last_modified": "2021-07-21T17:05:09+00:00",
    "input_file": "algoritmo-de-error-o-back-propagation.utf8.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-05-09-calculo-de-probabilidades-y-combinatorias-en-linea-de-comandos/",
    "title": "Cálculo de probabilidades y combinatorias por línea de comandos",
    "description": "Mediante la herramienta \"bc\" es posible contar con un poderosa calculadora desde la línea de comandos en Linux, con la que podemos realizar complejos cálculos de probabilidades. Esta Calculadora nos permite trabajar con precisión infinita en diversas bases, incluso podemos predefinir funciones para el calculo de combinatorias y funciones de probabilidad para las variables aleatorias con nombre propio, y esta es, precisamente, la razón de este post.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2011-08-30",
    "categories": [
      "Linux Recipes"
    ],
    "contents": "\n\nContents\nEl comando “bc”\nCálculo de combinatorias y probabilidades\nReferencias\n\nEl comando “bc”\nPara llamar a la aplicación bc escribimos desde la consola la siguiente instrucción:\n$ bc -il \nCon esta sentencia convocamos nuestra calculadora en modo interactivo (-i) y enlazando la librería matemática (-l)\nPara obtener la lista completa de parámetros de esta aplicación, la ejecutamos:\n$ bc --help\nusage: bc [options] [file ...]\n  -h  --help         print this usage and exit\n  -i  --interactive  force interactive mode\n  -l  --mathlib      use the predefined math routines\n  -q  --quiet        do not print initial banner\n  -s  --standard     non-standard bc constructs are errors\n  -w  --warn         warn about non-standard bc constructs\n  -v  --version      print version information and exit\nSi queremos incluir cálculos matemáticos dentro de un script de Linux es necesario pasar las formulas al comando bc, para eso podemos usar un pipeline, así:\n#!/bin/bash \necho 'scale=4; 10/3' | bc -l\nCálculo de combinatorias y probabilidades\nPara incorporar las funciones de cálculo de combinatorias debemos definir las correspondientes funciones en el ambiente de bc, también podemos pre-cargarlas a través de un archivo donde ya estén estas codificadas. Yo he preparado una versión de este archivo, que he llamado bc_defines.bc que pueden descargar de este enlace.\nAquí el contenido de este archivo:\npi = 4*a(1)\nnep = e(1)\ndefine fact (x) {\n  if (x <= 1) return (1);\n  return (fact(x-1) * x);\n  }\ndefine comb (n,x) {\n  return fact(n)/(fact(n-x)*fact(x))\n  }\ndefine poisson (s,x) {\n  return e(-s)*s^x/fact(x)\n  }\ndefine apoisson (s,x) { suma=0; for (i=0;i<=x;i++){ suma=suma+poisson(s,i)}; return suma}\n\ndefine binomial (n,p,x) {\n  return comb(n,x)*p^x*(1-p)^(n-x)\n  }\ndefine abinomial (n,p,x) { suma=0; for (i=0;i<=x;i++){ suma=suma+binomial(n,p,i)}; return suma}\n\ndefine geometrica (p,x) {\n  return p*(1-p)^x\n  }\ndefine ageometrica (p,x) { suma=0; for (i=0;i<=x;i++){ suma=suma+geometrica(p,i)}; return suma}\n\ndefine binomialneg (n,p,x) {\n  return comb(n+x-1,x)*p^n*(1-p)^x\n  }\ndefine abinomialneg (n,p,x) { suma=0; for (i=0;i<=x;i++){ suma=suma+binomialneg(n,p,i)}; return suma}\n\ndefine hipergeometrica (n,m,k,x) {\n  return comb(m,x)*comb(k,n-x)/comb(m+k,n)\n  }\ndefine ahipergeometrica (n,m,p,x) { suma=0; for (i=0;i<=x;i++){ suma=suma+hipergeometrica(n,m,p,i)}; return suma}\nPara ejecutar bc con las funciones que predefinimos escribimos:\n$ bc -il bc_defines.bc\nEn el, se implementan una serie de funciones que describo a continuación:\ncomb (n,x): Combinaciones de n en x.\npoisson (s,x): Función de probabilidad de la Poisson en x con parámetro s.\napoisson (s,x): Función de probabilidad acumulada de la Poisson en x con parámetro s.\nbinomial (n,p,x): Función de probabilidad de la Binomial en x con parámetros n y p.\nabinomial (n,p,x): Función de probabilidad acumulada de la Binomial en x con parámetros n y p.\ngeometrica (p,x): Función de probabilidad de la Geométrica en x con parámetro p.\nageometrica (p,x): Función de probabilidad acumulada de la Geométrica en x con parámetro p.\nbinomialneg (n,p,x): Función de probabilidad de la Binomial Negativa en x con parámetros n y p.\nabinomialneg (n,p,x): Función de probabilidad acumulada de la Binomial Negativa en x con parámetros n y p.\nhipergeometrica (n,m,k,x): Función de probabilidad de la Hipergeométrica en x con parámetros n, m y k.\nahipergeometrica (n,m,p,x): Función de probabilidad acumulada de la Hipergeométrica en x con parámetros n, m y k.\nReferencias\nCálculo numérico con bc\nCalculadora de línea de comandos\nEspero que les sirva…\n\n\n\n",
    "preview": "posts/2021-05-09-calculo-de-probabilidades-y-combinatorias-en-linea-de-comandos/../../images/tn_bc.jpg",
    "last_modified": "2021-05-10T02:05:44+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-29-guias-y-ejercicios-de-probabilidad-y-estadistica/",
    "title": "Guías y ejercicios prácticos de Probabilidad y Estadística",
    "description": "Material de apoyo para la materia de probabilidad y estadística de la Escuela de Computación de la UCV, recolectado o escritos por el  personal docente de la materia.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://example.com/josersosa"
      }
    ],
    "date": "2011-07-30",
    "categories": [
      "Teaching",
      "Statistic"
    ],
    "contents": "\n\nContents\nSílabo de la materia\nBibliografía\nGuias de teoría\nEjercicio de práctica\nOtros recursos\n\nTodos estos archivos pueden encontrarse en la pagina oficial de la asignatura, sin embargo en ocasiones no ha estado disponible, por lo que decidí colocar una espejo aquí:\nSílabo de la materia\nNota informativa\nBibliografía\nEliezer Correa, “Notas de Probabilidad”\nG. Canavos, “Probabilidad y Estadística”\nP. Meyer, “Probabilidad y Aplicaciones en Estadística”. Addison-­‐Wesley Ib.. (1973, 1986 y 1992).\nW. Mendenhall, D. Wackerly, R. Scheaffer, “Estadística Matemática con Aplicaciones”. (1ra. y 2da. Edición). Grupo Edit. Iberoamérica (1994).\nR. Walpole y R. Myers, “Probabilidad y Estadística” (4ta. Edición). Mc Graw Hill (1992).\nMilton Susan, Arnold Jesse. “Probabilidad y Estadística con aplicaciones para ingeniería y ciencias computacionales”. Mc Graw Hill. 2004.\nRoss Sheldon, “Introduction to Probability Models”. Academic Press.\nGuias de teoría\nGuía teórica Capítulo I: Conceptos básicos de conteo y probabilidades\nGuía teórica Capítulo II: Probabilidades condicionales, Ley de probabilidades totales, Regla de Bayes\nGuía teórica Capítulo III: Variables aleatorias, conceptos generales\nGuía teórica Capítulo IV: Variables aleatorias discretas con nombre propio\nGuía teórica Capítulo V: Variables aleatorias continuas con nombre propio\nGuía teórica Capítulo VI: Teorema Central del límite\nGuía teórica Capítulo VII: Variables aleatorias conjuntas\nEjercicio de práctica\nPráctica 0: Repaso de combinatoria y probabilidades condicionales\nPráctica 1: Variables Aleatorias [Publicada]\nPráctica 2: Distribuciones de variables aleatorias discretas con nombre propio.\nPráctica 3: Variables aleatorias continuas con nombre propio\nPráctica 4: Variables aleatorias distribuidas de manera conjunta\nPráctica 5: Práctica de TCL y Ley de Grandes números\nPráctica 6: Intervalos de confianza (otra versión)\nPráctica 7: Prueba de hipotesis.\nPráctica 8: Cadenas de Markov.\nPráctica 9: Confiabilidad\nOtros recursos\nTabla de valores de la distribución Normal: Esta tabla se utilizará para resolver los problemas que involucren a la Normal\nTabla de valores de la distribución T de Student: Esta tabla se utilizará para resolver los problemas que involucren a la T de Student\nFórmulas Fdp: Resumen con las fórmulas de las principales variables aleatorias con nombre propio vistas en clase.\nAlgunas evaluaciones con soluciones: ejercicio práctico, quiz, quiz, quiz, quiz, parcial,\n\n\n\n",
    "preview": "posts/2021-06-29-guias-y-ejercicios-de-probabilidad-y-estadistica/../../images/stats-class.png",
    "last_modified": "2021-06-29T23:05:54+00:00",
    "input_file": "guias-y-ejercicios-de-probabilidad-y-estadistica.knit.md",
    "preview_width": 640,
    "preview_height": 480
  },
  {
    "path": "posts/2021-06-12-robots-hechos-con-lego-mindstorms-nxt/",
    "title": "Robots hechos con Lego Mindstorms NXT",
    "description": "Hace algún tiempo compre la versión 2 del increíble \"Lego Mindstorms\". Fue diseñado y desarrollado originalmente entre LEGO y el  MIT, como un juguete para motivar a los niños (12 años +/-) a  interesarse por la robótica. Sin embargo se ha convertido en los últimos años en un herramienta poderosa para la modelación y prototipado de robots.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://josersosa.github.io/personalweb/"
      }
    ],
    "date": "2011-07-29",
    "categories": [
      "Lego Mindstorm",
      "Robotics"
    ],
    "contents": "\n\nContents\nLego Mindstorm NTX v2.0\nEl bloque NXT\nMi primer Robot NXT\nReferencias\nEjemplos de algunos videos\n\nLego Mindstorm NTX v2.0\nA primera vista tiene mucha semejanza con otros Legos Mechanics, sin embargo el Lego Mindstorm trae buena cantidad de piezas moviles como engranajes, poleas, ruedas, barras y en suma, más de 500 piezas de varios tamaños. Pero lo que realmente nos permite construir robos con este juguete, son la piezas que nos permiten introducir “inteligencia” a nuestros modelos así como poder accionar movimientos en función de los estímulos del ambiente.\nEstas piezas son los sensores, los efectores y un microprocesador, llamado NXT sobre el que podremos programar las aplicaciones que controlarán nuestros robots.\n\nSensores:\n2 sensores de contacto.\n1 sensor de sonido.\n1 sensor infrarrojo.\n1 sensor de ultrasonido.\n\nEfectores:\n3 servomotores.\nEl bloque NXT\nEs la pieza principal del Lego Mindstorm v2.0. Consiste fundamentalmente en una pieza que contiene un procesador de 32 bits y unas dimenciones de unos 4.6 x 15 x 15.1 pulgadas y pesa 4.6 libras. Tiene tres puertos de salida para conectar motores. Puertos A, B y C. y tiene cuatro puertos de entrada para conectar sensores. Puertos 1, 2, 3 y 4. Se conecta un cable USB y también se puede usar la conexión inalámbrica Bluetooth para transferir datos. Sus especificaciones son las siguientes:\nMicrocontrolador 32-bit ARM7\n256 Kbytes FLASH, 64 Kbytes RAM\nMicrocontrolador 8-bit AVR\n4 Kbytes FLASH, 512 Bytes RAM\nComunicación inalámbrica Bluetooth (Bluetooth Clase II V2.0)\n4 puertos de entrada, cable de 6 hilos\n3 puertos de salida, cable de 6 hilos\nPantalla gráfica LCD de 100 x 64 pixeles\nBocina - 8 kHz calidad de sonido\nFuente de poder: 6 baterías AA\nMi primer Robot NXT\nUnos de los modelos de robot que vienen en el manual es este bípedo que construí durante la noche. En cuanto a funcionalidad, es bastante simple pero sirve para experimentas con las posibilidades de este Lego. Solo mueve los brazos y “camina” (con algo de dificultad). la programación se realiza con el ambiente que trae en el CD, que es bastante simple y fácil de usar. Sin embargo es demasiado básico (muy bueno para enseñas a programar a los niños)\n\nAquí les dejo un pequeño vídeo que tome cuando lo terminé:\n\n \n\nReferencias\nhttp://mindstorms.lego.com/en-us/Default.aspx (página oficial)\nhttp://www.bakati.com/s~q-lego-mindstorm.aspx (tienda virtual)\nhttp://www.amazon.com/LEGO-4544091-Mindstorms-NXT-2-0/dp/B001USHRYI/ref=sr_1_1?ie=UTF8&qid=1297730139&sr=8-1 (tienda virtual)\nEjemplos de algunos videos\nhttp://www.gadgetreview.com/2008/03/lego-solves-rubiks-cube-in-6-minutes.html (robot que resuelve el cubo de rubic)\nhttp://www.maxmax.es/Lego-Mindstorm-NXT (algunas imágenes)\nhttp://www.youtube.com/watch?v=Mp8Y2yjV4fU (robot que resuelve sudocus)\nhttp://www.youtube.com/watch?v=gXiql8Fm64A (varios ejemplos de robot)\nhttp://www.youtube.com/watch?v=aec-YxOw-28&feature=related (una araña)\nhttp://www.youtube.com/watch?v=ebfxYAUBw-0&feature=related (carro que estaciona de lado)\nhttp://www.youtube.com/watch?v=vaiJz7NFDOY&feature=related (robot que camina)\nhttp://www.youtube.com/watch?v=9dvTvNmiXNE&feature=related (otro robot que camina)\nParecen muy complicados pero se una forma divertida de aprender a programar. El límite de los que se puede hacer con este juguete esta en la imaginación.\nAhora debo buscar otras herramientas de programación que me permitan sacar el máximo provecho de este juguete y además hacerlos desde mi sistema GNU/Linux.\n\n\n\n",
    "preview": "posts/2021-06-12-robots-hechos-con-lego-mindstorms-nxt/../../images/robotics/nxt_robot0780.jpg",
    "last_modified": "2021-06-29T19:49:08+00:00",
    "input_file": "robots-hechos-con-lego-mindstorms-nxt.knit.md"
  },
  {
    "path": "posts/2021-06-29-taller-de-estadistica-descriptiva-y-regresion-lineal-con-r/",
    "title": "Taller de Estadística Descriptiva y Regresión Lineal con R",
    "description": "Este taller de R esta dirigido a estudiantes de la materia de Introducción a la Probabilidad y Estadística de la Escuela de Computación de la UCV. Se resolverán problemas de descripción de una muestra y la inferencia estadística a través de modelos lineales en el entorno de RStudio.",
    "author": [
      {
        "name": "José R Sosa",
        "url": "https://example.com/josersosa"
      }
    ],
    "date": "2011-07-24",
    "categories": [
      "Teaching",
      "Statistic",
      "Data Science"
    ],
    "contents": "\n\nContents\nDescripción del taller\nObjetivos del Taller.\nObjetivos Específicos.\nRecursos del taller.\nDuración estimada del taller.\nReferencias y manuales sobre R.\n\nActividades del taller\n1. Introducción.\n2. Paquete estadístico R.\n3.Importar los datos muestrales.\n4.Representación gráfica de los datos muestrales.\n5.Análisis descriptivo de la muestra.\n6. Cálculo de los percentiles muestrales.\n7. Modelo de Regresión Lineal.\n8. Aplicando el modelo.\n9. Tarea para la casa.\n\n\nEl software estadístico utilizado es el R, y trabajaremos sobre una muestra estadística específicamente creada para este taller.\nDescripción del taller\nObjetivos del Taller.\nConocer y manejar los elementos fundamentales del entorno del software estadístico R.\nExperimentar los conceptos de estadística descriptiva sobre una muestra grande.\nAplicar el modelo de Regresión Lineal para hacer inferencias estadísticas sobre mediciones reales.\nObjetivos Específicos.\nAnalizar una muestra de niños y niñas entre 0 y 3 años de edad con medidas de Talla. Peso y Circunferencia Craneal a través de Estadística descriptiva\nGenerar modelos para construir los percentiles de cada una de las medidas a partir de modelos lineales\nConstruir un algoritmo que a partir de unas medidas de Peso, talla o Circunferencia Craneal de una determinada edad de una niña o niño, el mismo retorne entre que percentiles se encuentra.\nRecursos del taller.\nPueden descargar a través de los siguientes enlaces todos los recursos necesarios para la realización de este taller:\nTalle_R.pdf: Enunciado del Taller en formato PDF.\nMuestra.txt: Muestra en formato CSV. Nota: esta muestra fue generada artificialmente.\ncj41l018.pdf: Un ejemplo de gráficas de percentiles generados por la National Center of Health Statistics (EEUU).\nDuración estimada del taller.\nTiempo estimado: 2 horas\nReferencias y manuales sobre R.\nmanual_r.pdf: “Estadística básica con R y R-commander”, manual bastante completo (unas 160 pags) de la Universidad de Cádiz.\nrdebuts_es.pdf: “R para Principiantes”, manual básico tipo tutoriales del Institut des Sciences de l’Evolution Universit Montpellier II. Este tutorial cubre buena arte del manejo de gráficos con R.\nR-intro-1.1.0-espanol.1.pdf: “Introducción a R”. Otro manual bastante completo sobre R.\nR.pdf: “An R Tutorial”. Tutorial muy básico de R.\nrefman.pdf: “R: A Language and Environment for Statistical Computing” (en ingles y para windows).\nWikipedia: aquí se mantiene una página actualizada con información sobre R.\nActividades del taller\n1. Introducción.\nUno de los instrumentos más utilizados por los pediatras para el monitoreo del crecimiento de los niños en sus primeros años de vida son los gráficos de percentiles de peso talla y diámetro craneal emitidos por la Organización Mundial de la Salud (OMS) como el de ejemplo anexado a este taller. Estos gráficos permiten a los doctores comparar el desarrollo de los niños al identificar entre que percentiles se encuentra un niño en particular dadas su medidas de talla, peso y circunferencia craneal, así como también, pueden saber si su peso está acorde con su talla. Estas gráficas se generan a partir del análisis de datos estadísticos muestrales recolectados en varios países del mundo.\n2. Paquete estadístico R.\nR es un paquete estadístico de software libre, distribuido bajo licencia GPL. Más específicamente se trata de un lenguaje y un entorno de programación para el análisis estadístico. Este programa esta instalado en el la imagen docker que hemos preparado para la realización de este taller en los laboratorios docentes da la Facultad. Las versiones de otros sistemas operativos pueden descargase desde la pagina oficial r-project.org\n3.Importar los datos muestrales.\nEs recomendable definir el directorio de trabajo, que es donde se deben encontrar los archivos de entrada y donde se guardaran los archivos de salida. Seguidamente cargaremos en un marco de datos la muestra llamada “Muestra.txt”. Esta muestra esta compuesta por un listado de mediciones del peso, largo y circunferencia craneal de niños de ambos sexos entre 0 y tres años de edad (medidos en meses)\n\n\nmuestra <- read.csv(\"../../files/stats/taller-regresion/Muestra.txt\") \n\n\n\n4.Representación gráfica de los datos muestrales.\nGraficar la nube de datos que representa la relación del peso niños varones con respecto a su edad. Para esto crearemos sol listados, uno para contener las edades y el otro para los pesos.\n\n\ny <- muestra$Pesos[muestra$Sexo==1]\nx <- muestra$Edades[muestra$Sexo==1]\nplot(x,y, pch=\".\", main=\"Muestra de pesos de niños entre 0 3 años\")\n\n\n\n\n5.Análisis descriptivo de la muestra.\nGrafíque el histograma de los pesos de los niños varones de 10 meses de edad. Diga el tamaño de la muestra para esta población y determine su media, desviación estándar y rango muestrales.\n\n\nlPeso <- muestra$Pesos[muestra$Sexo==1 & muestra$Edades==10]\nl <- length(lPeso)\nm <- mean(lPeso)\ns <- sqrt(var(lPeso))\nclases <- seq(min(lPeso), max(lPeso), length.out=15)\nh <- hist(lPeso, prob=T,labels=F, breaks=clases, main=\"Histograma de Pesos de niños de 10 meses\")\nnormal <- function(x) dnorm(x, m, s)\ncurve(normal, add=T)\ntext(h$mids,h$density+0.01,h$counts)\ntext(min(lPeso)+1,0.22,as.expression(substitute(sigma==des,list(des=s))))\ntext(min(lPeso)+1,0.21,as.expression(substitute(mu==prom,list(prom=m))))\ntext(min(lPeso)+1,0.20,as.expression(substitute(n==tam,list(tam=l))))\n\n\n\n\nRepita luego esta operación para los niños varones de 25 meses, compare y comente.\n6. Cálculo de los percentiles muestrales.\nGeneré un archivo de salida con el listado de medias, desviaciones estándar y percentiles de 5%, 10%, 25%, 50%, 75%, 90% y 95% para cada una de las edades y sexo.\n\n\nNombres <-  c(\"Sexo\", \"Edad\", \"mPeso\", \"sPeso\", \"p05Peso\", \"p10Peso\", \"p25Peso\", \"p50Peso\", \"p75Peso\", \"p90Peso\", \"p95Peso\")\nwrite.table(t(Nombres), file = \"../../files/stats/taller-regresion/Salida.txt\", append = TRUE, row.names = FALSE, col.names = FALSE, sep = \",\")\nfor (sexo in 1:2) {\n lEdades <- unique(muestra$Edades[muestra$Sexo==sexo])\n for (edad in lEdades) {\n  lPesos <- muestra$Pesos[muestra$Sexo==sexo & muestra$Edades==edad]\n  mPeso <- mean(lPesos)\n  sPeso <- sqrt(var(lPesos))\n  p05Peso <- quantile(lPesos, 0.05)\n  p10Peso <- quantile(lPesos, 0.1)\n  p25Peso <- quantile(lPesos, 0.25)\n  p50Peso <- quantile(lPesos, 0.50)\n  p75Peso <- quantile(lPesos, 0.75)\n  p90Peso <- quantile(lPesos, 0.90)\n  p95Peso <- quantile(lPesos, 0.95)\n  Salidas <- c(sexo, edad, mPeso, sPeso,p05Peso,p10Peso, p25Peso, p50Peso, p75Peso, p90Peso, p95Peso)\n  write.table(t(Salidas), file = \"../../files/stats/taller-regresion/Salida.txt\", append = TRUE, row.names = FALSE, col.names = FALSE, sep = \",\")\n }\n}\n\n\n\n7. Modelo de Regresión Lineal.\nCargue el archivo generado para crear modelo lineal que relacione en peso de los niños varones en función de las edades. Haremos esto con el percentil muestral 50.\n\n\nmuestra <- read.csv(\"../../files/stats/taller-regresion/Salida.txt\")\nlp50Peso <- muestra$p50Peso[muestra$Sexo==1]\nlEdad <- muestra$Edad[muestra$Sexo==1]\nDatos <- data.frame(lEdad, lp50Peso)\nplot(Datos$lEdad, Datos$lp50Peso, main=\"Gráfico del Percentil muestral 50 de niños entre 0-3 años\")\nmlAjuste <- lm(lp50Peso~lEdad, data=Datos)\nabline(coef(mlAjuste))\nr <- cor(Datos$lEdad, Datos$lp50Peso)\ntext(min(Datos$lEdad)+4,max(Datos$lp50Peso)-3,as.expression(substitute(R==correl,list(correl=r))))\n\n\n\n\nComente sus observaciones. Repita la operación sobre una espacio transformado mediante el cálculo de los logaritmos, es decir manejando las coordenadas (Log(x),Log(y))\n\n\ne <- exp(1)\nloglEdad <- log(lEdad[-1],e) #Suprimiendo el primer elemento para evitar el log(0)\nloglp50Peso <- log(lp50Peso[-1],e) #Suprimiendo el primer elemento para evitar el log(0)\nlogDatos <- data.frame(loglEdad, loglp50Peso)\nmlAjuste <- lm(loglp50Peso~loglEdad, data=logDatos)\nplot(loglEdad, loglp50Peso, main=\"Gráfico del Percentil muestral 50 de niños entre 0-3 años\")\nabline(coef(mlAjuste))\nr <- cor(loglEdad, loglp50Peso)\ntext(0.5,2.5,as.expression(substitute(R==correl,list(correl=r))))\n\n\n\n\nComente sus observaciones. Ahora grafiquemos estos resultados en el espacio no transformado (x,y) y calculemos el error promedio obtenido con este modelo.\n\n\nparam <- coef(mlAjuste)\nx <- lEdad\ny <- exp(log(x)*param[2]+param[1])\nplot(lEdad, lp50Peso, main=\"Gráfico del Percentil muestral 50 para niños varones\")\nlines(lEdad,y)\n\n\n\n\n8. Aplicando el modelo.\nConsideremos un caso particular de un niño con peso y Edad dados (8 meses, 10.2 Kg). Escriba un función que reciba estos parámetros y determine si dicho niño se encuentra por encima del percentil 50 o no. Grafíque el resultado.\n\n\nSobrePercentil <- function(edad, peso) {\n  peso >= exp(log(edad)*param[2]+param[1])\n}\n\nMedidas <- c(8, 10.2)\nplot(lEdad,exp(log(x)*param[2]+param[1]),type=\"l\")\npoints(Medidas[1], Medidas[2], col=\"red\")\n\n\n\nSobrePercentil(8, 10.2)\n\n\nloglEdad \n    TRUE \n\n9. Tarea para la casa.\nEn función del digito con el que termina su número de cédula realize uno de los siguientes ejercicios para la casa. Este será evaluado en un breve interrogatorio posteriormente:\nGenere un archivo de salida con los coeficientes asociados a los modelos lineales de los percentiles 10%,25%,50%,75% y 90% de las mediciones de Talla en función de la edad para niños varones entre 0 y 3 años de edad. Luego codifique un algoritmo (función) que reciba como parámetros un valor de Sexo, Edad y Talla de un niño determinado y retorne como resultado entre que percentiles se encuentra, graficando el resultado (el punto y los dos percentiles entre los que se encuentra).\nGenere un archivo de salida con los coeficientes asociados a los modelos lineales de los percentiles 5%,25%,50%,75% y 95% de las mediciones de Talla en función de la edad para niñas hembras entre 0 y 3 años de edad. Luego codifique un algoritmo (función) que reciba como parámetros un valor de Sexo, Edad y Talla de una niña determinada y retorne como resultado entre que percentiles se encuentra, graficando el resultado (el punto y los dos percentiles entre los que se encuentra).\nGenere un archivo de salida con los coeficientes asociados a los modelos lineales de los percentiles entre 5% y 95% a intervalos de 5%, de las mediciones de Peso en función de la edad para niños varones entre 0 y 3 años de edad. Luego codifique un algoritmo (función) que reciba como parámetros un valor de Sexo, Edad y Peso de un niño determinado y retorne como resultado entre que percentiles se encuentra, graficando el resultado (el punto y los dos percentiles entre los que se encuentra).\nGenere un archivo de salida con los coeficientes asociados a los modelos lineales de los percentiles entre 5% y 95% a intervalos de 5%, de las mediciones de Peso en función de la edad para niñas hembras entre 0 y 3 años de edad. Luego codifique un algoritmo (función) que reciba como parámetros un valor de Sexo, Edad y Peso de una niña determinada y retorne como resultado entre que percentiles se encuentra, graficando el resultado (el punto y los dos percentiles entre los que se encuentra).\nGenere un archivo de salida con los coeficientes asociados a los modelos lineales de los percentiles 10%,25%,50%,75% y 90% de las mediciones de Circunferencia Craneal en función de la edad para niños varones entre 0 y 3 años de edad. Luego codifique un algoritmo (función) que reciba como parámetros un valor de Sexo, Edad y Circunferencia Craneal de un niño determinado y retorne como resultado entre que percentiles se encuentra, graficando el resultado (el punto y los dos percentiles entre los que se encuentra).\nGenere un archivo de salida con los coeficientes asociados a los modelos lineales de los percentiles 5%,25%,50%,75% y 95% de las mediciones de Circunferencia Craneal en función de la edad para niñas hembras entre 0 y 3 años de edad. Luego codifique un algoritmo (función) que reciba como parámetros un valor de Sexo, Edad y Circunferencia Craneal de una niña determinada y retorne como resultado entre que percentiles se encuentra, graficando el resultado (el punto y los dos percentiles entre los que se encuentra).\nGenere un archivo de salida con los coeficientes asociados a los modelos lineales de los percentiles entre 10% y 90% a intervalos de 10%, de las mediciones de Talla en función de la edad para niños varones y hembras entre 0 y 3 años de edad. Luego genere las gráficas de percentiles para niños y niñas de la Talla en función de la edad, como las generadas por las organizaciones de salud.\nGenere un archivo de salida con los coeficientes asociados a los modelos lineales de los percentiles entre 10% y 90% a intervalos de 10%, de las mediciones de Talla en función de la edad para niños varones y hembras entre 0 y 3 años de edad. Luego genere las gráficas de percentiles para niños y niñas de la Talla en función de la edad, como las generadas por las organizaciones de salud.\nGenere un archivo de salida con los coeficientes asociados a los modelos lineales de los percentiles entre 10% y 90% a intervalos de 10%, de las mediciones de Circunferencia Craneal en función de la edad para niños varones y hembras entre 0 y 3 años de edad. Luego genere las gráficas de percentiles para niños y niñas de la Circunferencia Craneal en función de la edad, como las generadas por las organizaciones de salud.\nGenere un archivo de salida con los coeficientes asociados a los modelos lineales de los percentiles entre 5% y 95% a intervalos de 10%, de las mediciones de Peso y Talla en función de la edad para niñas hembras entre 0 y 3 años de edad. Luego genere las gráficas de percentiles para niñas del Peso y Talla en función de la edad, como las generadas por las organizaciones de salud.\nComente ¿cual sería su propuesta si se le solicitará opinión sobre la realización de un servicio informático que haga este trabajo sin la necesidad de contar con una muestra en línea como la utilizada en este taller?. ¿Cual es la importancia del uso de modelos matemáticos en este tipo de problemas?\n\n\n\n",
    "preview": "posts/2021-06-29-taller-de-estadistica-descriptiva-y-regresion-lineal-con-r/../../images/statistic_with_r.jpg",
    "last_modified": "2021-06-30T15:48:50+00:00",
    "input_file": "taller-de-estadistica-descriptiva-y-regresion-lineal-con-r.knit.md"
  }
]
